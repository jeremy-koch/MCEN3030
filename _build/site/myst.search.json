{"version":"1","records":[{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Introduction"},"content":"Welcome to MCEN 3030: Computational Methods!\n\nThis course is offered by The University of Colorado Boulder Department of Mechanical Engineering, taught by Professor Jeremy Koch in the spring 2026 semester. We will learn about many of the mathematical algorithms that power engineering calculations. This is an exciting topic, as it allows us to study problems that go beyond what we can do with pencil and paper.\n\nCheck the \n\nCourse Schedule for links to all the readings (they are getting a bit scattered around now that the website is filling up.)","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Introduction","lvl2":"Scope"},"type":"lvl2","url":"/#scope","position":2},{"hierarchy":{"lvl1":"Introduction","lvl2":"Scope"},"content":"This is an introductory course with a large amount of coding, though it is arguably more of an “applied math” course than a programming course. Most of the heavy lifting will be done with for, while, if, and thoughtful use of arrays. We will build our own versions of optimization algorithms, finite-element calculators, and differential equation solvers and that will allow us to better understand: what information is needed in these methods, what errors might we see, what the results mean, and what can we do if our approach is not working.\n\n\n\nNonlinear/chaotic differential equations can be “solved” using the numerical techniques learned in this class (Runge-Kutta Method). Here is a phase diagram, inspiration and equation from: Njah “Synchronization via active control of parametrically and externally excited Φ6 Van der Pol and Duffing oscillators and application to secure communications” Journal of Vibration and control 17.4 (2011): 493-504. Plot created with Julia’s “Plots” package (after calculating the trajectories using Runge-Kutta).","type":"content","url":"/#scope","position":3},{"hierarchy":{"lvl1":"Introduction","lvl2":"Some policy highlights"},"type":"lvl2","url":"/#some-policy-highlights","position":4},{"hierarchy":{"lvl1":"Introduction","lvl2":"Some policy highlights"},"content":"We will use the \n\n“flipped classroom” model and will cultivate a classroom environment that is highly collaborative.\n\nYou can choose what language you use. MATLAB, Python, or Julia (ask me about others). AI will help you get your feet underneath you, and I have built \n\na page that includes pretty much all the commands you will need this semester, in those three languages. (Again, let’s talk about other languages.)\n\n“AI will help you get your feet underneath you”? Yep, you have a green light to use AI on the homework and project in this course. However, make sure to \n\nuse it responsibly -- the exams are pencil and paper only, no electronics.","type":"content","url":"/#some-policy-highlights","position":5},{"hierarchy":{"lvl1":"Introduction","lvl2":"Some content highlights"},"type":"lvl2","url":"/#some-content-highlights","position":6},{"hierarchy":{"lvl1":"Introduction","lvl2":"Some content highlights"},"content":"We will (probably) use GitHub Classroom (and will get that going together). GitHub “repositories” are a very standard way to share code, and this organization step might be one of the most important lessons of the semester.\n\nWe will learn how to fit models, including nonlinear ones, to experimental data.\n\nWe will do an introduction to machine learning, including a project.\n\nWe will solve coupled nonlinear differential equations, including those that describe \n\nmathematical chaos. (Plot above is an example.)","type":"content","url":"/#some-content-highlights","position":7},{"hierarchy":{"lvl1":"Introduction","lvl2":"How to use this site"},"type":"lvl2","url":"/#how-to-use-this-site","position":8},{"hierarchy":{"lvl1":"Introduction","lvl2":"How to use this site"},"content":"I prepared this site to augment the learning that occurs elsewhere -- a rephrasing of the lecture (video) material that may clarify things, and a reference if you are quickly looking for an equation. It is not as detailed as a textbook and does not have many examples.\n\nIt is a living document that will have things added and removed frequently. As such, I do NOT recommend forking this repository (if you know how to do this) -- if you are reading this early in the semester, there could be 50% more material by the end of the semester, I probably have incomplete pages floating around, and I might decide to eliminate some content in favor of adding other content.\n\nCourse units are in the panel on the left, and clicking them will open a drop-down menu. Each item in that drop-down menu is a short reading. The readings are mostly about the motivation and the math, though sometimes code is included. Expect to read 1-3 of these before each class period (alongside watching the videos).\n\nIn the top-right corner of this site is a search bar. So, if you are looking for references to Taylor Series within this site, you can search for it up there.\n\nBecause this is a “polyglot” course, most of the times that code is referenced, it will be included in an environment like that below. You can choose the tab for your language, then see the code. In the top-right corner of each coding environment, you can choose an icon to copy that code block, and then you can paste it into your working environment and run it. Please confirm the code does what you think it does! Maybe I made a mistake!\n\nf=@(x,a) sin(x)+a;\n\nf=lambda x,a: np.sin(x)+a\n\nf=(x,a) -> sin(x)+a","type":"content","url":"/#how-to-use-this-site","position":9},{"hierarchy":{"lvl1":"Introduction","lvl2":"A quick extra... because I wanted more color on this page"},"type":"lvl2","url":"/#a-quick-extra-because-i-wanted-more-color-on-this-page","position":10},{"hierarchy":{"lvl1":"Introduction","lvl2":"A quick extra... because I wanted more color on this page"},"content":"\n\nA quick example of where you might take your wisdom after completing MCEN 3030 -- this is kind of a specialized numerical solution to a PDE. \n\nAgents.jl is a Julia package that can implement flocking/swarming models -- really difficult to understand with pencil and paper, as there are often hundreds or thousands of entities interacting in these systems. One of their examples implements a forest fire model -- unfortunately very relevant to us in Colorado.","type":"content","url":"/#a-quick-extra-because-i-wanted-more-color-on-this-page","position":11},{"hierarchy":{"lvl1":"Course Policies"},"type":"lvl1","url":"/course-policies","position":0},{"hierarchy":{"lvl1":"Course Policies"},"content":" **Author:** Jeremy Koch \n\nFor more details about course policy, see the official course syllabus on Canvas.\n\nAttention\n\nThis document, and the course syllabus, cannot outline explicit policies for every eventuality. I reserve the right to modify any course policy in response to significant events over the semester. This could include, but is not limited to: excessive class cancellations due to weather or pandemic, changes in the accessibility of AI tools (e.g. if free versions disappear), widespread academic dishonesty, students not making effective use of class time, etc.\n\nKeep in mind, your success is my success, and so you should have nothing to worry about if you approach this class earnestly.","type":"content","url":"/course-policies","position":1},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Grade Breakdown"},"type":"lvl2","url":"/course-policies#grade-breakdown","position":2},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Grade Breakdown"},"content":"10% in-class problems15% homework repository5% ML project20% midterm 120% midterm 230% final exam\n\nin-class problems:\n\nThese will be completed in groups of three towards the beginning of each class period and will be mostly tech-free. An example problem is: compute the first two iterations of an algorithm by hand. The goal is for you to get a feel for how the algorithm works, which will allow you to better understand how to translate it to code. Further, it will give you a check to see if your code is working: in the above case, an if iteration==2, print x within your loop might be a good thing to check out.\n\nBigger picture: These points represent your active participation in discussions with your colleagues, which I believe is the most productive way to learn the course material. Submission will occur before the end of the class period. There will be no option to submit these late -- if you missed the class discussion, you missed the learning opportunity and will not receive credit for it. However, we will drop a small number of these assignments, likely 4, in the final grade calculation, and so you will not be penalized if you miss a small number of classes due to illness, travel, or a need to temporarily prioritize another course (which I don’t approve of, but it’s your call). I do not recommend trying to be strategic with these absences -- save them for when you are sick.\n\nhomework repository:\n\nOver the course of the semester we will learn 25-30 computational ideas. Implementing these ideas as functions/scripts will be your homework, to be submitted via GitHub Classroom (mimicking the development of an actual code repository).\n\nWe will usually have the opportunity to begin this work in the classroom where your colleagues, a TA, or myself will be around to help you talk through your ideas. However...\n\nWarning\n\nThe instructional staff can see when GitHub commits occur, and will pay attention to the number that are occurring at the end of class periods. If we see that the two sections are not making use of the in-class time, as evidenced by a low percentage of students committing something by the end of class, we will eliminate this working opportunity and replace it with additional in-class problems or lecture content. We will additionally monitor the commit history over the course of the semester. A student who consistently submits one (perfect) version of the code shortly before the deadline is almost certainly misusing AI \n\nmachine learning project:\n\nWe will get some authentic experience in doing a machine learning calculation. We will briefly introduce the topic, describing some of the strategies but not necessarily diving deeply into the math. MATLAB has a machine learning toolbox, Python has several packages and has the most robust machine learning community (Scikit-learn, PyTorch, TensorFlow), Julia has Lux and Flux.\n\nAI use is encouraged, tutorial use is encouraged, but plagiarism is not. An example of plagiarism in this context is: taking someone’s completed analysis published in a blog somewhere and submitting it as your own work. Plagiarism in this course is completely unacceptable and will lead to immediate failing grade for the course and submission to the honor council, regardless of your grade in the other aspects of the course.\n\nThere may be intermediate milestones such as submitting a topic for approval and submitting your LLM prompting. More details will be posted.\n\nexams:\n\nThis course will have three exams -- two midterms that will occur during class, and a final exam scheduled by the university. The midterms are \n\ntentatively scheduled and the \n\nfinal exam time is cemented by the university before the academic year even begins.\n\nThe exams will be entirely pencil-and-paper, no electronics (including calculators). You will be allowed a small set of notes (specifics on this added later). The most important aspect of these notes will be the inputs, outputs, and descriptions of the functions you have written this semester.\n\nExam questions will likely be something like: achieve a task by doing the necessary setup work (e.g., defining an array of equally spaced values), calling a function, and post-processing the results. It will not be made explicit what function to call -- you will make that judgment based on your understanding of the function inputs, outputs, and limitations. There may be some additional types of questions -- I might add some details here later.\n\nThe final exam will be cumulative.","type":"content","url":"/course-policies#grade-breakdown","position":3},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Professionalism"},"type":"lvl2","url":"/course-policies#professionalism","position":4},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Professionalism"},"content":"In the past year, have observed an uptick in emails that indicate students are not paying attention to course policies and/or that students believe that course policies should not apply to them. Policies are only policies if they apply to the entire class.\n\nI am glad to receive emails from you in general, don’t be discouraged to send them to me, but I would like you to think twice before:\n\n... sending an email with just “question” (or something similar) in the subject line. See \n\nhow to write emails for this class.\n\n... asking me to move deadlines/exams because you have a project or exam in another class.\n\n... asking me to accept a late submission without penalty, including if you “forgot”, “thought you had already submitted it”, or had internet issues on the due date.\n\n... asking me for extra credit or to curve exams.\n\n... asking me when the final is. \n\nIt has been scheduled already, and it takes place in the classroom unless you hear otherwise.\n\n... asking me to round up your grade.\n\n... or similar requests. Please do not try to circumvent course policies, the answer is no.","type":"content","url":"/course-policies#professionalism","position":5},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Class Disruption"},"type":"lvl2","url":"/course-policies#class-disruption","position":6},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Class Disruption"},"content":"This is a \n\nflipped classroom that involves discussion between students and computer use. The classroom will be lively -- it is imperative that we remain focused. If you are seen to be checking social media/the news/sports scores, playing games, watching non-course-related videos, listening to music, etc. ... basically if you are using class time for things not related to class ... you will be asked to leave the classroom and your in-class score for the day will be a non-droppable zero. This includes phone use.\n\nCaution\n\nA rough calculation: after dropping a few, your grade on the in-class portion of the class will be based on something like 20 in-class problems this semester, and an earnest student will likely receive full credit on this aspect of the course. However, a zero on one will drop your overall grade by about 0.5%.","type":"content","url":"/course-policies#class-disruption","position":7},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Late Work"},"type":"lvl2","url":"/course-policies#late-work","position":8},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Late Work"},"content":"Homework will be due every two weeks, Friday at 11:59PM. I strongly discourage waiting until Friday night to do your homework. Late work will be subject to a penalty of 10% per day, and may be submitted up to 5 days late.\n\nComputer and internet issues are not a valid excuse for submitting late work. If you would like to “play chicken” with the deadline, then you must accept that might lose. My recommendation is to plan to submit early which will give you a buffer in case you run into trouble. Forgetting to submit work does not absolve you from these penalties. You can consider the zero on the assignment to be a penalty for not confirming that your work was submitted. \n\nSome of the best advice I can give you is: get the easy stuff right. Submitting your work on time (and confirming it was submitted) is an example of the easy stuff. If you are going to do the hard work of completing the assignment, don’t mess up the easy work of submitting it on time.","type":"content","url":"/course-policies#late-work","position":9},{"hierarchy":{"lvl1":"Course Policies","lvl2":"AI Policy"},"type":"lvl2","url":"/course-policies#ai-policy","position":10},{"hierarchy":{"lvl1":"Course Policies","lvl2":"AI Policy"},"content":"This course allows for \n\nresponsible use of AI on homework and projects. AI is prohibited on in-class activities (unless explicitly stated for a specific assignment) and on exams.\n\nIf we are not going to police AI use, the responsibility shifts to the student to understand what amount of AI use is too much.\n\nTip\n\nA good starting point: If you would be hesitant to show me your prompts, you probably went too far.\n\nThe instructional staff will monitor student submissions and commit history. This data will inform discussions with individual students or the class as a whole. For example, one commit near the deadline, with perfect code, is a strong indicator of AI misuse and/or misuse of class time.","type":"content","url":"/course-policies#ai-policy","position":11},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Final Grades, Extra Credit, and Curving"},"type":"lvl2","url":"/course-policies#final-grades-extra-credit-and-curving","position":12},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Final Grades, Extra Credit, and Curving"},"content":"Students are assessed based on the work that they have submitted over the course of the semester. I cannot and do not take into consideration your intended graduation date, financial aid, sports eligibility, number of courses, work schedule, desire to attend grad school, or anything else.\n\nYou should assume that there is no extra credit in this class and should not ask for extra credit opportunities. Please recognize that I am tasked with determining whether you have met the learning objectives of the course. Far too often, extra credit is not actually “extra” and instead effectively covers for missed learning, thus leaving the student underprepared for ensuing classes.\n\nA slight curve may be applied to exam grades or the overall grade, but this is not guaranteed. This may be tied to my perception of AI misuse, namely: if I am suspicious that a large portion of the class is misusing AI (e.g., based on commit history or incredibly perfect homework submissions), I will be more reluctant to curve the exams. Again, please do not ask about a curve.","type":"content","url":"/course-policies#final-grades-extra-credit-and-curving","position":13},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Further policies..."},"type":"lvl2","url":"/course-policies#further-policies","position":14},{"hierarchy":{"lvl1":"Course Policies","lvl2":"Further policies..."},"content":"... can be found in the full syllabus on Canvas.","type":"content","url":"/course-policies#further-policies","position":15},{"hierarchy":{"lvl1":"Tentative Schedule"},"type":"lvl1","url":"/course-schedule","position":0},{"hierarchy":{"lvl1":"Tentative Schedule"},"content":"Week 0:       8 Jan\n\nCourse Intro\n\nWeek 1:       12-16 Jan\n\nTuesday 13 Jan:\n\nProgramming intro\n\nThursday 15 Jan:\n\nFloats(Video on Canvas)\n\nNumerical Error\n\nWeek 2:       19-23 Jan\n\nTuesday 20 Jan:\n\nRoot-finding Methods Intro\n\nThe Bisection Method(Video on Canvas)\n\nThursday 22 Jan:\n\nThe (1D) Newton-Raphson Method and Secant Method(Video on Canvas)\n\nFriday, 23 Jan: homework due\n\nWeek 3:       26-30 Jan\n\nTuesday 27 Jan:\n\nThe 2D Newton-Raphson Method\n\nCramer’s Rule\n\nClasses\n\nThursday 29 Jan:\n\nLU Decomposition\n\nA note on the matrix inverse\n\nWeek 4:       2 - 6 Feb\n\nTuesday 3 Feb:\n\nTBD\n\nThursday 5 Feb:\n\nTBD\n\nFriday, 6 Feb: homework due\n\nWeek 5:       9-13 Feb\n\nTuesday 10 Feb:\n\nLinear fitting\n\nThe meaning of R^2\n\nThursday 12 Feb:\n\nNonlinear fitting\n\nWeek 6:       16-20 Feb\n\nTuesday 17 Feb:\n\nPattern Search\n\nThursday 19 Feb:\n\nMidterm Practice\n\nFriday, 20 Feb: homework due\n\nWeek 7:       23-27 Feb\n\nTuesday, 24 Feb: MIDTERM 1 in class (tentative)\n\nThursday, 26 Feb: no class, Midterm Reading Day\n\nWeek 8:       2-6 Mar\n\nTuesday 3 Mar:\n\nGolden Search\n\nThursday 5 Mar:\n\nSteepest Ascent\n\nWeek 9:       9-13 Mar\n\nTuesday 10 Mar:\n\nMachine Learning Introduction\n\nThursday 12 Mar:\n\nMachine Learning Project Work\n\nFriday, 13 Mar: homework due\n\nSpring Break Week:       15-21 Mar\n\nno class\n\nWeek 10:       23-27 Mar\n\nTuesday 24 Mar:\n\nNumerical Integration\n\nThursday 26 Mar:\n\nMonte Carlo Methods\n\nWeek 11:       30 Mar-3 Apr\n\nTuesday 31 Mar:\n\nOrdinary Differential Equations Intro\n\nEuler’s Method\n\nThursday 2 Apr:\n\nCoupled Equations\n\nFriday, 3 Apr: homework due\n\nWeek 12:       6-10 Apr\n\nTuesday 7 Apr: Midterm Practice\n\nThursday, 9 Apr: MIDTERM 2 in class (tentative)\n\nWeek 13:       13-17 Apr\n\nTuesday, 14 Apr:\n\nBoundary-Value Problems\n\nThursday, 16 Apr:\n\nThe Shooting Method\n\nWeek 14:       20-24 Apr\n\nTuesday 21 Apr:\n\nPartial Differential Equations\n\nThursday 23 Apr:\n\nPartial Differential Equations 2\n\nFriday, 24 Apr: homework due\n\nFinals Week:       27 Apr-1 May\n\nSection 010: Thursday, 30 Apr 10:30AM - 1PM\n\nSection 020: Tuesday,  28 Apr 4:30–7PM(Yes, the earlier section has their final on the later date.)","type":"content","url":"/course-schedule","position":1},{"hierarchy":{"lvl1":"Course Statistics"},"type":"lvl1","url":"/course-statistics","position":0},{"hierarchy":{"lvl1":"Course Statistics"},"content":"Added (1) for those interested, (2) as examples of (hopefully) well-prepared plots, (3) to be transparent regarding the data that may be used to shift course structure, and (4) to emphasize quantitatively that this is a learning community that will not work as well if we are not all participating.","type":"content","url":"/course-statistics","position":1},{"hierarchy":{"lvl1":"Course Statistics","lvl2":"Language choice"},"type":"lvl2","url":"/course-statistics#language-choice","position":2},{"hierarchy":{"lvl1":"Course Statistics","lvl2":"Language choice"},"content":"MATLAB\n\n98\n\nPython\n\n41\n\nJulia\n\n4","type":"content","url":"/course-statistics#language-choice","position":3},{"hierarchy":{"lvl1":"Course Statistics","lvl2":"Video views"},"type":"lvl2","url":"/course-statistics#video-views","position":4},{"hierarchy":{"lvl1":"Course Statistics","lvl2":"Video views"},"content":"\n\nLooking better!\n\nLeaving this for now...\n\nTaking the Newton-Raphson video as an example: The following plot describes the percentage of students (y-axis) who watched at least x% of the video (x-axis).\n\n\n\nSo: less than half of the class opened the video. Of the 67 students who opened the video, only 40 watched the entire video. That is: only 28% of the students enrolled in MCEN 3030 watched the entire video.","type":"content","url":"/course-statistics#video-views","position":5},{"hierarchy":{"lvl1":"The Flipped Classroom"},"type":"lvl1","url":"/flipped-classroom","position":0},{"hierarchy":{"lvl1":"The Flipped Classroom"},"content":" **Author:** Jeremy Koch ","type":"content","url":"/flipped-classroom","position":1},{"hierarchy":{"lvl1":"The Flipped Classroom","lvl2":"Motivation"},"type":"lvl2","url":"/flipped-classroom#motivation","position":2},{"hierarchy":{"lvl1":"The Flipped Classroom","lvl2":"Motivation"},"content":"I am excited about this semester because we are going to use the “flipped classroom” format for this course.\n\nThe rationale is this: I have observed an increase in student passivity in the past year or so -- less participation in class, less effort on homework (perhaps enabled by AI), less curiosity, ... less interest in mechanical engineering! Perhaps this cohort was already going to buck that trend, but I am putting a framework in place that is going to help with engagement. As much as possible, you will be less of a “spectator” in your own education and will spend more time “doing”. Some further motivation: I understand that engineering students are busy (don’t forget I was once a student too!) and I would like to be as productive as we can in our time together.","type":"content","url":"/flipped-classroom#motivation","position":3},{"hierarchy":{"lvl1":"The Flipped Classroom","lvl2":"Organization"},"type":"lvl2","url":"/flipped-classroom#organization","position":4},{"hierarchy":{"lvl1":"The Flipped Classroom","lvl2":"Organization"},"content":"Here’s how it will look:\n\nThe “lecture content” is 1-3 videos watched before class (so, by Tuesday and Thursday morning). I have gone through great efforts to streamline these videos such that they rarely will exceed 20 minutes, and often will be less than 10. Probably totalling an hour per week. Take notes, with pencil and paper, during the videos. Going back to this theme of “passivity” -- writing down notes is a little step you can take to be more “active” and to engage deeper parts of your brain. (By the way, taking notes with a pencil has been \n\nshown to be more effective than typing notes.)\n\nWe will spend the first few minutes of each class with a very brief summary and questions. The summary will not be a complete rehashing of the videos, and instead will be a reminder of the important equations such that we are all on the same page for the class that day. You may be volunteered to come to the board to sketch us a picture or write down an equation!\n\nYou will be given a problem to be completed collaboratively, submitted in groups of three. An example would be to carry out an algorithm by hand through two iterations. The purpose of this is to help you understand the logic of the algorithm by going through it yourself. Then, more-or-less, you will just need to translate that process into language a computer can understand. Were you mimicking a for or while loop?\n\nThe remainder of class will be devoted to getting started on your code in groups -- spiritually, this is office hour time. You may collaborate with colleagues, but everyone writes their own code. You may ask me or the TAs questions. If you are not on-task, you will be asked to leave.\n\nNote\n\nThe same content, delivered in a traditional format, might have taken a whole class period to cover (that is, 2.5 hours per week). This is both a benefit and a drawback: much of each 75-minute class period is devoted to getting the class to quiet down, fighting HDMI cables, making and correcting little mistakes, saying umm... a lot of wasted time that we will mostly avoid. However, a lot of that time is spent on questions from you, which is definitely not a waste of time, and obviously you cannot ask those questions. That is an admitted drawback, but also it could be an opportunity to think on your own (be “active”).\n\nSo the trade I am offering you (and I guess you are being forced to accept) is 30 minutes of “lecture” time at home for 30 minutes of homework time in “lecture”, twice a week. It is a good trade though: that time in class will be very productive because you are collaborating on the problems. I hypothesize that you will need to devote fewer hours to this course than you would if it was in a traditional format.\n\nWarning\n\nFor now, I will not attach any submission to the short lecture videos. However, if I measure or sense that the videos are not being watched or digested, I may implement one or more of the following:\n\nQuestions embedded within the videos\n\nNightly Canvas “quiz” to check that you understood the videos\n\nClicker questions during class\n\nNotes check at the start of class\n\nEliminating the “office hour” aspect of the second half of class, bringing back a traditional lecture format\n\nThis is more work for me and more work for you, so my preference is for you to just watch the videos.\n\nI do genuinely believe this will be an excellent environment for learning. Note that, with this structure, you should see the course content in five different ways within 24 hours: video lecture, reading, summary at the start of class, pencil-and-paper in-class problem, and getting started on the code. Spend a bit of time Tuesday/Thursday evening finishing up the homework problem and you are in GREAT shape. For students who are earnest, this structure is going to make for an extremely positive learning experience.","type":"content","url":"/flipped-classroom#organization","position":5},{"hierarchy":{"lvl1":"Professional Emails"},"type":"lvl1","url":"/professional-emails","position":0},{"hierarchy":{"lvl1":"Professional Emails"},"content":"","type":"content","url":"/professional-emails","position":1},{"hierarchy":{"lvl1":"Professional Emails","lvl2":"Motivation"},"type":"lvl2","url":"/professional-emails#motivation","position":2},{"hierarchy":{"lvl1":"Professional Emails","lvl2":"Motivation"},"content":"When applying to internships, jobs, etc., it is probably best to err on the side of caution and be aggressively polite. So, OK, start emails to a future employer with “Hope this email finds you well. I am very interested in working for your company, as I see it doing amazing things... blah blah blah”... all that nice stuff.\n\nHowever, I value efficient emails. I don’t want to hunt through three paragraphs to find a question. The truth (that I think we all have realized): it is mentally draining to read long emails and craft responses to them. So let’s get on the same page, and be efficient!","type":"content","url":"/professional-emails#motivation","position":3},{"hierarchy":{"lvl1":"Professional Emails","lvl2":"A good email"},"type":"lvl2","url":"/professional-emails#a-good-email","position":4},{"hierarchy":{"lvl1":"Professional Emails","lvl2":"A good email"},"content":"","type":"content","url":"/professional-emails#a-good-email","position":5},{"hierarchy":{"lvl1":"Professional Emails","lvl3":"Key #1: A good subject line","lvl2":"A good email"},"type":"lvl3","url":"/professional-emails#key-1-a-good-subject-line","position":6},{"hierarchy":{"lvl1":"Professional Emails","lvl3":"Key #1: A good subject line","lvl2":"A good email"},"content":"Firstly, you should establish the subject. I am asking that students in this course begin their emails with [MCEN 3030] -- yes, with square brackets, yes, with a space between “MCEN” and “3030”. I will filter all emails that include “[MCEN 3030]” in the subject line to a folder in my inbox. I will pay special attention to this folder, and further, I will be able to find your message more easily in the future if it is in this folder.\n\nIn your future job, the subject might be “[EPG]” for engine performance group, “[PF merger]” if your company is buying another company called PF, etc.\n\nSecondly, you should include specific details about the email contents, and the more specific the better (without getting ridiculous). “[MCEN 3030] question” is not a very good subject line -- is it a quick question like “can I use this command in my code” or is it “I got a last-second call to participate in the Olympics and need to know whether I should withdraw from this course or if we can work out a way to complete the final from Italy”. The former I can answer in less than 30 seconds, the latter is going to take me a while. You should have a detailed subject line regardless, but to give you more of an incentive: I will be more inclined to open your email if I suspect I can answer the question quickly. Otherwise, it waits for when I am in “email mode”.\n\n“[MCEN 3030] question on bisection method inputs” is good. “[MCEN 3030] scikit-learn or pytorch” is good, but I can tell it is going to require a bit more thought (and I appreciate that you made that clear with your subject line). “[MCEN 3030] exam 1 accommodation room” is good. You get the picture.","type":"content","url":"/professional-emails#key-1-a-good-subject-line","position":7},{"hierarchy":{"lvl1":"Professional Emails","lvl3":"Key #2: Focused email content","lvl2":"A good email"},"type":"lvl3","url":"/professional-emails#key-2-focused-email-content","position":8},{"hierarchy":{"lvl1":"Professional Emails","lvl3":"Key #2: Focused email content","lvl2":"A good email"},"content":"I don’t know who decided that all emails have to begin with “I hope this email finds you well”, but I hate it. In this class, we don’t need that. Here is a GREAT email:\n\nSubject: [MCEN 3030] use built-in flip(x)?\n\nHey Professor,\n\nCan we use MATLAB’s flip(x) in our code?\n\nThanks,\n\nStudent\n\nHere might be my response:\n\nyep\n\n... hopefully you appreciate that I was able to respond quicker than I might have had I written a fluffier email. If you want to be equally brief, go ahead. Other professors might get annoyed by the brevity, not me. Just do a good subject line and I will interpret that as you being polite!\n\nHowever, don’t be so brief that you leave out key details. I am not going to do much debugging for you this semester, but in past semesters I have gotten emails like\n\nI tried to use an if, but it keeps giving me an error.\n\nNo details about the error message, just “an error”. So, now I have to send an email asking what the specific error message was, which requires the student to reply, then I have to reply to that. A whole ordeal! Include relevant information! But, also, don’t just dump information on me and make me sort through it. Focused email content!\n\nEmails like this are part of the reason I am reluctant to debug for students anymore. I was “bailing out” too many students who weren’t even reading and processing the error messages. Deciphering error messages -- develop this skill!","type":"content","url":"/professional-emails#key-2-focused-email-content","position":9},{"hierarchy":{"lvl1":"Professional Emails","lvl3":"Key #3: Don’t ask for special treatment","lvl2":"A good email"},"type":"lvl3","url":"/professional-emails#key-3-dont-ask-for-special-treatment","position":10},{"hierarchy":{"lvl1":"Professional Emails","lvl3":"Key #3: Don’t ask for special treatment","lvl2":"A good email"},"content":"I receive about two dozen emails every semester that boil down to students asking for special treatment that violates course policy. Leniency because they:\n\nare taking 19 credit hours.\n\nhad to work.\n\nhad a project due in another class.\n\nforgot to turn in an assignment, or thought they had already submitted it.\n\ngot an error.\n\nfell asleep.\n\nhad internet problems at 11:48PM.\n\nTip\n\nIf you are going to “play chicken” with a deadline, you have to accept that you might lose.\n\nFurther, in the Fall 2025 semester I received more “grade-grubbing” emails than ever, wherein students ask, e.g., for a final grade of 89.3% to be rounded to an A-.\n\nThe answer to all of these requests is no. We, unfortunately, give grades in this school (there are some schools that don’t and it sounds really interesting), and the course policies are the rules of the game that everyone abides by. I am not going to be the judge of who has a good excuse, and it is not a course policy if I waive it for anyone who asks. Build some more robustness in your schedule where you can -- finishing things by the deadline should not, in general, be stressful.\n\nI am always wary of giving special treatment to the outspoken student, while the introverted student accepts the course policies (a deduction for being late). Why does the outspoken student deserve the higher grade? They don’t.\n\nAs it pertains to the present discussion: Asking me to go against course policy immediately makes it a bad email (and it becomes a huge cognitive load for me because I have to find a gentle way to say no). Let’s just stay on top of things as much as we can!","type":"content","url":"/professional-emails#key-3-dont-ask-for-special-treatment","position":11},{"hierarchy":{"lvl1":"Responsible use of AI"},"type":"lvl1","url":"/responsible-ai","position":0},{"hierarchy":{"lvl1":"Responsible use of AI"},"content":" **Author:** Jeremy Koch ","type":"content","url":"/responsible-ai","position":1},{"hierarchy":{"lvl1":"Responsible use of AI","lvl2":"Introduction"},"type":"lvl2","url":"/responsible-ai#introduction","position":2},{"hierarchy":{"lvl1":"Responsible use of AI","lvl2":"Introduction"},"content":"In this course, you have the green light to use AI/LLMs on homework (though not on exams or in-class problems, which are pencil and paper). Here, I will give a perspective on AI use and misuse, including recommendations on how it can be properly used by students.\n\nSomething to think about: understanding an answer is very different from being able to produce an answer. I am worried many students are asking LLMs to produce a solution, then they “study” it, and then think they “understand” the problem. This is never true -- you cannot learn to solve problems unless you, yourself, face the decisions and uncertainty. There is no uncertainty when you are handed a solution.\n\nAttention\n\nA moment of blunt honesty: Misuse of AI is THE reason why homework is weighted relatively low in the final grade calculation in this class (and likely will be low in all of my classes going forward). I would strongly prefer a teaching environment where final grades were not so dependent on performance during three time-limited exams -- I do not believe that working quickly makes one a good engineer, at all. However, I also do not want to have a class where a hard-working but imperfect student receives a lower grade than a student who puts in nearly zero effort. You may find that the department in general is going back to the old model of engineering education, where homework is not worth many points. But it is certainly worth doing to prepare for exams!\n\nAt the same time...\n\nTip\n\nGreen-lighting AI in this course opens up opportunities -- I am not too worried about allowing students to choose what programming language they use, I am looking forward to the machine learning project, and I think/hope students will get some experience in proper AI use.\n\nIf the instructional staff is not policing AI use, it is you, the student, who must judge proper use.","type":"content","url":"/responsible-ai#introduction","position":3},{"hierarchy":{"lvl1":"Responsible use of AI","lvl2":"AI Misuse"},"type":"lvl2","url":"/responsible-ai#ai-misuse","position":4},{"hierarchy":{"lvl1":"Responsible use of AI","lvl2":"AI Misuse"},"content":"We instructors worry that students are not developing as engineers because they are allowing the hard (but meaningful) work to be done by LLMs. A particularly audacious behavior that I have observed several times: students taking screenshots of problems, pasting into an AI, and then copying the results. These students possibly did not even read the problem!\n\nTip\n\nI have the following (controversial) advice: If these students care so little about the content of mechanical engineering that they are copying answers straight from the LLMs, maybe they would be happier in a different major? They are certainly smart enough to be mechanical engineers, but are they interested?\n\nBut milder uses are also sometimes problematic. Many students claim they use AI “just to get started” or “just when stuck”. Getting started on problems and getting unstuck is like 95% of the learning that occurs on the homework! I actually care less about the algebra that happens once you see the path forward. Finding the path forward is the hard part. As mentioned above: understanding an answer is very different from being able to produce an answer.\n\nIf you are interested, you can read about \n\nBloom’s Taxonomy, which is a framework for understanding how students master a topic. Studying LLM solutions may help you with “knowledge” and “comprehension”, the lower levels of the taxonomy. (“Ah that is how to format the inputs” -- that is indeed a good, useful lesson.) It will not help you get better at the “application”, “analysis”, “synthesis”, or “evaluation” levels, and those are the actually interesting parts of engineering that you are hopefully excited to do.","type":"content","url":"/responsible-ai#ai-misuse","position":5},{"hierarchy":{"lvl1":"Responsible use of AI","lvl2":"AI Reasonable Use"},"type":"lvl2","url":"/responsible-ai#ai-reasonable-use","position":6},{"hierarchy":{"lvl1":"Responsible use of AI","lvl2":"AI Reasonable Use"},"content":" It is my assessment that, overall, LLMs are plagiarism machines. It's just that they go word-by-word, statistically, and so it is difficult to point to a single source from which their text was plagiarized. However, when it comes to coding, I have a comforting hypothesis that the LLMs are looking at code documentation (e.g. for [numpy piecewise](https://numpy.org/devdocs/reference/generated/numpy.piecewise.html)) and logicking together the inputs and outputs to achieve a goal. I feel a bit better about that, at least from an ethical standpoint. \n\nIf you want to learn while using an LLM, you must be thoughtful about how you interact with it. I cannot make you be thoughtful -- you must resist the urge to jump to the answer. So here are my recommendations on how to responsibly use AI, if your goal is to actually learn:\n\nDo not go to AI at the beginning. Do not go to AI immediately when you get stuck. Getting stuck and thinking about how to get unstuck is very much an authentic engineering experience and is probably the best way to learn. Reread the problem, think about what information is given, what information is missing that is needed, what assumptions could be made etc.\n\nIf, after a while of being stuck, you have not made much progress, then talk to an AI. But write it in your own words, and try to be specific about the issue. “I am trying to write a root-solving algorithm using Newton-Raphson Method. I am stuck trying to figure out when to end the iterations. I suspect I should use a while statement but am confused on how to implement the logic.” Honestly, I don’t think the AI will need all that detail, but this is not about what the AI needs, it is about what you need! You need to get practice with using engineering language to define problems! (This is part of the reason we will have a lot of peer discussion in our \n\nflipped classroom.)\n\nIf you find yourself prompting incrementally, asking the AI to help with every step, pause. Review your notes, review the steps you’ve taken so far, and try to at least speculate about what is next. If you are being given every step, you probably are not learning!\n\nWhen you get towards the end, you might encounter a cryptic error message, again: try to decipher it on your own, and if you can’t figure it out, ask and be specific. Programming languages/environments are usually decent at explaining where the error occurs, giving a line number and the error type (ValueError, KeyError, etc.). “I get the following error: <whatever the error is>. It seems to be related to my function inputs but I am not sure what the message means.” That is not unreasonable, and again, you put some thought into it instead of just asking it to bail you out.\n\nDebugging via AI is a valid use, though I believe developing an eye for debugging is a very valuable skill. Try for a minute to debug on your own, but I get it: AI might save us from spending 90 minutes hunting for some tiny thing.\n\nWhenever you are “done”, don’t be done. Interpret the result yourself, decide if it makes sense, think about the steps it took to get there and the decisions that you needed to make along the way.\n\nTip\n\nIf you would be ashamed to show your instructor your prompts, you are probably misusing AI.\n\nWarning\n\nThe inputs to LLMs become part of its training data and thus that information essentially becomes public. You may be in a situation where your organization has an agreement with a particular LLM company to not use the data for training, but I would in general be very careful about what you share. Indeed, in your job, you may be prohibited from sharing proprietary information like diagrams, performance metrics, or computer code with LLMs. You need to practice talking about the big ideas and then implementing the specifics locally, without giving away company secrets to LLMs!\n\nCU seems to have an agreement with Google Gemini where our chats do not go to training their models. (I am not sure if students have the same access as faculty?)","type":"content","url":"/responsible-ai#ai-reasonable-use","position":7},{"hierarchy":{"lvl1":"Programming Basics -- Introduction"},"type":"lvl1","url":"/intro","position":0},{"hierarchy":{"lvl1":"Programming Basics -- Introduction"},"content":"One common concern about this course is that it requires you to learn math and a new programming language at the same time. Or at least it did... part of the reason we started offering MCEN 1030 was to deliver more experience in MATLAB/Python. Many of you may have gotten to take that course instead of CSCI 1300. But anyway: I think viewing them as two separate challenges is pessimistic -- the best way to learn to program is to actually do something.\n\nYou all know what if, for, and while do. You know what an array/vector is. You know that you can access the various elements of an array based on their indices. What you may not be certain about is: how exactly does that look in MATLAB/Python/Julia? Should you begin a function with function or is it something else? Do you have to end an if statement? In previous semesters I spent time going through these things in class, with students copying what I wrote and then confirming they get the same output. In retrospect, I am suspicious that this was a waste of time... so passive for students! It probably did not stick! Better will be to dive in and actually start doing things.\n\nIn the first week of this course, you will:\n\n... \n\ndecide which programming language to use this semester, and \n\nget it going on your machine.\n\n... explore some tasks using some references I have created about \n\nbasic mathematical commands.\n\n... become familiar with \n\nGitHub. (Kind of optional... you can integrate it with your coding environment if you want, otherwise can just upload via your web browser.)\n\nAdditionally, make sure you have read all the Course Details section, as well as \n\ntips for success.\n\nAgain, I think the best way to learn will be to dive in. Throughout the semester, my goal is to give you the resources and support to do so and succeed. But if you are feeling a bit uncomfortable, no problem -- let’s schedule an office hour and we can talk about it.","type":"content","url":"/intro","position":1},{"hierarchy":{"lvl1":"Classes"},"type":"lvl1","url":"/classes","position":0},{"hierarchy":{"lvl1":"Classes"},"content":"In our \n\n2D Newton-Raphson Method code, we could write a function that includes, as inputs, (f,g,dfdx,dfdy,dgdx,dgdy,...) a lot of little functions (either anonymous or full).\n\nAn interesting alternative is to pass one thing called, say, F, that includes within it all of those little functions. (So it would be (F,...) instead!) Then we could define the model entirely within F, and pass that whole model to a general 2D Newton-Raphson code. This is exactly what we can do with “classes” -- it’s going to really clean up our code, everything will be packaged together nicely!","type":"content","url":"/classes","position":1},{"hierarchy":{"lvl1":"Classes","lvl2":"Classes"},"type":"lvl2","url":"/classes#classes","position":2},{"hierarchy":{"lvl1":"Classes","lvl2":"Classes"},"content":"Let’s just dive-in with an example.\n\nWe are going to define a class below called LineCircle that could be used in a \n\n2D Newton-Raphson Method problem -- “find where this line intersects this circle”. (I made up the name LineCircle, could have called it BroccoliRabe and everything would be the same.) The set of properties, constructor, and collection of methods could be modified to apply to any system of two equations, and adding more things to this class would allow us to apply the algorithm to a 3D system (though, unless we are really thoughtful, it would probably require a different Newton-Raphson code).\n\nFor our purposes:\n\nproperties\n\n... are parameters in the problem. For this problem we will have m and b for the line and R for the radius -- they are just constants.\n\nthe constructor\n\n... is how we create a new variable that is of this class. Here, we provide values for m, b, and R when initializing a variable.\n\nmethods\n\n... are tasks or functions associated with the class. For example, we could have a method that calculated the area of the circle (based on R). Here, we will calculate f(x,y), g(x,y), \\partial f/\\partial x(x,y), \\partial f/\\partial y(x,y), \\partial g/\\partial x(x,y), and \\partial g/\\partial y(x,y). Additionally, let’s go ahead and create the Jacobian Matrix as an additional method, which notably will call on the other methods!\n\nNote: class definitions in MATLAB must occur in their own file, similar to how we define functions. The class name must match the file name. Alternatively: it can be defined at the bottom of another file (like a local function).classdef LineCircle\n    properties\n        m % These three parameters will be\n        b % set whenever we create a variable\n        R % of this class.\n    end\n    \n    methods\n        % the \"constructor\"\n        function obj      = LineCircle(m_in,b_in,R_in)\n            % obj is a generic way for the class to\n            % reference itself\n            obj.m=m_in;\n            obj.b=b_in;\n            obj.R=R_in;\n        end\n        \n        % and the remaining methods are the tasks we'd\n        % like to be built-in to the class\n        function f_out = f(obj,x,y)\n            % m*x+b-y\n            f_out=obj.m*x+obj.b-y; \n        end\n\n        function g_out    = g(obj,x,y)\n            % x^2 + y^2 - R^2\n            g_out= x.^2+y.^2-(obj.R)^2;\n        end\n\n        function dfdx_out = dfdx(obj, x, y)\n            % this derivative is just m\n            dfdx_out=obj.m;\n        end\n        \n        function dfdy_out = dfdy(obj, x, y)\n            % for this problem it's just -1\n            dfdy_out=-1;\n        end\n\n        function dgdx_out = dgdx(obj, x, y)\n            dgdx_out=2*x;\n        end\n\n        function dgdy_out = dgdy(obj, x, y)\n            dgdy_out=2*y;\n        end\n\n    end\nend\n\nWith this class defined (in it’s own file called LineCircle.m), we can then create a new variable in this class based on the properties and can access those properties using an F.something. And, usefully, we can pass F to a function. That is, we can input (F,...) instead of (f,g,dfdx,dfdy,dgdx,dgdy,...).F = LineCircle(1,0,1);\n\n[A_F,B_F]=a_fxn(F,1,0)\n% unsuppressed for a lazy print\n\nfunction [A,B]=a_fxn(F,x_0,y_0)\n    A=F.dfdx(x_0, y_0);\n    B=F.g(x_0,y_0);\nend\n\n\nWith Python, we can have the class definition and script within the same file. With the class defined, we can create a new variable in the class based on the properties using an F.something. And, usefully, we can pass F to a function. That is, we can input (F,...) instead of (f,g,dfdx,dfdy,dgdx,dgdy,...).class LineCircle:\n    def __init__(self, m_in, b_in, R_in):\n        \"\"\"\n        The constructor and property definitions. \n        Must use \"self\" to refer to itself\n        \"\"\"\n        self.m = m_in\n        self.b = b_in\n        self.R = R_in\n    \n    # the useful functions:\n    def f(self, x, y):\n        return self.m * x + self.b - y\n        \n    def g(self, x, y):\n        return x**2 + y**2 - self.R**2\n        \n    def dfdx(self, x, y):\n        return self.m\n        \n    def dfdy(self, x, y):\n        return -1\n        \n    def dgdx(self, x, y):\n        return 2 * x\n        \n    def dgdy(self, x, y):\n        return 2 * y\n\ndef a_fxn(F, x_0, y_0):\n    A=F.dfdx(x_0, y_0)\n    B=F.g(x_0,y_0)\n    return A, B\n\n# Script Execution\nF = LineCircle(1, 0, 1)\nA_F, B_F = a_fxn(F, 1, 0)\nprint(f\"A = {A_F}, B = {B_F}\")\n\nAnd, again, we can use F as a function input.\n\nJulia does not have “classes” -- a “structure” serves a similar purpose. I’ll be honest... not sure what the difference is, other than this looks inside-out when compared to the other two languages. If you figure out another way let me know!\n\nWe will define both the model and function within something called a module that contains a struct and the function, and then call it from a script below using the module name. (The .someProject is necessary because they are in the same file, I think?)module someProject\n\nexport LineCircle, a_fxn # things we'd like to use outside this module\n\nstruct LineCircle\n    m::Float64\n    b::Float64\n    R::Float64\nend\n\n# Define the model functions\nf(obj::LineCircle, x, y)    = obj.m * x + obj.b - y\ng(obj::LineCircle, x, y)    = x^2 + y^2 - obj.R^2\ndfdx(obj::LineCircle, x, y) = obj.m\ndfdy(obj::LineCircle, x, y) = -1.0\ndgdx(obj::LineCircle, x, y) = 2x\ndgdy(obj::LineCircle, x, y) = 2y\n\nfunction a_fxn(F::LineCircle, x_0, y_0)\n    A=dfdx(F, x_0, y_0)\n    B=g(F,x_0,y_0)\n    return A,B\nend\n\nend # of the module\n\n# Script\nusing .someProject\n\nF = LineCircle(1.0, 0.0, 1.0) # m, b, R\nA_F, B_F = a_fxn(F, 1.0, 0.0)\nprintln(\"A = $A_F, B = $B_F\")\n\nI encountered a bit of an annoynace... within a single REPL session, the module cannot be overwritten once imported. I just restarted the REPL but there are other workarounds.\n\nHint\n\nWe will probably come back to this structure when solving coupled differential equations, defining different functions in that case.","type":"content","url":"/classes#classes","position":3},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB"},"type":"lvl1","url":"/coding-elements-matlab","position":0},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB"},"content":"MATLAB is the default option for MCEN 3030 and has been the (one) language used for this class since before my time. We are opening the door to other languages, but I still expect MATLAB, which is tightly intertwined with engineering education, will have the greatest number of users in this class.\n\nMATLAB is made for math, so, for example, the solution to “the linear algebra problem” \\mathbf{A}\\cdot\\mathbf{x}=\\mathbf{b} is b=inv(A)*x or b=A\\x.","type":"content","url":"/coding-elements-matlab","position":1},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Functions"},"type":"lvl2","url":"/coding-elements-matlab#functions","position":2},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Functions"},"content":"Let’s just give an example and talk about it. Here are the contents of one file, with a “local function” included below it (described below).function [out1,out2]=my_fxn(in1,in2)\n    x=[in1,in2];\n    out1=my_local_fxn(x);\n    out2=in2+3;\nend\n\nfunction b=my_local_fxn(x)\n    b=mean(x);\nend\n\nAnd here are a few things that you might try in a separate script file, or as an input in the command window:my_fxn(4,5)\n\na=my_fxn(4,5)\n\n[a,b]=my_fxn(4,5)\n\nmy_local_fxn([4,5,6])\n\n\nSome things you will notice:\n\nmy_fxn(4,5) works, but produces only one output. a=my_fxn(4,5) works, but you only get the first output (saved as a).\n\nTo get both outputs, you must “warn” MATLAB that two are coming. So the second command, [a,b]=my_fxn(4,5) is how to get both outputs.\n\nmy_local_fxn([4,5,6]) produces an error: Unrecognized function or variable 'my_local_function'.\n\nWhen calling a function, the output variables don’t need to be the same as those in the function declaration. Here: a and b are perfectly fine names -- we don’t need to save them as out1 and out2.\n\nThe Rules:\n\nCallable functions must have, as their first line, [output variables] = function_name(input variables), and the file must be called function name.m.\n\nSuch functions can be called as long as you are in the same working directory -- if that *.m file is in the folder you currently have open in MATLAB.\n\nThe local function my_local_fxn cannot be called outside of the file. We can’t call it from a script or other function or the command window -- it is only known “locally” within the main function file my_fxn.m. Local functions are useful if there is a little side quest you need to do within a main function that gets rid of some clutter.\n\nA consequence of the above: there is only one “main” function per *.m file. This is one of the most annoying things about MATLAB.\n\nBy default, MATLAB only returns the first output if you simply call the function. In order to retrieve the other output variables, you need to “warn” MATLAB that more are coming by defining variables where they will be stored.","type":"content","url":"/coding-elements-matlab#functions","position":3},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Creating vectors/matrices/arrays"},"type":"lvl2","url":"/coding-elements-matlab#creating-vectors-matrices-arrays","position":4},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Creating vectors/matrices/arrays"},"content":"x1=0:0.1:2;                 % start:step:stop\nx2=linspace(0,10,500);      % 500 points between 0 and 10\nx3=logspace(4,7,500);       % 500 log-spaced points between 10^4 and 10^7\nA=[[1,2,3];[4,5,6]];        % a matrix is an array of arrays with rows separated by ;\n\ny=zeros(1,length(x2));      % a row vector full of zeros with the same length as x2\nz=ones(1,length(x2));       % same, but full of ones\nA=zeros(4,4);               % a 4x4 matrix of zeros\nB=eye(4);                   % diagonal is full of ones, rest zero\nD=diag([5,3,1]);            % diagonal is 5,3,1, rest zero\nD2=diag([5,3,1],1);         % the first diagonal above the main is [5,3,1]... so this is a 4x4 matrix\n\nr=rand(1,5);                % a row vector with 5 random numbers, uniformly spaced between 0 and 1\nR=rand(4,4);                % same, but a 4x4 matrix","type":"content","url":"/coding-elements-matlab#creating-vectors-matrices-arrays","position":5},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Indexing and Modifying Elements"},"type":"lvl2","url":"/coding-elements-matlab#indexing-and-modifying-elements","position":6},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Indexing and Modifying Elements"},"content":"MATLAB indexes from 1 and can use end to refer to the last index. Be careful when talking to Python folks, your “first” element might be their “zeroth”.x(i)=5;                     % changes the ith element of x (x would need to exist already)\nx(3:end)=0;                 % elements 3 to the end all become 0\nx(2:4)=-88;                 % the second, third, and fourth elements become -88\n\nA(4,1)=5;                   % change the fourth element in column 1\nA(:,5)=6;                   % the fifth column is a vector... this makes all those elements equal 6\nA(4,:)=-9;                  % the fourth row is now full of -9s","type":"content","url":"/coding-elements-matlab#indexing-and-modifying-elements","position":7},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Doing math with them"},"type":"lvl2","url":"/coding-elements-matlab#doing-math-with-them","position":8},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Doing math with them"},"content":"MATLAB uses “dot star” .* and similar to do element-by-element math, which is mostly what we will be doing in this class.x=[1, 2, 3];\ny=[4, 5, 6];\nz=x.*y;\n\nFrom the above code, we would find z=[4, 10, 18]. To square all elements, .^2, to divide element-by-element, x./y. No dot is needed for addition and subtraction.\n\nCommon mathematical functions work element-by-element on arrays: sin(x), exp(x), log(x) is the natural log, log10(x) is the base-10 log, sqrt(x) for square root. sin, cos, tan, etc.","type":"content","url":"/coding-elements-matlab#doing-math-with-them","position":9},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Conditional Statements"},"type":"lvl2","url":"/coding-elements-matlab#conditional-statements","position":10},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Conditional Statements"},"content":"Here is the if-elseif-else structure:if x<5\n    y=10;\nelseif x>9\n    y=15;\nelse\n    y=-99;\nend\n\nThe “logical equals” is == (as in, x==5 checks to see if x is equal to 5, evaluating that as True/False or 1/0). The logical and is &&, the logical or is ||, and >= and <= work as you’d expect! “Not equals” is ~=.","type":"content","url":"/coding-elements-matlab#conditional-statements","position":11},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Loops"},"type":"lvl2","url":"/coding-elements-matlab#loops","position":12},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Loops"},"content":"A while loop looks like this:counter=0;\nwhile counter<5\n    display('hi')\n    counter=counter+1;\nend\n\nand a for loop looks like this:x=[1,2,3];\nS=0;\nfor i=1:length(x)\n    S=S+x(i);\nend","type":"content","url":"/coding-elements-matlab#loops","position":13},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Reading/Writing Spreadsheets"},"type":"lvl2","url":"/coding-elements-matlab#reading-writing-spreadsheets","position":14},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Reading/Writing Spreadsheets"},"content":"It is common to use *.csv files: comma-separated values. You may be able to load from other sources, but csv will be our standard because of the predictability of the formatting.\n\nTo read in a csv and store the data as a matrix: data = readmatrix('my_data.csv');. (From there you can get individual columns via x_data=data(:,1) etc.)\n\nTo write a new csv: writematrix([x_data, y_data], 'data.csv'); creates a new file in your current directory called “data.csv”.","type":"content","url":"/coding-elements-matlab#reading-writing-spreadsheets","position":15},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Anonymous Functions"},"type":"lvl2","url":"/coding-elements-matlab#anonymous-functions","position":16},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Anonymous Functions"},"content":"In our root-finding algorithms, we will input a (mathematical) function into a (programming) function, e.g.: find the root of f(x)=\\sin(x)-0.85. This can be achieved via an anonymous function: f=@(x) sin(x)-0.85;.\n\nIf two inputs are needed: f=@(x,y) x+y;.","type":"content","url":"/coding-elements-matlab#anonymous-functions","position":17},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"break, continue, and return"},"type":"lvl2","url":"/coding-elements-matlab#break-continue-and-return","position":18},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"break, continue, and return"},"content":"When you are within a loop, break immediately breaks you out of the loop entirely. So, for example:for i=1:5\n    if i==3\n        break\n    end\nend\ndisplay(i)\n\nYou should see that i is 3.\n\nWhen you are within a loop, continue immediately sends you back to the top of the loop. So, for example:S=0;\nfor i=1:5\n    if i==2 || i==3\n        continue\n    end\n    S=S+1;\nend\ndisplay(S)\n\nYou should see that S is 3.\n\nAnywhere within a function, a return functions as an end, and outputs the current values of the output variables. So, for example:function y=my_fxn(x)\n    if x==0\n        y=0;\n        return\n    end\n    y=15;\nend\n\nIf you call the function with my_fxn(0), it should return 0. If you call it with any other number, say my_fxn(1), it should return 15.","type":"content","url":"/coding-elements-matlab#break-continue-and-return","position":19},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Some common motifs"},"type":"lvl2","url":"/coding-elements-matlab#some-common-motifs","position":20},{"hierarchy":{"lvl1":"Necessary Coding Elements -- MATLAB","lvl2":"Some common motifs"},"content":"If you need something to happen if a number is even:if mod(x,2)==0  % even!\n    % do something\nelse            % odd!\n    % do something else\nend\n\nTo calculation a summation, initialize the sum at zero:N=15;       % how many terms to include\nS=0;        % initialize the sum at zero\nfor n=1:N\n    S=S+sin(n);\nend\n\nMATLAB has built-in functions: isnan, which checks if a number is NaN (“not a number”); and isinf, which checks if a number is Inf. NaN and Inf are different in MATLAB:isnan(15)  % returns 0 because 15 IS a number\nisnan(1/0) % returns 0 because MATLAB interprets Inf as a number\nisnan(0/0) % returns 1\nisinf(15)  % returns 0\nisinf(1/0) % returns 1\nisinf(0,0) % returns 0","type":"content","url":"/coding-elements-matlab#some-common-motifs","position":21},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia"},"type":"lvl1","url":"/coding-elements-julia","position":0},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia"},"content":"If you are interested in computational science, you might find Julia to be an interesting language. Maybe you’d like to read this: \n\nJulia: A Fresh Approach to Numerical Computing.\n\nThe considerations outlined in that paper are not important to MCEN 3030, but, if you have the appetite for it, you could spend MCEN 3030 building up some relevant experience in some basic tasks, and then can expand to more cutting-edge things on the side or after the course has concluded.\n\nThere are a lot of extra considerations with Julia that will make it challenging for those who are unfamiliar with the vocabulary of computer science -- you will need to be more careful with data types and variable scope, as examples. For this reason, I think I’d like to chat with you before you commit to this language. Everyone in the class could use it and would be fine, but I just want to make sure the juice is worth the squeeze (for your situation). That being said, I would be really interested to get some more experience myself with a handful of brave students.\n\nJulia is famous for “multiple dispatch” which is something we will not really have an opportunity to explore in this class. However, you may independently explore this, and tell me about it!","type":"content","url":"/coding-elements-julia","position":1},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Functions"},"type":"lvl3","url":"/coding-elements-julia#functions","position":2},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Functions"},"content":"Here is a file with a couple functions in it, and a couple function calls:function my_first_fxn(a, b)\n    c = a + b\n    return c\nend\n\nfunction my_second_fxn(a, b)\n    c = a - b\n    d = 2 * a\n    return c, d \nend\n\nC_1 = my_first_fxn(3, 2)\nC_2, D_2 = my_second_fxn(3, 2)\n\nThe Rules:\n\nFunctions begin with a line that includes function, a function name, and the input variables(/arguments).\n\nThe output of the function is whatever follows the return. Could be one number or one array or multiple numbers or multiple arrays. An end must be included as well -- it’s a bit clumsy.\n\nThere is something called “implicit return”, where the last thing that is evaluated is the thing that is returned. Probably being explicit (as we are above) is the more careful thing to do.\n\nIf there are multiple outputs, you must “prepare” your script for them, as I did above with the C_2,D_2=.","type":"content","url":"/coding-elements-julia#functions","position":3},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Creating vectors/matrices/arrays"},"type":"lvl3","url":"/coding-elements-julia#creating-vectors-matrices-arrays","position":4},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Creating vectors/matrices/arrays"},"content":"x1 = 0:0.1:2                      # start:step:stop (creates a range object)\nx2 = range(0, 10, length=500)     # 500 points between 0 and 10\nx3 = 10 .^range(4, 7, length=500) # 500 log-spaced points between 10^4 and 10^7\nA = [1 2 3; 4 5 6]                # a matrix is built with spaces separating columns and semicolons separating rows\n\ny = zeros(1, length(x2))    # a row vector full of zeros with the same length as x2\nz = ones(1, length(x2))     # same, but full of ones\nA = zeros(4, 4)             # a 4x4 matrix of zeros\n\nusing LinearAlgebra         # Required for eye (I) and diag functions\nB = Matrix(1.0I, 4, 4)      # diagonal is full of ones, rest zero\nD = diagm(0 => [5, 3, 1])   # diagonal is 5,3,1, rest zero\nD2 = diagm(1 => [5, 3, 1])  # the first diagonal above the main is [5,3,1]... so this is a 4x4 matrix\n\nr = rand(1, 5)              # 1x5 row matrix of random numbers\nR = rand(4, 4)              # same, but a 4x4 matrix","type":"content","url":"/coding-elements-julia#creating-vectors-matrices-arrays","position":5},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Indexing and Modifying Elements"},"type":"lvl3","url":"/coding-elements-julia#indexing-and-modifying-elements","position":6},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Indexing and Modifying Elements"},"content":"Julia indexes from 1 and can use end to refer to the last index. Be careful when talking to Python folks, your “first” element might be their “zeroth”. (MATLAB indexes from 1.)\n\nJulia is consistent with the following rule: if it applies to multiple elements, the operation is “dot something”. Both MATLAB and Julia have the .^ and .* for element-by-element math, but Julia has the peculiar .= when setting multiple values of an array. It makes sense, if you think about it, but also I am not sure if x[3:end]=0 (which is how MATLAB would do it) is actually that ambiguous!x[i] = 5                    # changes the ith element of x (x would need to exist already)\nx[3:end] .= 0               # elements 3 to the end become 0\nx[2:4] .= -88               # elements 2, 3, and 4 becomes -88\n\nA[4, 1] = 5                 # changes the fourth element in column 1\nA[:, 5] .= 6                # the fifth column is a vector... this makes all of those elements equal 6\nA[4, :] .= -9               # the fourth row is now full of -9s","type":"content","url":"/coding-elements-julia#indexing-and-modifying-elements","position":7},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Doing math with them"},"type":"lvl3","url":"/coding-elements-julia#doing-math-with-them","position":8},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Doing math with them"},"content":"x=[1, 2, 3]         # with commas... this creates a column vector\ny=[4, 5, 6]\n# the same without commas would create a row vector\nz=x.*y\n\nFrom the above code, we would find z=[4, 10, 18]. To square all elements, .^2, to divide element-by-element, x./y. No dot is needed for addition and subtraction.\n\nThe “dot something” structure applies to basic mathematical functions too, which is kind of annoying: sin.(x), exp.(x), log.(x) is the natural log, log10.(x) is the base-10 log, sqrt.(x) for square root. sin, cos, tan, etc., are a similar pattern.","type":"content","url":"/coding-elements-julia#doing-math-with-them","position":9},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Conditional Statements"},"type":"lvl3","url":"/coding-elements-julia#conditional-statements","position":10},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Conditional Statements"},"content":"Here is the if-elseif-else structure:if x<5\n    y=10\nelseif x>9\n    y=15\nelse\n    y=-99\nend\n\nThe “logical equals” is == (as in, x==5 checks to see if x is equal to 5, evaluating that as True/False or 1/0). The logical and is &&, the logical or is ||, and >= and <= work as you’d expect! “Not equals” is !=.\n\nJulia has something called “the ternary operator”, which is a succinct way to write a “condition, value if true, value if false” statement: y = x < 5 ? 10 : -99.","type":"content","url":"/coding-elements-julia#conditional-statements","position":11},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Loops"},"type":"lvl3","url":"/coding-elements-julia#loops","position":12},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Loops"},"content":"A while loop looks like this:counter = 0\nwhile counter < 5\n    println(\"hi\")\n    counter += 1\nend\n\n...but for loops (and maybe while too, in another application?) have a “gotcha”: variables within a for loop have scope limited to within the loop, by default (and maybe only within scripts or the REPL?). Declaring the variables global is necessary to adjust them overall. So:x = [1, 2, 3]\nS = 0\nfor i in 1:length(x)\n    global S = S + x[i]\nend\n\n... has that global declaration, which is not needed in MATLAB/Python. However, wrapping the summation in a function eliminates the need:function sum_em(z)\n    S=0\n    for z_i in z\n        S += z_i  # No 'global'\n    end\n    return S\nend\n\nx = [1, 2, 3]\nS=sum_em(x)\n\nWe will end up using for loops a lot in this class, and so this will be something to keep an eye out for.","type":"content","url":"/coding-elements-julia#loops","position":13},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Reading/Writing Spreadsheets"},"type":"lvl3","url":"/coding-elements-julia#reading-writing-spreadsheets","position":14},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Reading/Writing Spreadsheets"},"content":"It is common to use *.csv files: comma-separated values. You may be able to load from other sources, but csv will be our standard because of the predictability of the formatting.\n\nIn Julia, some additional packages are necessary: CSV.jl and DataFrames.jl. (I haven’t tried this yet but apparently both are needed?) And then the beginning of your script will beusing CSV\nusing DataFrames\n\n# This reads the file into a \"DataFrame\" (similar to a MATLAB Table)\ndf = CSV.read(\"my_data.csv\", DataFrame)\n\n# Convert the DataFrame to a plain Matrix\ndata = Matrix(df)\n\n# OR: Read it directly as a matrix without headers\ndata = CSV.read(\"my_data.csv\", Tables.matrix)\n\nTo write a csv:using CSV\n\nx_data = [1, 2, 3]\ny_data = [10, 20, 30]\n\n# [x_data y_data] creates a matrix with two columns\ndata_matrix = [x_data y_data]\n\n# Write to file (header is optional)\nCSV.write(\"data.csv\", Tables.table(data_matrix), header=[\"X\", \"Y\"])\n\nThere is also a built-in option that, for whatever reason, is discouraged: using DelimitedFiles then data = readdlm(\"my_data.csv\", ',') would load-in data, and writedlm(\"data.csv\", data_matrix, ',') would write a new csv.","type":"content","url":"/coding-elements-julia#reading-writing-spreadsheets","position":15},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Anonymous Functions"},"type":"lvl3","url":"/coding-elements-julia#anonymous-functions","position":16},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Anonymous Functions"},"content":"In our root-finding algorithms, we will input a (mathematical) function into a (programming) function, e.g.: find the root of f(x)=\\sin(x)-0.85. This can be achieved via an anonymous function: f = x -> sin(x) - 0.85 or f(x) = sin(x) - 0.85. And remember: to use a function with an array we use the “dot something” structure: f.([1,2,3]).\n\nIf two inputs are needed: f = (x, y) -> x + y or f(x,y) = x+y.","type":"content","url":"/coding-elements-julia#anonymous-functions","position":17},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl2":"break, continue, and return"},"type":"lvl2","url":"/coding-elements-julia#break-continue-and-return","position":18},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl2":"break, continue, and return"},"content":"When you are within a loop, break immediately breaks you out of the loop entirely. So, for example:S=0\nfor i in 1:500\n    if i==5\n        break\n    end\n    global S+=1\nend\nprintln(S)\n\nYou should see that S is 4.\n\nWhen you are within a loop, continue immediately sends you back to the top of the loop. So, for example:S=0\nfor i in 1:5\n    if i==2 || i==3\n        continue\n    end\n    global S+=1\nend\nprintln(S)\n\nYou should see that S is 3.\n\nYou can return from anywhere in a function. So, for example:function my_fxn(x)\n    if x==0\n        return 0\n    end\n    return 15\nend\n\nprintln(my_fxn(0))\nprintln(my_fxn(1))\n\nYou should see that the first print produces 0, the second produces 15.","type":"content","url":"/coding-elements-julia#break-continue-and-return","position":19},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Some common motifs","lvl2":"break, continue, and return"},"type":"lvl3","url":"/coding-elements-julia#some-common-motifs","position":20},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Some common motifs","lvl2":"break, continue, and return"},"content":"If you need something to happen if a number is even:if x % 2 == 0  # Even!\n    # do something\nelse           # Odd!\n    # do something else\nend\n\n... but actually Julia has built-in commands: iseven(x) and isodd(x).","type":"content","url":"/coding-elements-julia#some-common-motifs","position":21},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"A few frustrations","lvl2":"break, continue, and return"},"type":"lvl3","url":"/coding-elements-julia#a-few-frustrations","position":22},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"A few frustrations","lvl2":"break, continue, and return"},"content":"A few frustrations I have encountered (and most of these are likely just because I am more used to MATLAB/Python, which are more novice-friendly):\n\ny = x will assign y to the same memory location as x, which means that changing x[1] also changes y[1]. If you need to make a genuine copy that can be independently modified: y=copy(x).\n\nMeanwhile, slicing an array makes a copy automatically. z=x[2:end] creates an independent array, z that is not tied to x.\n\nKeep an eye on the variable scope within for loops.\n\nThe compile times within VS Code (on the few functions I have written... I am learning too!) have been borderline unnoticeable, just a 2-3 second hiccup the first time you run after major changes. Second time, fast. For MCEN 3030, with our smaller functions, this may be a bit of a frustration... until we get to the machine learning project, where I am hopeful compiling will knock the training time down considerably. It is not awful in Python... I am doing a project where it might take 40 seconds to train the model, but I wonder if I switched over to Flux, would be like 5 seconds? I’ll be interested to see!","type":"content","url":"/coding-elements-julia#a-few-frustrations","position":23},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Additional resources/readings","lvl2":"break, continue, and return"},"type":"lvl3","url":"/coding-elements-julia#additional-resources-readings","position":24},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Julia","lvl3":"Additional resources/readings","lvl2":"break, continue, and return"},"content":"https://​github​.com​/brenhinkeller​/JuliaAdviceForMatlabProgrammers","type":"content","url":"/coding-elements-julia#additional-resources-readings","position":25},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Overview"},"type":"lvl1","url":"/coding-elements-overview","position":0},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Overview"},"content":" **Author:** Jeremy Koch<sup>1,2</sup> \\ \n\nThis course is less about using built-in functions like fsolve and more about understanding the algorithms. Truthfully, nearly all of the necessary coding elements to write all the functions in this course appear on these pages -- indexing x[i] or x(i); if, for, while; you’ll need to do some space preallocation, maybe with something built-in called zeros; might need to use the modulus function, e.g. to determine if a number is odd or even, maybe a little random-number generation... not much else.\n\nCaution\n\nDon’t stare at any of these lists in hopes of memorizing them. Instead, treat them as reference lists early in the semester, and after putting these commands into action a few times you will find that you indeed memorized a lot of them.\n\nDon’t forget that you have the AI green-light for homework... asking “how do I make a for loop in julia” is a really reasonable prompt for Google or an LLM, akin to just looking it up on a reference list like this! (Much more \n\nresponsible than just pasting the problem description and copying the result!)\n\nNecessary Coding Elements -- MATLAB\n\nNecessary Coding Elements -- Python\n\nNecessary Coding Elements -- Julia\n\nIn addition to basic commands like how to create an array, each of the above links describes scripts, functions, and “anonymous functions”.\n\nScript\n\nWe will take this to mean a coding file with simple instructions that don’t require much overhead. For example: make a list of numbers between 0 and 50, use them in a function, and print the results. This takes three lines of code in a *.m, *.py, or *.jl file... no need for any formal “main function” declarations, just go through the steps in that script, in order. For our purposes, MATLAB, Python, and Julia are scripting languages, though that label is controversial for Julia because it is compiled.\n\nFunction\n\nThese turn inputs into outputs according to a set of rules. Functions require a formal declaration, the structure of which is basically the same in all languages: give a function name, input variables, and return the outputs. We “call” functions from scripts or other functions.\n\nAnonymous Function\n\nMATLAB, Python, and Julia all have a way of writing small functions that are not stored under a traditional function name (hence the moniker “anonymous”). They are still stored under a variable name. When part of a project’s foundational architecture, this type of function definition is discouraged (one reason: it makes tracing errors difficult because the functions are not named in the error messages). However, within scripting languages, it is often a really nice tool to create an equation function for use in our algorithms like f(x) = \\ln{(\\sin(x))}. As an example: f=@(x) log(sin(x)) (in MATLAB). You can then pass f as an argument into a function!","type":"content","url":"/coding-elements-overview","position":1},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Overview","lvl2":"Some common motifs"},"type":"lvl2","url":"/coding-elements-overview#some-common-motifs","position":2},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Overview","lvl2":"Some common motifs"},"content":"Don’t “hard-code” in numbers if you can avoid it! It will make your code more flexible, readable, and easier to debug. For example, in MATLAB:x=1:100;\ny=1:100;\nfor i=1:100          \n    % are we iterating through x or y?\n    % If we have to change whichever of them to 1:500, we'd have to change our \"for\" line above\nend\n\n% this is better\nfor i=1:length(y)\n    % now we know it is iterating through y\n    % and if we change to y=1:500, it automatically is ready to go!\nend","type":"content","url":"/coding-elements-overview#some-common-motifs","position":3},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python"},"type":"lvl1","url":"/coding-elements-python","position":0},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python"},"content":"“Native Python” lists like x=[1,2,3,4] do not cooperate well with mathematical operations. Instead, we are going to turn everything into NumPy arrays, and so the first line in almost every code you write will be import numpy as np. (The standard alias is np, I encourage that use.)\n\nThe standard plotting package is matplotlib. The second line in your code will probably be import matplotlib.pyplot as plt, and the basic plotting command is plt.plot(x,y) followed by plt.show().\n\nMany of the tools we will build -- differential equation solvers, numerical integrators, ... -- can be found in the SciPy package. I would recommend installing that package as well. However, remember that we are building our own tools this semester: if you start some code with from scipy.optimize import curve_fit, you are doing it wrong! But maybe these would be good checks against your code, and maybe we will explore them sometime during the course.","type":"content","url":"/coding-elements-python","position":1},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Functions"},"type":"lvl2","url":"/coding-elements-python#functions","position":2},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Functions"},"content":"Here is a file with a couple functions in it, and a couple function calls:def my_first_fxn(a,b):\n    c=a+b\n    return c\n\ndef my_second_fxn(a,b):\n    c=a-b\n    d=2*a\n    return c,d # returns two things\n\nC_1=my_first_fxn(3,2)\nC_2,D_2=my_second_fxn(3,2)\n\nThe Rules:\n\nFunctions begin with a line that includes def, a function name, and the input variables(/arguments). (Optional arguments are easy to do in Python -- see below.)\n\nThe output of the function is whatever follows the return. Could be one number or one array or multiple numbers or multiple arrays.\n\nIf there are multiple outputs, you must “prepare” your script for them, as I did above with the C_2,D_2=.\n\nMany functions can be included in the same file, and they can be imported into another file in the working directory -- this is basically what is going on with the import numpy stuff! The way to do it: if the file is called some_fxns.py you could do: import some_fxns as sf and then the call would look like C_1=sf.my_first_fxn(3,2).","type":"content","url":"/coding-elements-python#functions","position":3},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl3":"Optional Arguments","lvl2":"Functions"},"type":"lvl3","url":"/coding-elements-python#optional-arguments","position":4},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl3":"Optional Arguments","lvl2":"Functions"},"content":"Python allows for easy use of optional arguments -- an idea that is technically possible in MATLAB, but very clumsy. (Julia does optional arguments well too.)\n\nOptional arguments are really neat and relevant to MCEN 3030: in most cases the answers we get will be approximate, and we have to make a judgment about what is close enough; or we have to put our foot down and say our iterations need to stop because we are not going to get the answer. Two metrics that would help us here are an acceptable convergence -- as in, if our last two iterations were basically the same, let’s call it good -- and a maximum number of iterations -- as in, we’ve gone through this algorithm 1000 times, if we aren’t there yet we aren’t going to get there. It is reasonable to have default values for these two metrics, but to allow them to be adjusted if the user desires.\n\nIn Python it would look something like this:def Newton_Raphson1(f,x_0,con_accept=10^-3,max_iter=1000)\n    ...\n    # NR method where the function terminates when the error reaches 10^-3 or 1000 iterations have occurred.\n    ...\n    return x_R\n\n... and the idea is: you can call this function using just two input arguments, f and x_0, and it will assume the default values for the other two arguments. If you’d like to adjust those, you can by calling with, e.g. Newton_Raphson1(g,0,err_accept=10^-2) or Newton_Raphson1(g,0,max_iter=9000) or Newton_Raphson1(g,0,err_accept=10^-2,max_iter=9000).","type":"content","url":"/coding-elements-python#optional-arguments","position":5},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Creating vectors/matrices/arrays"},"type":"lvl2","url":"/coding-elements-python#creating-vectors-matrices-arrays","position":6},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Creating vectors/matrices/arrays"},"content":"import numpy as np                      # almost all your code will need this at the top of the file\n\nx0 = np.array([1, 2, 3])                # a numpy array from a python list\nx1 = np.arange(0, 2.1, 0.1)             # start,stop (EXCLUSIVE!),step\nx2 = np.linspace(0, 10, 500)            # 500 points between 0 and 10\nx3 = np.logspace(4, 7, 500)             # 500 log-spaced points between 10^4 and 10^7\nA  = np.array([[1, 2, 3], [4, 5, 6]])   # a matrix is made up of lists as rows\n\ny  = np.zeros(len(x2))                   # a row vector full of zeros with the same length as x2\nz  = np.ones(len(x2))                    # same, but full of ones\nA  = np.zeros((4, 4))                    # a 4x4 matrix of zeros (note the argument is a \"tuple\")\nB  = np.eye(4)                           # diagonal is full of ones, rest zero\nD  = np.diag([5,3,1])                    # diagonal is 5,3,1, rest zero\nD2 = np.diag([5,3,1],k=1)                # the first diagonal above the main is [5,3,1]... so this is a 4x4 matrix\n\nr  = np.random.rand(5)                   # a row vector with 5 random numbers, uniformly spaced between 0 and 1 (exclusive!)\nR  = np.random.rand(4,4)                 # same, but a 4x4 matrix","type":"content","url":"/coding-elements-python#creating-vectors-matrices-arrays","position":7},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Indexing: Accessing and Modifying Elements"},"type":"lvl2","url":"/coding-elements-python#indexing-accessing-and-modifying-elements","position":8},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Indexing: Accessing and Modifying Elements"},"content":"Python indexes from 0. I like to say that the initial element in an array is the “zeroth” element... be careful when talking to MATLAB/Julia folks about the “first” element, it might be your “zeroth”.x[i]=5             # changes the ith element of x (x would need to exist already)\nx[3:]=0            # elements 3 to the end all become 9 (could have done e.g. [9,10,11]... changes elements 3,4,5)\nx[2:5]=-88         # the second, third, and fourth elements become -88, python excludes the stop index (exclusive!)\nx[-1]=999          # the last element can be indexed as -1 (and the second to last, -2)\n\nA[4,1]=5;          # change the fourth element in column 1\nA[:,5]=5;          # the fifth column is a vector... this makes all elements in that vector =5\nA[4,:]=-9;         # the fourth row is now full of -9s","type":"content","url":"/coding-elements-python#indexing-accessing-and-modifying-elements","position":9},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Doing math with them"},"type":"lvl2","url":"/coding-elements-python#doing-math-with-them","position":10},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Doing math with them"},"content":"Python assumes element-by-element math (mostly what we will be doing in this class) by default, so addition, multiplication, and division of arrays is just x+y, x*y, and x/y. Raising to powers is, controversially x**2 (i.e., that is how we square a number).\n\nNumPy has many built-in mathematical functions that work on arrays: np.exp(x) for the exponential function, np.log(x) is the natural log, np.log10(x) is the base-10 log, np.sqrt(x) gets a square root. np.sin, np.cos, np.tan, etc.","type":"content","url":"/coding-elements-python#doing-math-with-them","position":11},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Conditional Statements"},"type":"lvl2","url":"/coding-elements-python#conditional-statements","position":12},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Conditional Statements"},"content":"Here is the if-elif-else structure:if x<5:\n    y=10\nelif x>9:\n    y=15\nelse:\n    y=-99\n\nPython looks like natural language here: we literally write if x>5 and x<10, and similar with or. >= and <= work as you’d expect!","type":"content","url":"/coding-elements-python#conditional-statements","position":13},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Loops"},"type":"lvl2","url":"/coding-elements-python#loops","position":14},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Loops"},"content":"A while loop looks like this:counter=0;\nwhile counter<5:\n    print('hi')\n    counter=counter+1\n\nnote that no end is needed! Whitespace!\n\nA for reads like natural language:x=np.array([1,2,3]);\nS=0\nfor i in range(x):\n    S=S+x[i]","type":"content","url":"/coding-elements-python#loops","position":15},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Reading/Writing Spreadsheets"},"type":"lvl2","url":"/coding-elements-python#reading-writing-spreadsheets","position":16},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Reading/Writing Spreadsheets"},"content":"It is common to use *.csv files: comma-separated values. You may be able to load from other sources, but csv will be our standard because of the predictability of the formatting.\n\nTo read in a csv and store the data as a matrix: data = np.loadtxt('my_data.csv', delimiter=','). (From there you can get individual columns via x_data=data[:,1] etc.)\n\nTo write a new csv: np.savetxt('data.csv', [x_data,y_data], delimiter=',') creates a new file in your current directory called “data.csv”.","type":"content","url":"/coding-elements-python#reading-writing-spreadsheets","position":17},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Anonymous Functions"},"type":"lvl2","url":"/coding-elements-python#anonymous-functions","position":18},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Anonymous Functions"},"content":"In our root-finding algorithms, we will input a (mathematical) function into a (programming) function, e.g.: find the root of f(x)=\\sin(x)-0.85. This can be achieved via an anonymous function, sometimes called a “lambda” function: f=lambda x: np.sin(x)-0.85.\n\nIf two inputs are needed: f=lambda x,y: x+y.","type":"content","url":"/coding-elements-python#anonymous-functions","position":19},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"break, continue, and return"},"type":"lvl2","url":"/coding-elements-python#break-continue-and-return","position":20},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"break, continue, and return"},"content":"When you are within a loop, break immediately breaks you out of the loop entirely. So, for example:for i in range(5): # note: I recommend np.arange, it is more robust, but this works in base python\n    if i==3:\n        break\nprint(i)\n\nYou should see that i is 3.\n\nWhen you are within a loop, continue immediately sends you back to the top of the loop. So, for example:S=0\nfor i in range(5):\n    if i==2 or i==3:\n        continue\n    S=S+1\nprint(S)\n\nYou should see that S is 3.\n\nYou can return from anywhere in a function. So, for example:def my_fxn(x):\n\tif x==0:\n\t\treturn 0\n\treturn 15\n\nprint(my_fxn(0))\nprint(my_fxn(1))\n\nYou should see that the first print produces 0, the second produces 15.","type":"content","url":"/coding-elements-python#break-continue-and-return","position":21},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Some common motifs"},"type":"lvl2","url":"/coding-elements-python#some-common-motifs","position":22},{"hierarchy":{"lvl1":"Necessary Coding Elements -- Python","lvl2":"Some common motifs"},"content":"If you need something to happen if a number is even:if x % 2 ==0: # even!\n    # do something\nelse:            # odd!\n   # do something else\n\nTo calculation a summation, initialize the sum at zero:N=15       # how many terms to include\nS=0       # initialize the sum at zero\nfor n in range(N):\n    S=S+np.sin(n)\n","type":"content","url":"/coding-elements-python#some-common-motifs","position":23},{"hierarchy":{"lvl1":"GitHub"},"type":"lvl1","url":"/github","position":0},{"hierarchy":{"lvl1":"GitHub"},"content":"GitHub has become the standard location for developers to store, manage, and share their code. An example code collection: \n\nTrackPy is something I found useful when I was analyzing videos from my experiments. The link above is the nice public-facing website, but the code is \n\nhosted on GitHub, and you can look around (bottom right) and see that there are 32 contributors to that project.\n\nImagine trying to co-write code with 31 other people by emailing files back-and-forth! Is there a better way?! Yes -- \n\ngit. GitHub notably uses git as a way for collaborators to seamlessly collaborate on the same project, “pushing” changes from their computers to a shared repository and “merging” those changes to the main branch if they look good and don’t conflict with other contributions. Perhaps the coolest thing: you can link this up with your coding environment, sending updates directly from MATLAB/VS Code.","type":"content","url":"/github","position":1},{"hierarchy":{"lvl1":"GitHub","lvl2":"In this course"},"type":"lvl2","url":"/github#in-this-course","position":2},{"hierarchy":{"lvl1":"GitHub","lvl2":"In this course"},"content":"We will use GitHub Classroom this semester for homework submissions. In keeping with the theme of letting you choose your own adventure (a bit), I outline below two approaches: a web-based method, which requires no downloads, just uploading via your web browser (similar to what you do for GradeScope/Canvas); and a more advanced approach, which after some initial setup work will allow you to submit directly from MATLAB/VS Code.\n\nNote\n\nThis website was built in VS Code, and I push changes to its repository with a couple clicks in VS Code’s left toolbar. Feels good.\n\nEven if you don’t embrace it early in the semester, you might consider using it for the machine learning project later.\n\nTip\n\nIf you are proud of your project, you can publish it publically on GitHub and maybe include a link to it in your resume. Additionally: particularly now that AI is around to help, it is easy to put together a website and host it on GitHub. And it doesn’t have to look like this one -- plenty of tutorials and templates out there! Maybe you’d be interested in establishing an internet presence, highlighting projects to show future employers...","type":"content","url":"/github#in-this-course","position":3},{"hierarchy":{"lvl1":"GitHub","lvl2":"GitHub Classroom setup"},"type":"lvl2","url":"/github#github-classroom-setup","position":4},{"hierarchy":{"lvl1":"GitHub","lvl2":"GitHub Classroom setup"},"content":"Canvas will host links to each homework’s repository. The first time you click one, it will ask you to pick your account from a list, and then will send your \n\ncolorado.edu address a confirmation email. Until you accept the invitation in your email, it will tell you that the repository is unavailable. After accepting, that link will show you a webpage with a description of the homework problems. This is YOUR repository (which I hopefully have access to... we’ll see this weekend, I guess) -- it should say something like mcen3030-hw1-yourName at the top, and you will submit your code into the appropriate folder\n\nThe confirmation step should only be needed once. On future assignments, the links will take you directly to the new homework assignment.","type":"content","url":"/github#github-classroom-setup","position":5},{"hierarchy":{"lvl1":"GitHub","lvl2":"Setting up the homework submission pipeline -- Easy mode"},"type":"lvl2","url":"/github#setting-up-the-homework-submission-pipeline-easy-mode","position":6},{"hierarchy":{"lvl1":"GitHub","lvl2":"Setting up the homework submission pipeline -- Easy mode"},"content":"You may choose to use GitHub in a straightforward way, with no downloads, no git, none of that. All you need is your internet browser, and you will submit in a similar fashion as you do on Canvas/GradeScope: by uploading.\n\nAccept each homework assignment by clicking on the classroom link posted on Canvas.\n\nGo to the new repository online (e.g. mcen3030-hw1-yourName).\n\nNavigate to the correct folder. For problem one, problem_1.\n\nLook for the “Add file” button towards the top right. Select “Upload files”, and find your .m, .py, or .jl file(s).\n\nScroll down to the green “Commit changes” button and click it.\n\nImportant\n\nI’m going to say it again: Scroll down to the green “Commit changes” button and click it. If you forget to commit changes, the file is not saved!\n\nThis approach is perfectly fine to use for the rest of the semester, and can be your fallback plan if you want to use the integrated method below but have some trouble.","type":"content","url":"/github#setting-up-the-homework-submission-pipeline-easy-mode","position":7},{"hierarchy":{"lvl1":"GitHub","lvl2":"Setting up the homework submission pipeline -- Harder-at-first-but-ultimately-not-too-bad mode"},"type":"lvl2","url":"/github#setting-up-the-homework-submission-pipeline-harder-at-first-but-ultimately-not-too-bad-mode","position":8},{"hierarchy":{"lvl1":"GitHub","lvl2":"Setting up the homework submission pipeline -- Harder-at-first-but-ultimately-not-too-bad mode"},"content":"It is possible to directly link each homework repository to your programming environment, and you can simply click “commit”+“push” to submit. No need to clumsily navigate around on the internet -- submit directly from MATLAB or VS Code! Feels good!\n\nSimilarly to above, you will accept each homework assignment by clicking the link, and a new repository will be created under your name. Each will need to be integrated into VS Code/MATLAB, as described below.\n\nTip\n\nThese instructions may look a bit overwhelming but likely we are talking about 20 minutes of work. Submitting homeworks will then be a breeze, quicker than navigating the internet. Plus, interacting with GitHub is a good skill to have -- you could put it on your resume if you get confident with it.","type":"content","url":"/github#setting-up-the-homework-submission-pipeline-harder-at-first-but-ultimately-not-too-bad-mode","position":9},{"hierarchy":{"lvl1":"GitHub","lvl3":"If you are using VS Code...","lvl2":"Setting up the homework submission pipeline -- Harder-at-first-but-ultimately-not-too-bad mode"},"type":"lvl3","url":"/github#if-you-are-using-vs-code","position":10},{"hierarchy":{"lvl1":"GitHub","lvl3":"If you are using VS Code...","lvl2":"Setting up the homework submission pipeline -- Harder-at-first-but-ultimately-not-too-bad mode"},"content":"... I followed \n\nthis tutorial to get it set up. There is a lot there but only part of it is really relevant to us: Prerequisites, Getting started, Cloning a repository, and then there is information scattered about on “committing” (which is to your local repository, as in updating the version on your computer) and “pushing” (sending it to the online repository). When committing you have to give a commit message -- something like “draft of problem 1” or similar is more than sufficient. (Since you don’t have 31 collaborators, this isn’t a huge deal.)\n\nTo emphasize, you will need to commit and push to submit the homework. This is done through the “Source Control” icon on the left toolbar (which should be highlighted after you have made changes to the repository). Particularly the first time, and maybe every time, I recommend visiting the web version to make sure your submission made it there.\n\nTip\n\nTry asking an AI for help or to clarify things. As I was setting up the GitHub Classroom, I asked Gemini things like: “Can students upload their solutions online without needing to use git?” ... and it more-or-less gave the tutorial above. It can really help navigate tutorials, especially when they are bloated with extra things you don’t need (as is the case here).","type":"content","url":"/github#if-you-are-using-vs-code","position":11},{"hierarchy":{"lvl1":"GitHub","lvl3":"If you are using MATLAB...","lvl2":"Setting up the homework submission pipeline -- Harder-at-first-but-ultimately-not-too-bad mode"},"type":"lvl3","url":"/github#if-you-are-using-matlab","position":12},{"hierarchy":{"lvl1":"GitHub","lvl3":"If you are using MATLAB...","lvl2":"Setting up the homework submission pipeline -- Harder-at-first-but-ultimately-not-too-bad mode"},"content":"I asked Gemini the following:\n\nHow can I integrate MATLAB with GitHub? I would like to clone a repository, make changes locally, and push those changes back to GitHub.\n\n... and the resulting instructions were much clearer than \n\nthe official documentation. (I don’t recommend those instructions... the LLM did a better job.) I’ll describe what I did here, a bit streamlined from the LLM, but you might try asking an AI yourself. If you need to clarify anything along the way, it can help!\n\nPrerequisites:\n\nInstall Git: download from \n\ngit-scm.com. You can try step 2 here first if you think you might have it -- you might, e.g. if you have worked with Python before. (I had it already. Mine came from the Python package manager, hopefully installation via that website is good.)\n\nVerify Installation: In the MATLAB Command Window, type the following to ensure MATLAB can find Git: !git --version. If it returns a version number, you are ready to proceed.\n\nGetting a repository:\n\nHome -> New -> Git Clone. You can also do Project.\n\nIt will ask for a URL. That is the web address of your repository, e.g. \n\nhttps://​github​.com​/your​-name​/mcen3030​-hw1​-yourName. (This is generated after you accept the assignment.)\n\nYou can change the folder destination within that menu if you’d like, but don’t have to. After a few seconds, your workspace (“Files”) should switch to a local version of the repository.\n\nYou can then make changes locally. Create your .m files in the appropriate folders, etc. When you are ready to commit a draft or final version of your code to the online repository.\n\nRight- or control-click on each of the new files you created and go to “Source Control” -> “Add to Source Control”.\n\nRight- or control-click in the white area within your workspace (beneath the files) and go to “Source Control” -> “Commit”. You have to provide some comment about what the commit is, something like “first draft of problem 1” is reasonable. (Since you don’t have 31 collaborators, this isn’t a huge deal.)\n\nThen, back into “Source Control”, but this time choose “Push”. It will ask for a login name and token. Leave it here for now.\n\nGetting a token takes a couple steps in your web browser.\n\nGo to \n\nwww.github.com\n\nTop-right there is an avatar (which you can change, by the way). Clicking it opens a menu -- choose “Settings”.\n\nIn the list on the left side, at the very bottom, is “Developer Settings”.\n\nFrom there, you can choose “Personal access tokens”, and then “Tokens (classic)”, and then in the middle of the page you should see “Generate new token”. Click on that and choose “Generate new token (classic)”.\n\nA complicated-looking set of choices will pop up, but the only thing you need to turn on is “repo”. Scroll to the bottom and click “Generate Token”, and then the next page will give you a long password-like thing. That is what you paste-in to go alongside your login name. Probably you will use a six-month token, which will give your MATLAB access for six months... you should only have to do this one time this semester.\n\nImportant\n\nThe token is like a password and should be a secret.","type":"content","url":"/github#if-you-are-using-matlab","position":13},{"hierarchy":{"lvl1":"GitHub","lvl3":"If these sound like too much...","lvl2":"Setting up the homework submission pipeline -- Harder-at-first-but-ultimately-not-too-bad mode"},"type":"lvl3","url":"/github#if-these-sound-like-too-much","position":14},{"hierarchy":{"lvl1":"GitHub","lvl3":"If these sound like too much...","lvl2":"Setting up the homework submission pipeline -- Harder-at-first-but-ultimately-not-too-bad mode"},"content":"No problem, just skip back up to “Easy mode” above. You can submit online for now and get this set up later, or use the online submission forever and never get this git stuff set up. It won’t hold you back at all!","type":"content","url":"/github#if-these-sound-like-too-much","position":15},{"hierarchy":{"lvl1":"Getting going in your language"},"type":"lvl1","url":"/installing","position":0},{"hierarchy":{"lvl1":"Getting going in your language"},"content":"A few recommendations, if you want them. MATLAB has some special steps because we have a license through the school, though overall the installation process is probably the easiest.\n\nThe other languages are open source, meaning you can follow any online tutorial to get them installed. Python technically can be installed with a graphical user interface (GUI), but I have grown to hate that environment -- I recommend miniconda, as described below. You will need to do a bit of work from the command line. Julia takes some command line work. If you flat-out do not want to do command line stuff, just go with MATLAB, but it makes me feel powerful to do command line stuff!\n\nAttention\n\nI considered giving NO instructions for installing Python/Julia, because these languages may require more careful setup/some maintenance throughout the semester. I want students to be willing and able to handle that themselves! But I relented and give some recommendations here.","type":"content","url":"/installing","position":1},{"hierarchy":{"lvl1":"Getting going in your language","lvl2":"MATLAB"},"type":"lvl2","url":"/installing#matlab","position":2},{"hierarchy":{"lvl1":"Getting going in your language","lvl2":"MATLAB"},"content":"MATLAB is the easiest to get going. As a CU student, you have free access if you create an account using your CU email address. Instructions are \n\nhere -- use the ones for students, under “How to get it”.\n\nOnce you have a MathWorks account and have it associated with the school’s license, you can choose to download a desktop version of MATLAB, or to access the cloud version of the software. (See the note below about toolboxes before installing!) Students in previous semesters have used both options, and you can hop back-and-forth if you would like, so you can decide what works best for you. I like the immediate access of having MATLAB installed on my machine and I think it runs a bit faster, but you can access your code from any computer if you are using the online version. MATLAB has a GitHub integration that I have not explored yet -- you will need to get your code into GitHub Classroom, and that may be the best way. I will revisit this to give some tips!\n\nThe MathWorks site has many tutorials, maybe most notably the “MATLAB OnRamp”. \n\nYou can find it here... it is an “Online Training”.","type":"content","url":"/installing#matlab","position":3},{"hierarchy":{"lvl1":"Getting going in your language","lvl3":"Toolboxes","lvl2":"MATLAB"},"type":"lvl3","url":"/installing#toolboxes","position":4},{"hierarchy":{"lvl1":"Getting going in your language","lvl3":"Toolboxes","lvl2":"MATLAB"},"content":"Basic MATLAB is going to be enough for the homework in this class. You can always add toolboxes later, and MATLAB online has them installed by default.\n\nWe will do a machine learning project in this class, so do install the machine learning toolbox.\n\nSimulink is used MCEN 4043: System Dynamics. If you’d like to go ahead and install it, you can.","type":"content","url":"/installing#toolboxes","position":5},{"hierarchy":{"lvl1":"Getting going in your language","lvl2":"Python"},"type":"lvl2","url":"/installing#python","position":6},{"hierarchy":{"lvl1":"Getting going in your language","lvl2":"Python"},"content":"There are multiple avenues here, and if you are confident enough to find you own way (e.g. with pip), I believe in you.\n\nMy recommendation is to \n\ninstall miniconda -- NOT the full Anaconda (which you can find nearby if you really want to, but I’m not linking it). Anaconda is attractive: it has everything you will need in one install, but also a lot of unnecessary stuff. I grew to hate the navigator and the way it insisted on cross-checking all the packages every time I updated, and so I “downgraded” to miniconda. No sluggish navigator, way fewer packages.\n\nAdditionally, I am not fond of the IDEs (Integrated Development Environment) that come with Anaconda. I much prefer \n\nVS Code, which supports Jupyter Notebooks and has a GitHub integration.","type":"content","url":"/installing#python","position":7},{"hierarchy":{"lvl1":"Getting going in your language","lvl3":"Package management","lvl2":"Python"},"type":"lvl3","url":"/installing#package-management","position":8},{"hierarchy":{"lvl1":"Getting going in your language","lvl3":"Package management","lvl2":"Python"},"content":"Miniconda starts with no packages, and so you will have to install these manually. NumPy and matplotlib might be all we need at first. Assuming you are using miniconda, \n\nthis page has instructions. Note that miniconda still uses “conda” in the command line.\n\npip is another option for package management, really it’s not that different from conda. If you have reason to go that way, do it, plenty of tutorials around.\n\nSee Also\n\nSeaborn is built on-top of matplotlib... it is beautiful, I recommend installing it too.\n\nSciPy contains many tools that we are going to try to replicate this semester. Remember: we are building our own tools from the fundamentals, so you can’t use, say, SciPy’s trapezoid rule integrator on homework. But it is probaby worth installing.\n\nFor the machine learning project, \n\nScikit-Learn is probably what I will recommend, though more serious users seem to use PyTorch and TensorFlow. We can circle back to this later...\n\nPython “Environments” (Optional)\n\nMany serious programmers insist each project should have its own “environment” with a unique set of packages. For example, TensorFlow apparently does not play nice with NumPy version 2.0 or higher, and so folks who use TensorFlow will likely have an isolated environment for it where NumPy 1.9x is installed. (I still couldn’t get TensorFlow to work, but that is beside the point!) For this class, it should not be a big deal to work entirely in the base environment.\n\nIf you do want to create separate environments, e.g., one for your homework repository, one for the machine learning project, you can. From the command line, you would start with something like conda create --name homework and then conda activate homework puts you in that environment, and then conda install numpy would get you numpy in just that environment. You need to install packages in each environment -- if you have three environments set up on your machine, you might technically have numpy installed three times.","type":"content","url":"/installing#package-management","position":9},{"hierarchy":{"lvl1":"Getting going in your language","lvl2":"Julia"},"type":"lvl2","url":"/installing#julia","position":10},{"hierarchy":{"lvl1":"Getting going in your language","lvl2":"Julia"},"content":"Though this is not as mainstream, there are plenty of tutorials/discussions online from a dedicated and helpful group of users. If you are the type who would be interested in Julia, I assume you will be able to figure it out. Go \n\nhere, and the \n\nrecommended IDE is again VS Code. There is a \n\nbuilt-in package manager -- Plots.jl might be all you need to add at the beginning, but the machine learning package you’ll use is probably \n\nFlux or maybe \n\nLux. There is \n\na debugger.\n\nThough Julia is technically a compiled language, working within VS Code makes it feel like a scripting language, which is nice. Something about \n\njust in-time compilation makes it work out.","type":"content","url":"/installing#julia","position":11},{"hierarchy":{"lvl1":"Choosing Your Language"},"type":"lvl1","url":"/languages","position":0},{"hierarchy":{"lvl1":"Choosing Your Language"},"content":"Despite what you may have heard, this is not “a MATLAB course” -- I would describe it as “an applied math course”. (Indeed, many of the algorithms we will describe were invented long before computers.) In previous iterations of this course we have insisted that students use MATLAB, with the largest reason being to streamline the student, grader, and instructor experience. There are indeed good reasons to use MATLAB, most notably it is easiest to get set up and it is the most likely to be used in other mechanical engineering courses. If those reasons are compelling to you, use MATLAB. However, some folks might be looking ahead to a career where MATLAB is not the standard and would like to get experience with a language that aligns with their career goals. Or they already have some experience in a different language and would like to keep using it.\n\nSo what I am getting at?\n\nI am giving you the opportunity to choose the language you use in this course: you may choose MATLAB, Python, or Julia, and will have thousands of lines of coding experience in that language by the end of the semester. (Other languages: let’s talk. But they need to be “scripting” or “scripting-like”.)\n\nFor all three languages, I have provided\n\na page that includes nearly all necessary coding elements that you may reference as you complete your homework.\n\na page that has recommendations about how to get these set up, though, other than MATLAB, you have a lot of flexibility.\n\nan \n\n“AI green light” on homework assignments, which you should not \n\nmisuse, but it will help to enable this “polyglot” approach to the course.\n\nWarning\n\nNo matter what language you choose, you should be prepared to KNOW things like: whether indexing starts with 0 or 1, how to find the length of an array, how to write a for loop, the character used for comments # % ..., etc. On the exams, forgetting that Python indexes from 0 or that MATLAB requires you to end loops will lose you points -- do not ask for leniency if you make these mistakes. I am empowering you to learn and use whatever language you want, so learn it!\n\nFor this reason, you are strongly encouraged to commit to a language (perhaps after a trial period, if you would like). However, and tentatively, I believe I can make the logistics work even if you decide to switch languages during the semester.\n\nOnce you have read through the following and think you are ready to commit to a language, see \n\nthe installation recommendations page.","type":"content","url":"/languages","position":1},{"hierarchy":{"lvl1":"Choosing Your Language","lvl2":"TL;DR:"},"type":"lvl2","url":"/languages#tl-dr","position":2},{"hierarchy":{"lvl1":"Choosing Your Language","lvl2":"TL;DR:"},"content":"Choose MATLAB if you want the easiest installation, or if you just want some direct, explicit, no fuss experience with the language that is (probably going to be) used in MCEN 3047: Data Analysis and MCEN 4043: System Dynamics.\n\nChoose Python if you want the language with widest use, and if you are not bothered by having to do some setup work.\n\nChoose Julia if you are thoroughly interested in numerical methods and have an appetite for a more challenging but more powerful language. Probably this will be chosen by just a few advanced users.\n\nOther: let’s talk.\n\nSee a more detailed list of pros and cons below, and talk to me if you want to talk about your options. I would guess 60% of the class will choose MATLAB, 35% will choose Python, and 5% will choose Julia/other. (Again: talk to me about “other”.) I will let the class know what the distribution is -- I am sure you are curious!\n\nTip\n\nFrom a certain, practical level, these languages are very similar, using index:slicing, for, while, etc. You will be able to understand each other’s code and will be pretty capable of switching between languages in the future, if needed. You are not committing for life! And AI can help you translate.\n\nWarning\n\nNote that you are responsible for setting up and maintaining your programming environment, which is easy for MATLAB but is slightly more involved for the other languages.\n\nIncluded at the bottom of each of these tabs is an example bit of code that would compute\\sum\\limits_{n=1}^N \\frac{1}{n^k}\n\nto give you a feel for what some basic code looks like. If you are curious, I would encourage you to look around online to see how engineers are using these languages. You can also go ahead and look at \n\nthe overview of basic coding elements.","type":"content","url":"/languages#tl-dr","position":3},{"hierarchy":{"lvl1":"Choosing Your Language","lvl2":"Pros/Cons"},"type":"lvl2","url":"/languages#pros-cons","position":4},{"hierarchy":{"lvl1":"Choosing Your Language","lvl2":"Pros/Cons"},"content":"Reasons to choose MATLAB:\n\nFor students it is free.\n\nEasiest to set up: you can either download MATLAB and run it on your machine, or use MATLAB online.\n\nMATLAB has traditionally been used in MCEN 3047: Data Analysis and MCEN 4043: System Dynamics. Maybe you don’t want to be distracted with another language.\n\nIt is a language for scientists and engineers. Matrix math is just: A*x.\n\nIndexing starts with 1.\n\nMATLAB has an excellent built-in debug mode.\n\nReasons to NOT choose MATLAB:\n\nWhile it is 100% free for students, it is not free in the real world: a yearly license for an individual costs $1015.\n\nRelated: some companies do use MATLAB and surely are getting a discount from that per-person price tag, but most companies are not going to want to pay thousands of dollars when there are many free options that can do all the same tasks.\n\nThe one function per file architecture is no fun, but is not a huge deal in this class since we will mostly be writing individual functions.\n\nMATLAB allows you to be “sloppy” in ways that make serious programmers shake their head. (But at the same time, other languages can seem overly rigorous.)\n\nLaunching it takes a minute.\n\nI find it annoying that the default is to print every line and a ; must be added to prevent that.\n\nExample code:k=2;\nN=50;\nS=0;        % initialize the sum at zero\nfor n=1:N\n    S=S+1/n^k;\nend\nprint(S)\n\nReasons to choose Python:\n\nFor everyone it is free.\n\nIndenting/whitespace is used instead of end statements, which makes the code look really clean. (However, see the note below about needing to prepend np. for numpy tools.)\n\nPython is probably the widest used language for scientific computing, or at least it has the most momentum. It is definitely the widest-used for machine learning.\n\nIt is a language that is used beyond engineering computing and you might appreciate getting some adjacent experience. An example: I accidentally scanned a hundred pages in reverse order, but used \n\nPyPDF2 to put them right.\n\nReasons to NOT choose Python:\n\nIt has become widely used by engineers and scientists (see for example \n\nTrackPy), but at its core it was not invented for engineers. NumPy/SciPy/matplotlib have been thoroughly developed, but it just less appealing to have to deal with np.sin(x) instead of just sin(x). Here is how to get a matrix inverse: np.linalg.inv(matrix_a).Raising to a power is ** instead of ^. Ugh. (Yes, I know you can from numpy import sin or even from numpy import * but that is rarely done.)\n\nIndexing starts with 0, which might annoy you enough to look elsewhere.\n\nThe install process, including package management, is not overwhelming, but it is extra steps that may have to occur in the command window/terminal.\n\nExample code:import numpy as np # this will be necessary in almost every function, though not really for this little example\n\nk=2\nN=50\nS=0            # initialize the sum at zero\nfor n in 1:N\n    S+=1/n**k  # ^ is ** in python\n\n# no end needed!\n\nprint(S)\n\nReasons to choose Julia:\n\nFor everyone it is free (open source).\n\nIt is a language developed for scientists and engineers. The code looks like math.\n\nIt is a small, seemingly advanced user base of scientists and engineers, but they seem wise and helpful.\n\nIndexing starts with 1.\n\nAmong these three languages, it is the most serious computational science language, as in: people on the cutting edge of computational research are choosing it.\n\nReasons to NOT choose Julia:\n\nJulia is a compiled language. This means the first time you run a new program, it may be slow. My experience is that this is not a big deal.\n\nIt is the least well-developed of the languages in this list, meaning there are fewer tutorials, fewer third-party programs, and fewer users to help.\n\nIt is not clear if Julia will continue to grow or if it will fade away -- you might become an expert in something that no one cares about in 10 years.\n\nWe will likely not have need to use the truly powerful aspects of Julia, e.g. multiple dispatch.\n\nIt seems that Julia sometimes goes out of its way to name things differently than MATLAB/Python. In MATLAB: linspace(0,10,101) makes an array with 101 elements. In Python+NumPy it is np.linspace(0,10,101). In Julia it is LinRange(0,10,101)... OK Julia. This is not a reason not to choose Julia on its own, but if you are talking to MATLAB/Python people it is a little annoyance.\n\nJulia makes some decisions for computational efficiency that can maybe be frustrating to a less-experienced user. For example: you’ll see in the code snipped below that an extra step is necessary because variable “scope” is limited within loops. I am sure there are deep reasons for this.\n\nExample code:\n\n\nContact me.\n\nCaution\n\nRemember our goal is to understand the algorithms, not to use built-in tools. While this rule is mostly about things like ode45 (the default ODE solver in MATLAB, which, to emphasize, is not permitted in this class), there may be occasions where “the pythonic”/“the julian” way of doing something opposes the fundamentals of the algorithm. The biggest example of this will likely be with for loops. I will try to keep an open mind, but also may require you write in un-optimized code that more clearly demonstrates that you indeed understand the algorithm.","type":"content","url":"/languages#pros-cons","position":5},{"hierarchy":{"lvl1":"Choosing Your Language","lvl2":"More Reading"},"type":"lvl2","url":"/languages#more-reading","position":6},{"hierarchy":{"lvl1":"Choosing Your Language","lvl2":"More Reading"},"content":"MATLAB vs. Julia vs. Python\n\nWhy numbering should start at zero (not sure I agree but, here is a reading) https://forem.julialang.org/vinodv/julia-vectors-and-matrices-n2l ","type":"content","url":"/languages#more-reading","position":7},{"hierarchy":{"lvl1":"Cramer’s Rule and Motivation for Matrix Methods"},"type":"lvl1","url":"/cramer","position":0},{"hierarchy":{"lvl1":"Cramer’s Rule and Motivation for Matrix Methods"},"content":"Solving a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b} for unknown \\mathbf{x} is “the” linear algebra problem. For a square matrix \\mathbf{A}, the solution is\\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}.\n\nEasy, right? It turns out that calculating the inverse of a matrix is computationally very expensive. We’ll see a hint as to why here.","type":"content","url":"/cramer","position":1},{"hierarchy":{"lvl1":"Cramer’s Rule and Motivation for Matrix Methods","lvl2":"Cramer’s Rule"},"type":"lvl2","url":"/cramer#cramers-rule","position":2},{"hierarchy":{"lvl1":"Cramer’s Rule and Motivation for Matrix Methods","lvl2":"Cramer’s Rule"},"content":"For a linear system \\mathbf{A}\\mathbf{x}=\\mathbf{b}, with \\mathbf{x}=[x_1, x_2, x_3, ... , x_N]^T, the value of x_n will be given byx_n = \\frac{\\text{det}(\\mathbf{A}_n)}{\\text{det}(\\mathbf{A})}\n\nwhere \\mathbf{A}_n is the matrix formed by replacing the n^\\text{th} column in \\mathbf{A} with \\mathbf{b}. A quick example: if\\begin{bmatrix}\n2 & 0\\\\ -1 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\nx \\\\ y\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n3 \\\\ 1\n\\end{bmatrix}\n\nthenx = \\frac{\\text{det}\\left(\n\\begin{bmatrix}\n3 & 0\\\\ 1 & 1\n\\end{bmatrix}\n\\right)}{\\text{det}\\left(\n\\begin{bmatrix}\n2 & 0\\\\ -1 & 1\n\\end{bmatrix}\n\\right)}\n\nandy = \\frac{\\text{det}\\left(\n\\begin{bmatrix}\n2 & 3\\\\ -1 & 1\n\\end{bmatrix}\n\\right)}{\\text{det}\\left(\n\\begin{bmatrix}\n2 & 0\\\\ -1 & 1\n\\end{bmatrix}\n\\right)}.","type":"content","url":"/cramer#cramers-rule","position":3},{"hierarchy":{"lvl1":"Cramer’s Rule and Motivation for Matrix Methods","lvl2":"Calculating the determinant, and FLOPs"},"type":"lvl2","url":"/cramer#calculating-the-determinant-and-flops","position":4},{"hierarchy":{"lvl1":"Cramer’s Rule and Motivation for Matrix Methods","lvl2":"Calculating the determinant, and FLOPs"},"content":"Computer performance is sometimes measured in FLOPs per second -- floating point operations (addition, multiplication etc. of floats) per second. A personal computer might be capable of 1000 gigaFLOPs per second (\n\n1012 FLOPs/sec). Let’s keep this number in mind.\n\nFor a 2\\times 2 matrix, the determinant is calculated with:\\text{det}\\left(\n\\begin{bmatrix}\na_{11} & a_{12}\\\\ a_{21} & a_{22}\n\\end{bmatrix}\n\\right) = a_{11}a_{22}-a_{12}a_{21}.\n\nSo, 3 FLOPs.\n\nFor a 3\\times 3 matrix:\\text{det}\\left(\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13}\\\\ a_{21} & a_{22} & a_{23}\\\\\na_{31} & a_{32} & a_{33}\n\\end{bmatrix}\n\\right) = a_{11}\\text{det}\\left(\n\\begin{bmatrix}\na_{22} & a_{23}\\\\ a_{32} & a_{33}\n\\end{bmatrix}\n\\right)\\\\\n-a_{12}\\text{det}\\left(\n\\begin{bmatrix}\na_{21} & a_{23}\\\\ a_{31} & a_{33}\n\\end{bmatrix}\n\\right)\n+a_{13}\\text{det}\\left(\n\\begin{bmatrix}\na_{21} & a_{22}\\\\ a_{31} & a_{32}\n\\end{bmatrix}\n\\right).\n\nSo, each of the 2\\times 2 determinants takes 3 FLOPs, and then each of those is multiplied by something, and then we add the results together. Maybe there is some subtlety here, but for the point of this demonstration: (3)(3)(2)= 18 FLOPs.\n\nFor a 4\\times 4 matrix, we will need to calculate the determinant of four 3\\times 3 matrices, each takes 18 FLOPs, then four multiplications, then three additions. (18)(4)(3)=216 FLOPs.\n\nFor a 5\\times 5: (216)(5)(4)=4320.\n\nFor a 6\\times 6: (4320)(6)(5)=129600.\n\nFor a 7\\times 7: 5443200. This isn’t really even a large system yet!\n\nFor an N\\times N matrix: 3N!(N-1)!/2.\n\nIn engineering, e.g. in a finite-element analysis, it would not be unreasonable (and still not that big) to have a 500\\times 500 matrix. 3N!(N-1)!/2 with N=500 is4466201622\n4189812326\n5086569612\n0519345854\\\\\n7202507990\n9234976578\n4489339089\n4575441168\\\\\n2689786180\n5906290490\n5656312051\n4443654755\\\\\n4930620936\n2288949089\n1244300239\n9337669587\\\\\n0438338361\n0914162116\n7594194263\n0741109577\\\\\n9297933535\n5427888826\n1795126255\n2302832494\\\\\n4097254659\n1458576409\n0262646003\n7028273551\\\\\n2180966805\n0595507178\n7874305286\n4298812953\\\\\n1875907971\n5637542761\n2363882034\n2684244171\\\\\n2497082191\n1175391896\n0690446382\n1764026413\\\\\n3277921574\n7997637893\n1564771000\n7975405099\\\\\n5282492083\n3571561264\n4348584705\n4490987115\\\\\n7151342158\n0122517497\n7717592409\n8774844826\\\\\n6451067760\n9318635628\n9534940392\n8020644744\\\\\n6875063037\n5219095234\n9155673257\n6574384497\\\\\n2719339357\n5923079158\n7381959160\n2715129001\\\\\n4899396412\n7542782049\n6419842909\n5815201746\\\\\n9497047781\n4732324641\n7374890396\n8570838906\\\\\n1531802777\n2411497938\n0439051486\n6030516552\\\\\n7145201409\n5332854985\n6968120718\n8828164871\\\\\n8172968127\n6502071633\n1472546706\n6742275153\\\\\n0695575028\n7527575414\n0820192131\n5262018838\\\\\n7898836040\n2727548277\n9973045018\n8459663413\\\\\n7221703972\n5580059452\n3620323014\n9099864283\\\\\n7294600312\n8689911384\n1656088190\n5087934483\\\\\n1797911146\n2832410526\n2837448607\n9817032648\\\\\n1749351722\n0779540960\n8591720389\n2467760526\\\\\n3322856478\n2182046616\n8687667347\n0461833863\\\\\n5334512229\n9192742778\n3775510922\n2237121628\\\\\n5414368451\n5087617233\n2553978213\n2854541329\\\\\n1068698630\n4984245046\n9795888390\n6950361917\\\\\n3980139368\n5103658285\n8913372393\n6174659681\\\\\n6616131365\n9798902174\n2655560025\n1849710206\\\\\n2720465344\n6733275917\n7114411494\n2148147009\\\\\n6872729536\n9888143782\n9092345015\n4389177636\\\\\n9482633358\n0443595468\n9592743655\n1969923813\\\\\n2309160708\n1127069848\n3107447822\n1619350981\\\\\n9381569580\n4559116745\n5634306877\n0229223551\\\\\n2878007187\n5336134572\n7313876478\n6960108219\\\\\n6785223899\n2821247302\n2057846467\n9944687460\\\\\n3139512903\n1128931260\n4412082010\n1255658196\\\\\n2613714454\n6610443053\n3158806709\n5166956324\\\\\n3391068207\n1926197240\n7672335403\n0713683814\\\\\n6164560718\n8382002391\n4319296720\n5864766093\\\\\n3431120129\n4150215709\n0832243471\n7701637729\\\\\n9309074311\n2759940915\n0010112638\n2750523983\\\\\n2387062465\n6301463310\n0731809149\n1754691721\\\\\n4816723968\n4651432582\n1687054391\n0601377869\\\\\n7880646814\n4660509671\n5522887308\n1001103196\\\\\n5541003798\n3074410851\n5965168160\n5809953084\\\\\n6775046027\n2189164748\n8000000000\n0000000000\\\\\n0000000000\n0000000000\n0000000000\n0000000000\\\\\n0000000000\n0000000000\n0000000000\n0000000000\\\\\n0000000000\n0000000000\n0000000000\n0000000000\\\\\n0000000000\n0000000000\n0000000000\n0000000000\\\\\n0000000000\n0000000000\n0000000000\n0000000000\\\\\n0000000000\n0000000000\n000000.\n\nThat is: 4.5 \\times 10^{2265}. At \n\n1012 FLOPs/sec, it would take 1.4 \\times 10^{2246} years to complete this calculation.\n\nAttention\n\nIt is estimated that there are about \n\n1080 atoms in the universe.\n\nThe Big Bang occurred 13.8 \\times 10^{9} years ago.\n\nIf every atom in the universe was a tiny computer capable of performing \n\n1012 FLOPs/sec, it would take \n\n102156 times the age of the universe to complete this calculation.\n\nThis suggests, QUITE strongly, that a computer is not using Cramer’s Rule to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nIf you want to see for yourself: The following code will calculate the determinant of a random 500\\times 500 matrix. It probably takes about one second.\n\ndet(rand(500,500))\n\nimport numpy as np\nd=np.linalg.det(np.random.rand(500, 500))\nprint(d)\n\nusing LinearAlgebra\nd = det(rand(500, 500))\nprintln(d)","type":"content","url":"/cramer#calculating-the-determinant-and-flops","position":5},{"hierarchy":{"lvl1":"Taylor Series Refresher"},"type":"lvl1","url":"/taylor-series","position":0},{"hierarchy":{"lvl1":"Taylor Series Refresher"},"content":"Suppose we have a complicated function f(x), made of natural logs and arctangents or whatever. Not friendly to deal with. We could reasonably ask the question: if there is another function \\hat{f}(x) that has the same value as f(x) at x=x_0, and the same value of the first derivative (so the value of \\hat{f}(x) is changing just as rapidly as f(x) at x=x_0), and the same value of the second derivative (so the rate of change of the rate of change of \\hat{f}(x) matches that of f(x)), and the same value of the third derivative, and the same value of the fourth derivative, etc., onwards to the infinitieth derivative... well, that sounds like we effectively have the same functional behavior for both f(x) and \\hat{f}(x). A function that meets this requirement can usually be constructed:\\begin{align}\n\\hat{f}(x) &= f(x_0)+ (x-x_0)f'(x_0) + \\frac{1}{2!}(x-x_0)^2f''(x_0) + \\frac{1}{3!}(x-x_0)^3f'''(x_0) \\dots \\\\\n& = f(x_0) + \\sum\\limits_{n=1}^\\infty \\frac{1}{n!}(x-x_0)^nf^{(n)}(x_0)\n\\end{align}\n\nout to infinity terms with f^{(n)} being the nth derivative. Importantly, this equivalent function, \\hat{f}(x), is a polynomial, and polynomials are easy to deal with! The trade-off, of course, is that there are now infinity terms. We’ll see if we can tame that.\n\nThis is the Taylor Series for the function f(x), and it is one of the most important ideas in engineering.","type":"content","url":"/taylor-series","position":1},{"hierarchy":{"lvl1":"Taylor Series Refresher","lvl2":"Linearization"},"type":"lvl2","url":"/taylor-series#linearization","position":2},{"hierarchy":{"lvl1":"Taylor Series Refresher","lvl2":"Linearization"},"content":"Let’s suppose x-x_0=\\epsilon, where \\epsilon \\ll 1. To make it concrete, let’s say \\epsilon=0.1. What is the value, then, of (x-x_0)^2 = \\epsilon^2? It is small: 0.01. And (x-x_0)^3 = \\epsilon^3? Even smaller, 0.001.\n\nThis tells us that, presuming our x is near to the reference location x_0, and that the function itself is reasonably well-behaved, the successive terms in the Taylor Series become decreasingly significant. That is: we might get a decent approximation of the original function f(x) “near” to the reference point x_0 by just using the “linearization”f(x) \\approx f(x_0) + (x-x_0)f'(x_0).\n\nThis is the most practical lesson we learn from Taylor Series and will be the foundation for many of the algorithms we use in this course.","type":"content","url":"/taylor-series#linearization","position":3},{"hierarchy":{"lvl1":"Numerical Error"},"type":"lvl1","url":"/error","position":0},{"hierarchy":{"lvl1":"Numerical Error"},"content":"Here we describe numerical error. These are definitions, and not everyone uses precisely the same terminology, but we will try to be consistent in this class.","type":"content","url":"/error","position":1},{"hierarchy":{"lvl1":"Numerical Error","lvl2":"Quantifying Error"},"type":"lvl2","url":"/error#quantifying-error","position":2},{"hierarchy":{"lvl1":"Numerical Error","lvl2":"Quantifying Error"},"content":"","type":"content","url":"/error#quantifying-error","position":3},{"hierarchy":{"lvl1":"Numerical Error","lvl3":"Absolute error","lvl2":"Quantifying Error"},"type":"lvl3","url":"/error#absolute-error","position":4},{"hierarchy":{"lvl1":"Numerical Error","lvl3":"Absolute error","lvl2":"Quantifying Error"},"content":"Error is a fact of life in engineering -- measurement devices are miscalibrated, data is processed according to Bernoulli’s Equation but Bernoulli’s Equation neglects viscosity, computers can store only finite detail, etc. Regardless of the reason the error emerges, we can describe the relationship between the “true value” and “measured value” with (error)=(true value)-(measured value). We define this measurement of error as the “absolute error”.\n\nIn some situations it is useful to quantify error in this way. For example, in darts you might have an error of 3 (cm) in regards to the triple 20. That conveys meaningful information about how to adjust your trajectory to hit the target. However, a downside of this metric is that it neglects to consider the magnitudes of the numbers involved: an error of \\pm 1 is no-big-deal if the values in question are greater than, say, 100, while an error of \\pm 1 is devastating if the numbers in question are about 1.1. “One away” might be incredibly good if we are talking about a dart missing its target in microns, but it might be awful if we are talking meters.\n\nThe absolute error changes depending on the units being used.","type":"content","url":"/error#absolute-error","position":5},{"hierarchy":{"lvl1":"Numerical Error","lvl3":"Relative Error","lvl2":"Quantifying Error"},"type":"lvl3","url":"/error#relative-error","position":6},{"hierarchy":{"lvl1":"Numerical Error","lvl3":"Relative Error","lvl2":"Quantifying Error"},"content":"“Relative error” is often preferred in engineering applications because it conveys information about the size of the numbers in question via a normalization by the trusted/true value:(\\text{error}_\\text{rel})\\equiv \\left| \\frac{(\\text{true value})-(\\text{measured value})}{(\\text{true value})} \\right|.\n\nWe may choose to represent this as a percentage by multiplying it by 100. Then, we have some intuition: a 1% (relative) error is, in most engineering applications, very good, and it doesn’t matter if we are talking about something small like the measurement of the diameter of a human hair or something large like the diameter of a sun spot. We understand what a 1% error means and probably have respect for that level of accuracy.\n\nCaution\n\nProblems arise if the true value is zero, and arbitrary placement of the zero point influences this metric: the relative error between 275 and 280 K is fairly small, the relative error between 2 and 7°C is much larger.\n\nTip\n\nI usually prefer to represent a 1% error as err=0.01 in my code, to avoid having to do the awkward multiplication by 100.","type":"content","url":"/error#relative-error","position":7},{"hierarchy":{"lvl1":"Numerical Error","lvl2":"Accuracy and Precision"},"type":"lvl2","url":"/error#accuracy-and-precision","position":8},{"hierarchy":{"lvl1":"Numerical Error","lvl2":"Accuracy and Precision"},"content":"Let’s describe what we might mean by “accuracy” and “precision” when it comes to storage of numbers. The most common way to store a number in scientific programming is as a “double”/“double-float”, with 64 bits of information (in binary). Because of the way these numbers are represented, this corresponds to about 16 (base 10) digits. We might say that the “precision” of such a number (in regards to the storage process), is 16 digits.\n\nSixteen digits is, in most engineering applications, incredibly precise! Astronomers use AU, astronomical units, to measure distance. The average distance between the Earth and the Sun is 1 AU, or 1.5 \\times 10^11 meters. If our average distance from the Sun was one human-hair diameter larger it would be approximately 1.000000000000001 AU. A double is able to store 1.000000000000001, just barely but it can!\n\nIf we use 3.309402940125679 as \\pi, well that’s not very accurate. Accuracy is related to the true value of a number: using 3.14 as \\pi is more accurate than 3.309402940125679, but 3.309402940125679 is the more precise number. Storing a number as a double limits its precision, but the double architecture has no effect on the accuracy of the number. Actually, we may not know the true value of the number, and thus might not be able to say anything about its accuracy.\n\nRegarding this 3.309402940125679: it would be like if you had a very carefully designed experiment that could indeed discern 3.309402940125678 from 3.309402940125679, but there was some sort of miscalibration that gave the wrong value. It was a precise experiment, but not an accurate one.\n\nIn cases where we are aware of the true value of a number (let’s call it x), we can describe the number of accurate digits in the approximation (let’s call it \\hat{x}), as(\\text{accurate digits})=-\\log_{10}\\left|\\frac{x-\\hat{x}}{x}\\right|.\n\nAs an example, using the above numbers for \\pi (along with an accurate value of \\pi=3.141592653589793):-\\log_{10}\\left|\\frac{3.141592653589793-3.309402940125679}{3.141592653589793}\\right| = 1.27\n\nand-\\log_{10}\\left|\\frac{3.141592653589793-3.14}{3.141592653589793}\\right| = 3.30.\n\nWe’d probably round these numbers down to say: 3.309402940125679 has one accurate digit, while 3.14 has three accurate digits.","type":"content","url":"/error#accuracy-and-precision","position":9},{"hierarchy":{"lvl1":"Numerical Error","lvl2":"Sources of Numerical Error"},"type":"lvl2","url":"/error#sources-of-numerical-error","position":10},{"hierarchy":{"lvl1":"Numerical Error","lvl2":"Sources of Numerical Error"},"content":"","type":"content","url":"/error#sources-of-numerical-error","position":11},{"hierarchy":{"lvl1":"Numerical Error","lvl3":"Round-off Error","lvl2":"Sources of Numerical Error"},"type":"lvl3","url":"/error#round-off-error","position":12},{"hierarchy":{"lvl1":"Numerical Error","lvl3":"Round-off Error","lvl2":"Sources of Numerical Error"},"content":"We can express big numbers, e.g. 10^100, and small numbers, e.g. 10^-100, as doubles, no problem. But those doubles have finite precision: 16 digits in base 10. If we multiply together two numbers with 16 sig figs by hand, we would ostensibly have 32 known digits, e.g.:2121212121212121\\times 9292929292929292 = 19712274257728799240893786348332.\n\nThe two numbers on the left-hand side of this equation can be perfectly described by a double. Their product can’t, and we’d lose the precision of the last 16 digits of that number. The detail of the number lost after a calculation is known as “the round-off error”.\n\nIn many practical applications, we need not be too concerned with round-off error -- losing the last 16 digits above, leaving 0.1971227425772879\\times 10^{32} (instead of 0.19712274257728799240893786348332\\times 10^{32})... that is still precise enough to be used in any engineering calculation. However, it is possible to “push too far” in some computational algorithms, maybe in an intermediate step, such that the round-off error appreciably affects the calculation.","type":"content","url":"/error#round-off-error","position":13},{"hierarchy":{"lvl1":"Numerical Error","lvl3":"Truncation Error","lvl2":"Sources of Numerical Error"},"type":"lvl3","url":"/error#truncation-error","position":14},{"hierarchy":{"lvl1":"Numerical Error","lvl3":"Truncation Error","lvl2":"Sources of Numerical Error"},"content":"How does a computer calculate something like \\sin\\left(0.13\\right)? Computers are very prepared to do arithmetic (addition, multiplication) with floats, but calculating sine, not so much. Recall the \n\nTaylor Series for sine:\\sin{x}= x-\\frac{x^3}{3!}+\\frac{x^5}{5!} - \\frac{x^7}{7!} + \\dots = \\sum\\limits_{n=0}^\\infty \\frac{(-1)^n}{(2n+1)!}x^{2n+1}.\n\n(We are going to talk about Taylor Series probably 10 times this semester, get ready!) One of the neat things about Taylor Series: we can write any function as a polynomial, and polynomials are just addition and multiplication. Computers are able to do simple arithmetic like this quickly. This is actually how calculators determine the sine of a number.\n\n“Truncation error” refers to the difference between a finite summation and a (possibly hypothetical) summation with infinite terms. If x=0.1,\\sin{(x)}\\approx 0.099833 \\approx 0.1 = x.\n\nThat is, the truncation error for the “one-term approximation” is not too bad. But for x=2,\\sin{(x)}\\approx 0.909297 \\neq 2 = x.\n\nSo the truncation error for the one-term approximation is bad. We need to keep more terms. If we calculate through the x^7 term in the Taylor Series, we get 0.907937... pretty decent.\n\nNote that the truncation error is basically theoretical -- the computer is not aware of the “true value” of \\sin{(0.13)}, and so is unable to judge whether it is accurate based on an assessment of the truncation error.","type":"content","url":"/error#truncation-error","position":15},{"hierarchy":{"lvl1":"Numerical Error","lvl2":"Convergence"},"type":"lvl2","url":"/error#convergence","position":16},{"hierarchy":{"lvl1":"Numerical Error","lvl2":"Convergence"},"content":"So how can we decide when to stop the summation if we don’t know the value it is converging to? We can invent a “convergence criterion” to decide that adding one more term is not worth it.\n\nYou spent quite some time on convergent/divergent series in Calculus 2, I’ll leave the formality to that class. Practically speaking, we can quantify the convergence with a definition like\\left| \\frac{S_{n+1}-S_{n}}{S_{n+1}} \\right|\n\nwhere S_n is the sum of series through n terms. In spirit: whenever the above quantity drops below a certain value, say 0.001, we know that the inclusion of one more term in the summation is probably not going to dramatically change the result. And, assuming the summation is well-behaved, we trust that the term after that is even less significant, and the one after that even less significant, and so on. Thus, we have a condition for stopping our summation.\n\nThis practical implementation requires some trust that the series is actually converging: according to the above criterion, the summation\\sum\\limits_{n=1}^N \\frac{1}{n}\n\nmight “look like” it is converging after 175 terms, i.e., the 175th term changes the value of the sum by less than 0.001. However, this sum diverges as N\\rightarrow\\infty.\n\nIn 3030, we will use this convergence criterion frequently as we iterate to find approximate solutions to analytically unsolveable problems. For example: while con>con_accept might make several appearances, and we would read this as: “while the convergence criterion is larger than the acceptable value, continue with the while loop”. :::{hint}\n\n::: ","type":"content","url":"/error#convergence","position":17},{"hierarchy":{"lvl1":"The (1D) Newton-Raphson Method"},"type":"lvl1","url":"/nr-1d","position":0},{"hierarchy":{"lvl1":"The (1D) Newton-Raphson Method"},"content":"The Newton-Raphson Method is another root-finding algorithm, though this one is called an “open” method because the search is not confined to a specific range. This has it’s positives: most notably, it converges more quickly than the bisection method; and negatives: it is not guaranteed to find a solution even if one exists. Another downside: we must analytically calculate the function’s derivative in order to implement the algorithm (though we’ll also talk about a modified version that doesn’t require this). Still, I think it is a beautiful idea, and it is one of the most useful ideas in computational methods!\n\nThe idea is this: we have a function for which we are seeking the location where f(x)=0, and we have a guess for the solution x_0, called the seed (similar to how, with \n\nthe Bisection Method we had to set the search range). We \n\nlinearize the function around x_0 and trace the resulting line back to y=0. If our guess is decent and the function is not too erratic, it is likely that the associated x-location (call it x_1) is a better estimate of the root than our initial guess. We repeat the process, now linearizing around x=x_1 and tracing the line back to find an even better estimate, x_2, and then maybe we use that too get an even better estimate, etc.~etc.~etc., until we have acceptably \n\nconverged.","type":"content","url":"/nr-1d","position":1},{"hierarchy":{"lvl1":"The (1D) Newton-Raphson Method","lvl2":"The algorithm"},"type":"lvl2","url":"/nr-1d#the-algorithm","position":2},{"hierarchy":{"lvl1":"The (1D) Newton-Raphson Method","lvl2":"The algorithm"},"content":"Inputs to the algorithm are: the function f (defined by an \n\nanonymous function), the function derivative fp, a seed x_0, an \n\nacceptable convergence con_accept, and probably a maximum number of iterations max_iter. The last argument is necessary to halt the program when it is not converging.\n\nThen, a quick derivation: start with the linearized function f(x) \\approx f(x_0)+ f'(x_0)(x-x_0) and set f(x) =0. Rearrange to solve for x, which would be interpreted as “the x such that y=0 in the linearized function”: x = x_0 - f(x_0)/f'(x_0). This is an iterative scheme, and so we write it with an iterative index i:x_{i+1} = x_i - \\frac{f(x_i)}{f'(x_i)}\n\nThis equation is what you will need to program, and the algorithm is quite simple: use the seed x_0 to compute the first iteration x_1 via the above equation, then use x_1 to compute x_2, and so on. The program stops when an an \n\nacceptable convergence is met, or when the maximum number of iterations is met.\n\nHint\n\nFor the former... sounds like a while loop, right? While the convergence metric is bigger than the acceptable convergence value? For the latter, maybe break or return. See the \n\ncoding elements page.","type":"content","url":"/nr-1d#the-algorithm","position":3},{"hierarchy":{"lvl1":"The (1D) Newton-Raphson Method","lvl3":"An example","lvl2":"The algorithm"},"type":"lvl3","url":"/nr-1d#an-example","position":4},{"hierarchy":{"lvl1":"The (1D) Newton-Raphson Method","lvl3":"An example","lvl2":"The algorithm"},"content":"Suppose we want to find the value of 1/\\sqrt{c} for some known value of c. We could reframe this problem as:x^2=1/c \\implies 1/x^2=c \\implies \\frac{1}{x^2}-c = 0 = f(x)\n\nand, to perform the algorithm, we will need f'(x)=-2x^{-3}. Assembling generally into the algorithm’s main equation:x_{i+1} = x_i - \\frac{1/x^2-c}{-2x^{-3}} \\implies x_{i+1} = x_i - \\frac{1}{2}\\left(c x_i^3 -x_i\\right).\n\nTo make it concrete, let’s choose c=11, and we’ll need a seed guess... \\sqrt{9}=3, so how about x_0=1/3?\n\nProceeding: x_1=0.296296, x_2=0.301377, x_3=0.301511, x_4=0.301511... it seems we have converged very quickly! The actual answer is 0.301511.\n\nTip\n\nI did these calculations on \n\nWolfram Alpha using the “natural language” input: x - 1/2*(11* x^3 -x) at x=1/3, and then changed the x=... with each iteration.\n\n\n\nThe first and second iterations of Newton-Raphson (red arrows) for f(x)=x^{-2}-11 (in blue), beginning with seed x_0=0.333. Converges pretty quickly!\n\nCheck out...\n\n...this discussion of \n\nthe fast inverse square root used in the game Quake III. The first step in their algorithm is a mysterious “bit-fiddling technique” (wherein bits stored in a float just change positions), but then they used a Newton-Raphson step to improve the accuracy of the calculation.","type":"content","url":"/nr-1d#an-example","position":5},{"hierarchy":{"lvl1":"Newton-Raphson Method (2+D)"},"type":"lvl1","url":"/nr-2d","position":0},{"hierarchy":{"lvl1":"Newton-Raphson Method (2+D)"},"content":"The \n\n(1D) Newton-Raphson Method can be extended to higher dimensional systems. Suppose we have two equations,\ny=mx+b and x^2 + y^2 = R^2, with known constants m, b, and R.\n\nNote\n\nSo, a line and a circle. Keep in mind that there may be zero, one, or two solutions...\n\nWe can rearrange this into the system:mx-y+b=0\\\\\nx^2+y^2-R^2=0\n\nand call that first equation f(x,y)=0 and the second g(x,y)=0. So it is like a simultaneous root-finding problem. The \n\nTaylor Series idea can be extrapolated to 2+ dimensions based on a reference location (x_0,y_0). Examining the linearized versions of general f and g:f(x,y)\\approx f(x_0,y_0) + \\frac{\\partial f}{\\partial x}\\bigg\\rvert_0 (x-x_0) + \\frac{\\partial f}{\\partial y}\\bigg\\rvert_0 (y-y_0)\\\\\ng(x,y)\\approx g(x_0,y_0) + \\frac{\\partial g}{\\partial x}\\bigg\\rvert_0 (x-x_0) + \\frac{\\partial g}{\\partial y}\\bigg\\rvert_0 (y-y_0)\n\nwhere, e.g., \\partial f/\\partial y\\rvert_0 is evaluated at (x_0,y_0). Similar to in the 1D case, we can set f(x,y)=0 and g(x,y)=0 and rearrange to:\\frac{\\partial f}{\\partial x}\\bigg\\rvert_0 (x-x_0) + \\frac{\\partial f}{\\partial y}\\bigg\\rvert_0 (y-y_0) = -f(x_0,y_0)\\\\\n\\frac{\\partial g}{\\partial x}\\bigg\\rvert_0 (x-x_0) + \\frac{\\partial g}{\\partial y}\\bigg\\rvert_0 (y-y_0)= -g(x_0,y_0)\n\nand can then reframe this as a matrix system, defining \\Delta x\\equiv x-x_0 and \\Delta y=y-y_0:\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x} & \\frac{\\partial f}{\\partial y}\\\\\n\\frac{\\partial g}{\\partial x} & \\frac{\\partial g}{\\partial y}\n\\end{bmatrix}_0\n\\begin{bmatrix}\n\\Delta x\\\\ \\Delta y\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-f\\\\ -g\n\\end{bmatrix}_0.\n\nNote that the matrix and right-hand side of this equation are evaluated at the reference location to determine the unknown vector of displacements (\\Delta x,\\Delta y).\n\nNote\n\nA matrix full of partial derivatives like this is called “The Jacobian”. And in the general linear algebra problem \\mathbf{Ax}=\\mathbf{b}, the \\mathbf{b} is sometimes called “the forcing function” -- in this context, the further f and g are from zero, the greater \\Delta x and \\Delta y are, and so there is a greater “push” from the current location.\n\nAs was the case with the 1D Newton-Raphson Method, we think about this not as a single step, but rather an iterative scheme:\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x} & \\frac{\\partial f}{\\partial y}\\\\\n\\frac{\\partial g}{\\partial x} & \\frac{\\partial g}{\\partial y}\n\\end{bmatrix}_i\n\\begin{bmatrix}\n\\Delta x\\\\ \\Delta y\n\\end{bmatrix}_i\n=\n\\begin{bmatrix}\n-f\\\\ -g\n\\end{bmatrix}_i\n\nwhere x_{i+1}=x_i + \\Delta x_i and y_{i+1} = y_i +\\Delta y_i.","type":"content","url":"/nr-2d","position":1},{"hierarchy":{"lvl1":"Newton-Raphson Method (2+D)","lvl2":"The algorithm"},"type":"lvl2","url":"/nr-2d#the-algorithm","position":2},{"hierarchy":{"lvl1":"Newton-Raphson Method (2+D)","lvl2":"The algorithm"},"content":"The algorithm matches that of the 1D Newton-Raphson method, but let’s clarify the details.\n\nThe two functions and four partial derivatives must be provided as functions, as well as a seed value.\n\nThe Jacobian and forcing function of the iterative equation above can be evaluated.\n\nSolving the matrix system tells us how to update our estimation of the solution.\n\nIterate until convergence or until we give up.","type":"content","url":"/nr-2d#the-algorithm","position":3},{"hierarchy":{"lvl1":"Newton-Raphson Method (2+D)","lvl2":"Solving the matrix system"},"type":"lvl2","url":"/nr-2d#solving-the-matrix-system","position":4},{"hierarchy":{"lvl1":"Newton-Raphson Method (2+D)","lvl2":"Solving the matrix system"},"content":"Finding the inverse of a matrix is actually a challenging computational problem. We will learn a computer-friendly version of Gaussian Elimination shortly, but for a small system like this, \n\nCramer’s Rule is reasonable.","type":"content","url":"/nr-2d#solving-the-matrix-system","position":5},{"hierarchy":{"lvl1":"Root-Finding Methods Intro"},"type":"lvl1","url":"/root-finding-intro","position":0},{"hierarchy":{"lvl1":"Root-Finding Methods Intro"},"content":"Most of your work in traditional lecture classes involves pushing around equations until you can settle on something like:F = \\frac{\\pi}{2}\\rho U^2 R^2.\n\nThat is, you can usually “explicitly” solve for the variable you are interested using algebra. In practice, it doesn’t always work out so neatly. A classic example is the Colebrook Equation, which is used to determine the pressure drop in pipe flow:\\frac{1}{\\sqrt{f}} = -2 \\log\\left(\\frac{\\epsilon/D}{3.7}+\\frac{2.51}{\\text{Re}\\sqrt{f}}\\right)\n\nNotice that f appears both within the logarithm argument and outside the logarithm argument. This means it can’t be solved for explicitly... i.e., you cannot arrive at f=\\text{something} where the “something” is fundamental mathematical functions like \\exp, \\log, etc. To solve these problems, engineers have traditionally looked at a chart -- \n\nthe Moody Diagram. But we can also use “root-finding methods” to solve algebraic equations.","type":"content","url":"/root-finding-intro","position":1},{"hierarchy":{"lvl1":"Root-Finding Methods Intro","lvl2":"Root-Finding Algorithms"},"type":"lvl2","url":"/root-finding-intro#root-finding-algorithms","position":2},{"hierarchy":{"lvl1":"Root-Finding Methods Intro","lvl2":"Root-Finding Algorithms"},"content":"This type of problem could be called “algebraic equation solving”, but actually we need to use the special properties of zero in our algorithms. That is, we must examine an equation in the form g(x)=0, and we are finding the roots: the x-locations that make g(x)=0.\n\nAny equation, A(x)=B(x) can be turned into a root-finding problem by rearranging to A(x)-B(x)=0 and then working with g(x)\\equiv A(x)-B(x). For example, with the Colebrook Equation, we might manipulate it to\\frac{1}{\\sqrt{f}} +2 \\log\\left(\\frac{\\epsilon/D}{3.7}+\\frac{2.51}{\\text{Re}\\sqrt{f}}\\right) =0","type":"content","url":"/root-finding-intro#root-finding-algorithms","position":3},{"hierarchy":{"lvl1":"Root-Finding Methods Intro","lvl2":"Types of Root-Finding Methods"},"type":"lvl2","url":"/root-finding-intro#types-of-root-finding-methods","position":4},{"hierarchy":{"lvl1":"Root-Finding Methods Intro","lvl2":"Types of Root-Finding Methods"},"content":"There are two classes of root-finding methods:\n\n“Bracketed” methods are called as such because you place a lower and upper limit on your search range. These have a few downsides in general:\n\nYou must have some idea of where the root is located.\n\nThey tend to be slow to converge.\n\nIf there are two roots within the range, the algorithm may break.\nHowever, at least if there is only one root within the brackets, it is guaranteed to find it.\n\n“Open” methods are called as such because their search range is not limited. The downsides are:\n\nThey are not guaranteed to find the root.\n\nBecause they aren’t confined to a certain region, they may accidentally find “the wrong root”. E.g. you want the positive solution, you find the negative one.\n\nYou may need to do some prep work, e.g. calculating a derivative or rearranging g(x)=0 to something slightly different, a h(x)=0 (e.g., h(x)\\equiv g(x)/x... it is still equal to zero).\nHowever, they can converge more quickly than bracketed methods. Additionally, the main one we will discuss (Newton-Raphson) can be implemented in higher dimensions -- it works for g(x)=0; it also works for the system f(x,y)=0, g(x,y)=0; and further, with f(x,y,z)=0,g(x,y,z)=0,h(x,y,z)=0.\n\nEven higher dimensions too, but I don’t want to write it out!","type":"content","url":"/root-finding-intro#types-of-root-finding-methods","position":5},{"hierarchy":{"lvl1":"Root-Finding Methods Intro","lvl2":"The wrong way to do it"},"type":"lvl2","url":"/root-finding-intro#the-wrong-way-to-do-it","position":6},{"hierarchy":{"lvl1":"Root-Finding Methods Intro","lvl2":"The wrong way to do it"},"content":"The following will get you the root if one exists on a given range. Let’s assume we have a lower limit to the search, x_L, and upper limit to the search, x_U, and a spacing dx. And we’ll just use an anonymous function defined as f.\n\nx=x_L:dx:x_U;\ny=f(x);\n[~,idx]=min(abs(y));\nx_root=x(idx);\n\nx = np.arange(x_L, x_U, dx)\ny = f(x)\nidx = np.argmin(np.abs(y))\nx_root = x[idx]\n\nx = x_L:dx:x_U\ny = f.(x)\n_, idx = findmin(abs.(y))\nx_root = x[idx]\n\nThe downside of this approach is: we calculated the value of the function at every value of x, and then performed a second operation that checked over all of those values (min/argmin/findmin). A lot of calculations! We will call this a “brute force” method, because we are essentially just checking every possibility.\n\nWe will see that the methods described in this unit can achieve the same goal with significantly fewer operations, meaning they are much faster.\n\nTip\n\nWe will write functions for these algorithms, and the equation f(x) will be an input to those functions. Revisit \n\nanonymous functions in the coding elements pages... that is how we will do it!","type":"content","url":"/root-finding-intro#the-wrong-way-to-do-it","position":7},{"hierarchy":{"lvl1":"The Bisection Method"},"type":"lvl1","url":"/bisection","position":0},{"hierarchy":{"lvl1":"The Bisection Method"},"content":"The Bisection Method is the canonical example of a bracketing method. Assuming that a function f(x) is continuous and that precisely one root exists in a search range x_L\\rightarrow x_U, it iteratively halves the size of the search range until we say “good enough”. So: we might start the search knowing the root is between 0 and 100, a range of 100; after one iteration, we will be able to halve that to 50, after two iterations, 25, ... , after six iterations, we can say with confidence that the root lies within a range of 0.78125. Another way to say that: we pinpoint the root to x_\\text{root}\\pm 0.390625.\n\nNote\n\nThroughout this class, we will often sketch out functions to try to explain/understand algorithms. However, it is usually the case that we don’t actually know what the function looks like... otherwise we’d just say “the root is right there!” In the video, we made a sketch, here we will do something a bit more authentic.","type":"content","url":"/bisection","position":1},{"hierarchy":{"lvl1":"The Bisection Method","lvl2":"The algorithm"},"type":"lvl2","url":"/bisection#the-algorithm","position":2},{"hierarchy":{"lvl1":"The Bisection Method","lvl2":"The algorithm"},"content":"0. For a given function f(x), we define a search region between x_L (“x lower”) and x_U (“x upper”). There must be precisely one root on this range, else the algorithm breaks!1. Calculate x_M (“x middle”) as (x_L+x_U)/2.2. Calculate f(x_L), f(x_M), and f(x_U) and consider the sign of f(x_L)\\cdot f(x_M) OR f(x_M)\\cdot f(x_U). (See discussion below about making your code more robust.)3a. If f(x_L)\\cdot f(x_M)< 0, that means that the function changes sign somewhere between x_L and x_M. That is, the root is between x_L and x_M.4a. We reset: x_U=x_M and go back to step (1) (where we will use our new definition of x_U to calculate the next x_M).\n\nThe other possibility is:\n\n3b. If f(x_M)\\cdot f(x_U)< 0, that means that the function changes sign somewhere between x_M and x_U. That is, the root is between x_M and x_U.4b. We reset: x_L=x_M and go back to step (1) (where we will use our new definition of x_L to calculate the next x_M).","type":"content","url":"/bisection#the-algorithm","position":3},{"hierarchy":{"lvl1":"The Bisection Method","lvl3":"An example","lvl2":"The algorithm"},"type":"lvl3","url":"/bisection#an-example","position":4},{"hierarchy":{"lvl1":"The Bisection Method","lvl3":"An example","lvl2":"The algorithm"},"content":"What happens for f(x)=\\sin(x)-0.85? If we are seeking the first root, we know it will exist between x_L=0 and x_U=\\pi/2, and then x_M=\\pi/4. (We might call \\pi/4 our initial estimate of the root, and could say: x_\\text{root,0}=\\pi/4\\pm \\pi/4.)\n\nLet’s put it in a table, calling the setup above the zeroth iteration:\n\niteration\n\nx_L\n\nx_M\n\nx_U\n\nf(x_L)\n\nf(x_M)\n\nf(x_U)\n\n0\n\n0\n\n\\pi/4\n\n\\pi/2\n\n-0.85\n\n-0.1428\n\n0.15\n\nSince f(\\pi/4)\\cdot f(\\pi/2)<0, we know the root is between x_M and x_U, so: we reset x_L=x_M=\\pi/4, keep x_U=\\pi/2, and calculate a new x_M=3\\pi/8. (After one iteration, our estimate of the root is x_\\text{root,1}=3\\pi/8\\pm \\pi/8.) A few more steps:\n\niteration\n\nx_L\n\nx_M\n\nx_U\n\nf(x_L)\n\nf(x_M)\n\nf(x_U)\n\n1\n\n\\pi/4\n\n3\\pi/8\n\n\\pi/2\n\n-0.1428\n\n0.0739\n\n0.15\n\n2\n\n\\pi/4\n\n5\\pi/16\n\n3\\pi/8\n\n-0.1428\n\n-0.0185\n\n0.0739\n\n3\n\n5\\pi/16\n\n11\\pi/32\n\n3\\pi/8\n\n-0.0185\n\n0.0319\n\n0.0739\n\n... and we could say: after three iterations, our estimate of the root is x_\\text{root,3}=11\\pi/32\\pm \\pi/32.","type":"content","url":"/bisection#an-example","position":5},{"hierarchy":{"lvl1":"The Bisection Method","lvl3":"Making the algorithm more robust","lvl2":"The algorithm"},"type":"lvl3","url":"/bisection#making-the-algorithm-more-robust","position":6},{"hierarchy":{"lvl1":"The Bisection Method","lvl3":"Making the algorithm more robust","lvl2":"The algorithm"},"content":"We may not actually be certain there is a root within the range we provide, or there may be two roots. In either case, this algorithm fails. It might be a good idea to check the values of both f(x_L)\\cdot f(x_M) and f(x_M)\\cdot f(x_U) and return an error message if both are >0 or both are <0.\n\nIt is also possible, but unlikely, that f(x_L)==0, or f(x_M)==0, or f(x_U)==0. In any of these cases, the algorithm should promptly end.\n\nConsider the break or return commands. See the \n\ncoding elements page.","type":"content","url":"/bisection#making-the-algorithm-more-robust","position":7},{"hierarchy":{"lvl1":"The Secant Method"},"type":"lvl1","url":"/secant","position":0},{"hierarchy":{"lvl1":"The Secant Method"},"content":"Briefly: There is a cousin to Newton-Raphson Method known as “The Secant Method”, which notably does not require us to calculate and input an analytical derivative into the algorithm.","type":"content","url":"/secant","position":1},{"hierarchy":{"lvl1":"The Secant Method","lvl2":"The algorithm"},"type":"lvl2","url":"/secant#the-algorithm","position":2},{"hierarchy":{"lvl1":"The Secant Method","lvl2":"The algorithm"},"content":"The algorithm is very similar to \n\nNewton-Raphson, whose equation I will repeat here:x_i=x_{i-1}- \\frac{f(x_{i-1})}{f'(x_{i-1})}.\n\nInstead of an analytical derivative, we compute an approximate derivative:f'(x_{i-1})\\approx \\frac{f(x_{i-1})-f(x_{i-2})}{x_{i-1}-x_{i-2}}\n\nso that the algorithm’s core equation becomesx_i=x_{i-1}- f(x_{i-1})\\frac{x_{i-1}-x_{i-2}}{f(x_{i-1})-f(x_{i-2})}.\n\nWe will need two seed guesses to get this started, but otherwise the algorithm matches that of Newton-Raphson.","type":"content","url":"/secant#the-algorithm","position":3},{"hierarchy":{"lvl1":"The Secant Method","lvl2":"Picking the seed guesses"},"type":"lvl2","url":"/secant#picking-the-seed-guesses","position":4},{"hierarchy":{"lvl1":"The Secant Method","lvl2":"Picking the seed guesses"},"content":"As with all open methods, there is a chance that this algorithm does not converge, and so seed choice can be important. However, while spiritually we are approximating the analytical derivative, the algorithm does not need us to choose an infinitesimal separation between seed values.\n\nA demo: In this first case, the seed values are 0.5 and 0.6, and so the secant line is similar to the tangent line.\n\n\n\nSecant Method with seeds 0.5 and 0.6, for f(x) = exp(x)-3.91. The initial secant line is reminiscent of the tangent line at x=0.6, but that is not the case with further iterations. Yet we still converge!\n\nSame problem, but now the seed values are 0 and 1.9.\n\n\n\nSecant Method with seeds 0 and 1.9, again for f(x) = exp(x)-3.91. The initial secant line is not at all reminiscent of the tangent line at x=0 or x=1.9, yet we still converge to the root.\n\nTip\n\nTrace these paths and make sure you understand how the points are related by this algorithm.","type":"content","url":"/secant#picking-the-seed-guesses","position":5},{"hierarchy":{"lvl1":"LU Decomposition"},"type":"lvl1","url":"/lu","position":0},{"hierarchy":{"lvl1":"LU Decomposition"},"content":"Many analyses in engineering can be boiled-down to: solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}. For a square matrix with a non-zero determinant, the solution is:\\mathbf{x}=\\mathbf{A}^{-1}\\mathbf{b}\n\nbut how do we get the inverse? For small matrices there are formulas available, but computational methods is not about handling small matrices!\n\nThe \\mathbf{LU} decomposition is essentially a formalized version of Gaussian Elimination -- that technique where you subtract rows from each other until you isolate a single unknown in an equation. This can be used to find a matrix inverse, i.e., to solve \\mathbf{A}\\mathbf{x}=\\mathbf{b}.\n\nMATLAB/NumPy/Julia use \\mathbf{LU} in their calculation of the matrix inverse. We will build-up a similar functionality, without leaning on the built-in version. Row operations!","type":"content","url":"/lu","position":1},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"LU decomposition"},"type":"lvl2","url":"/lu#lu-decomposition","position":2},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"LU decomposition"},"content":"","type":"content","url":"/lu#lu-decomposition","position":3},{"hierarchy":{"lvl1":"LU Decomposition","lvl3":"Summary","lvl2":"LU decomposition"},"type":"lvl3","url":"/lu#summary","position":4},{"hierarchy":{"lvl1":"LU Decomposition","lvl3":"Summary","lvl2":"LU decomposition"},"content":"We seek the solution \\mathbf{x} to\\mathbf{A}\\mathbf{x} = \\mathbf{b}\n\nwhere n\\times n matrix \\mathbf{A} and forcing function \\mathbf{b} are known. Our goal is to use row operations to obtain\\mathbf{U}\\mathbf{x} = \\mathbf{d}\n\nwhere \\mathbf{U} is an upper-triangular matrix and \\mathbf{d} is related to the forcing function. With an upper-triangular matrix, the back-substitution algorithm quickly reveals the solution.","type":"content","url":"/lu#summary","position":5},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"LU decomposition"},"type":"lvl2","url":"/lu#lu-decomposition-1","position":6},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"LU decomposition"},"content":"","type":"content","url":"/lu#lu-decomposition-1","position":7},{"hierarchy":{"lvl1":"LU Decomposition","lvl3":"Upper-triangular matrix \\mathbf{U}","lvl2":"LU decomposition"},"type":"lvl3","url":"/lu#upper-triangular-matrix-mathbf-u","position":8},{"hierarchy":{"lvl1":"LU Decomposition","lvl3":"Upper-triangular matrix \\mathbf{U}","lvl2":"LU decomposition"},"content":"Beginning with the general\\mathbf{A}\\equiv\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13} & a_{14} & a_{15} & ... & a_{1n}\\\\\na_{21} & a_{22} & a_{23} & a_{24} & a_{25} & ... & a_{2n} \\\\\na_{31} & a_{32} & a_{33} & a_{34} & a_{35} & ... & a_{3n} \\\\\na_{41} & a_{42} & a_{43} & a_{44} & a_{45} & ... & a_{4n} \\\\\na_{51} & a_{52} & a_{53} & a_{54} & a_{55} & ... & a_{5n} \\\\\n⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮\\\\\na_{n1} & a_{n2} & a_{n3} & a_{n4} & a_{n5} & ... & a_{nn}\n\\end{bmatrix}\n\nwe perform a series of row operations to make the first column zero (except for the first entry in the column). This can be achieved via\\begin{alignat*}{2}\n    (\\text{second row})&\\rightarrow (\\text{second row})-&&\\frac{a_{21}}{a_{11}}(\\text{first row})\\\\\n    (\\text{third row})&\\rightarrow (\\text{third row})-&&\\frac{a_{31}}{a_{11}}(\\text{first row})\\\\\n    (\\text{fourth row})&\\rightarrow (\\text{fourth row})-&&\\frac{a_{41}}{a_{11}}(\\text{first row})\n\\end{alignat*}\n\nwhere the \\rightarrow can be interpreted as “becomes”.\n\nCaution\n\nWhat happens if a_{11}=0? The coefficient blows up! We need to rearrange the rows such that this is not the case. This is called pivoting, and we will not really worry about it in this class.\n\nAfter proceeding through all n rows, we will have developed an intermediate matrix\\mathbf{A'}\\equiv\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13} & a_{14} & a_{15} & ... & a_{1n}\\\\\n0 & a'_{22} & a'_{23} & a'_{24} & a'_{25} & ... & a'_{2n} \\\\\n0 & a'_{32} & a'_{33} & a'_{34} & a'_{35} & ... & a'_{3n} \\\\\n0 & a'_{42} & a'_{43} & a'_{44} & a'_{45} & ... & a'_{4n} \\\\\n0 & a'_{52} & a'_{53} & a'_{54} & a'_{55} & ... & a'_{5n} \\\\\n⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮\\\\\n0 & a'_{n2} & a'_{n3} & a'_{n4} & a'_{n5} & ... & a'_{nn}\n\\end{bmatrix}.\n\nIf we proceed similarly with\\begin{alignat*}{2}\n    (\\text{new third row})&\\rightarrow (\\text{new third row})-&&\\frac{a'_{32}}{a'_{22}}(\\text{new second row})\\\\\n    (\\text{new fourth row})&\\rightarrow (\\text{new fourth row})-&&\\frac{a'_{42}}{a'_{22}}(\\text{new second row})\n\\end{alignat*}\n\nwe will arrive at\\mathbf{A''}\\equiv\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13} & a_{14} & a_{15} & ... & a_{1n}\\\\\n0 & a'_{22} & a'_{23} & a'_{24} & a'_{25} & ... & a'_{2n} \\\\\n0 & 0 & a''_{33} & a''_{34} & a''_{35} & ... & a''_{3n} \\\\\n0 & 0 & a''_{43} & a''_{44} & a''_{45} & ... & a''_{4n} \\\\\n0 & 0 & a''_{53} & a''_{54} & a''_{55} & ... & a''_{5n} \\\\\n⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮\\\\\n0 & 0 & a''_{n3} & a''_{n4} & a''_{n5} & ... & a''_{nn}\n\\end{bmatrix}.\n\nand can continue with this process until we arrive at\\mathbf{U}\\equiv\\mathbf{A}''''''\\phantom{.}^{...}\\equiv\n\\begin{bmatrix}\na_{11} & a_{12} & a_{13} & a_{14} & a_{15} & ... & a_{1n}\\\\\n0 & a'_{22} & a'_{23} & a'_{24} & a'_{25} & ... & a'_{2n} \\\\\n0 & 0 & a''_{33} & a''_{34} & a''_{35} & ... & a''_{3n} \\\\\n0 & 0 & 0 & a'''_{44} & a'''_{45} & ... & a'''_{4n} \\\\\n0 & 0 & 0 & 0 & a''''_{55} & ... & a''''_{5n} \\\\\n⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮\\\\\n0 & 0 & 0 & 0 & 0 & ... & a''''''\\phantom{.}^{...}_{nn}\n\\end{bmatrix}\\equiv\n\\begin{bmatrix}\nu_{11} & u_{12} & u_{13} & u_{14} & u_{15} & ... & u_{1n}\\\\\n0 & u_{22} & u_{23} & u_{24} & u_{25} & ... & u_{2n} \\\\\n0 & 0 & u_{33} & u_{34} & u_{35} & ... & u_{3n} \\\\\n0 & 0 & 0 & u_{44} & u_{45} & ... & u_{4n} \\\\\n0 & 0 & 0 & 0 & u_{55} & ... & u_{5n} \\\\\n⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮\\\\\n0 & 0 & 0 & 0 & 0 & ... & u_{nn}\n\\end{bmatrix}.\n\n(You maybe will need to scroll right to see all that equation!) This is the upper-triangular matrix \\mathbf{U} that will be useful in the back-substitution algorithm.","type":"content","url":"/lu#upper-triangular-matrix-mathbf-u","position":9},{"hierarchy":{"lvl1":"LU Decomposition","lvl3":"Lower-triangular matrix \\mathbf{L}","lvl2":"LU decomposition"},"type":"lvl3","url":"/lu#lower-triangular-matrix-mathbf-l","position":10},{"hierarchy":{"lvl1":"LU Decomposition","lvl3":"Lower-triangular matrix \\mathbf{L}","lvl2":"LU decomposition"},"content":"The row operations described above can be made mathematical by a multiplication by\\mathbf{L}\\equiv\n\\begin{bmatrix}\n1 & 0 & 0 & 0 & 0 & ... & 0\\\\\na_{21}/a_{11} & 1 & 0 & 0 & 0 & ... & 0 \\\\\na_{31}/a_{11} & a'_{32}/a'_{22} & 1 & 0 & 0 & ... & 0 \\\\\na_{41}/a_{11} & a'_{42}/a'_{22} & a''_{43}/a''_{33} & 1 & 0 & ... & 0 \\\\\na_{51}/a_{11} & a'_{52}/a'_{22} & a''_{53}/a''_{33} & a'''_{54}/a'''_{44} & 1 & ... & 0 \\\\\n⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋱ & ⋮\\\\\na_{n1}/a_{11} & a'_{n2}/a'_{22} & a''_{n3}/a''_{33} & a'''_{n4}/a'''_{44} & a''''_{n5}/a''''_{55} & ... & 1\n\\end{bmatrix}\n\nas in, \\mathbf{L}\\mathbf{U}=\\mathbf{A}. Note that the lower-triangular entries are the same as the multipliers we used in the algorithm to get \\mathbf{U}. The creation of \\mathbf{L} is practically a by-product of generating \\mathbf{U}.","type":"content","url":"/lu#lower-triangular-matrix-mathbf-l","position":11},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"The Forward-Substitution Algorithm"},"type":"lvl2","url":"/lu#the-forward-substitution-algorithm","position":12},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"The Forward-Substitution Algorithm"},"content":"Beginning with \\mathbf{Ux}=\\mathbf{d}, we multiply both sides by \\mathbf{L} to obtain\\mathbf{L}\\mathbf{U}\\mathbf{x} = \\mathbf{L}\\mathbf{d}.\n\nSince \\mathbf{L}\\mathbf{U}=\\mathbf{A}, this reveals that\\mathbf{L}\\mathbf{d}=\\mathbf{b}.\n\nBecause \\mathbf{L} is a lower-triangular matrix, determination of \\mathbf{d} is relatively straightforward via the Forward-Substitution Algorithm. Framed in terms of a generic lower-triangular matrix with entries \\ell_{ij}, the first three steps are:\\begin{alignat*}{2}\n\\ell_{11}d_1 & ~ &&= b_1 \\implies d_1 = \\frac{1}{\\ell_{11}}b_1\\\\\n\\ell_{21}d_1 & +\\ell_{22}d_2  &&= b_2 \\implies d_2 = \\frac{1}{\\ell_{22}}\\left(b_2-\\ell_{21}d_1\\right)\\\\\n\\ell_{31}d_1 & +\\ell_{32}d_2+\\ell_{33}d_3 &&= b_3 \\implies d_3 = \\frac{1}{\\ell_{33}}\\left(b_3-\\ell_{31}d_1-\\ell_{32}d_2\\right)\n\\end{alignat*}\n\nand generallyd_i = \\frac{1}{\\ell_{ii}}\\left(\n    b_i-\\sum_{j=1}^{i-1} \\ell_{ij}d_j\n    \\right).\n\nWe use this to generate \\mathbf{d} from the given forcing function \\mathbf{b}.","type":"content","url":"/lu#the-forward-substitution-algorithm","position":13},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"The Backward-Substitution Algorithm"},"type":"lvl2","url":"/lu#the-backward-substitution-algorithm","position":14},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"The Backward-Substitution Algorithm"},"content":"Beginning with \\mathbf{Ux}=\\mathbf{d}, and since \\mathbf{U} is an upper-triangular matrix, and since we known \\mathbf{d} after going through the forward-substitution algorithm above, we can determine the solution \\mathbf{x} via the backward-substitution algorithm. Framed in terms of a generic upper-triangular matrix with entries u_{ij}, for a a matrix with n rows, the first three steps are:\\begin{alignat*}{2}\nu_{nn}x_n &= d_n &&\\implies x_n = d_n/u_{nn}\\\\\nu_{(n-1)(n-1)}x_{n-1} +u_{(n-1)(n)}x_{n}  &= d_{n-1} &&\\implies x_{n-1}=\\frac{1}{u_{(n-1)(n-1)}}\\left(d_{n-1}-u_{(n-1)(n)}x_{n}\\right)\\\\\nu_{(n-2)(n-2)}x_{n-2} +\nu_{(n-2)(n-1)}x_{n-1} +u_{(n-2)(n)}x_{n} &= d_{n-2} &&\\implies\\\\\n&x_{n-2}=&&\\frac{1}{u_{(n-2)(n-2)}}\\left(d_{n-2}-u_{(n-2)(n-1)}x_{n-1} -u_{(n-2)(n)}x_{n}\\right)\n\\end{alignat*}\n\nand generallyx_i = \\frac{1}{u_{ii}}\\left(\n    d_i-\\sum_{j=i+1}^{n} u_{ij}x_j\n    \\right).\n\nThis expression is mathematically correct, but it’s implementation is tricky: this algorithm must proceed backwards: i=n, then i=n-1, etc.","type":"content","url":"/lu#the-backward-substitution-algorithm","position":15},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"Starter code"},"type":"lvl2","url":"/lu#starter-code","position":16},{"hierarchy":{"lvl1":"LU Decomposition","lvl2":"Starter code"},"content":"... can be found \n\nhere.","type":"content","url":"/lu#starter-code","position":17},{"hierarchy":{"lvl1":"LU Decomposition Starter"},"type":"lvl1","url":"/lu-starter","position":0},{"hierarchy":{"lvl1":"LU Decomposition Starter"},"content":"Here are some skeleton codes to get you started","type":"content","url":"/lu-starter","position":1},{"hierarchy":{"lvl1":"LU Decomposition Starter","lvl2":"LU Decomposition"},"type":"lvl2","url":"/lu-starter#lu-decomposition","position":2},{"hierarchy":{"lvl1":"LU Decomposition Starter","lvl2":"LU Decomposition"},"content":"function [L,U] = LU_decomp(A)\n% LU_decomp performs the LU decomposition on a general matrix A using \n%   input:      A= a square matrix\n%   outputs:    L= a lower-triangular matrix\n%               U= an upper-triangular matrix\n\nn=length(A);    % length of a matrix is its number of columns.\n\nU=A;            % Initialize U as A, though it is not U yet -- must iterate.\nL=eye(size(A)); % L has 1s along its diagonal, initialize with \"eye\"\n\n% Big-picture: we go through elements 2->n in the first column to get an\n% intermediate matrix, and then 3->n in the second column ... we will\n% use nested for loops.\n\nfor i=1:n-1     % row i, multiplied by a scalar, is used to change...\n    for j=?:? % ... row j\n        k= % the multiplier\n        U(?,?)=U(?,?)-k*U(?,?); % make sure not to change the rows before i!\n        L(?,?)=k;\n    end\nend\n\nend\n\nDon’t forget Python indexes from zero!import numpy as np\n\ndef LU_decomp(A):\n    # LU_decomp performs the LU decomposition on a general matrix A using \n    #   input:      A= a square matrix\n    #   outputs:    L= a lower-triangular matrix\n    #               U= an upper-triangular matrix\n\n    n = len(A)    # length of a matrix is its number of columns.\n\n    U = A.copy()           # Initialize U as A, though it is not U yet -- must iterate.\n    L = np.eye(A.shape[0]) # L has 1s along its diagonal, initialize with \"eye\"\n\n    # Big-picture: we go through elements 2->n in the first column to get an\n    # intermediate matrix, and then 3->n in the second column ... we will\n    # use nested for loops.\n\n    for i in range(n-1):     # row i, multiplied by a scalar, is used to change...\n        for j in range(?, ?): # ... row j\n            k = ? # the multiplier\n            U[?, ?] = U[?, ?] - k * U[?, ?] # make sure not to change the rows before i!\n            L[?, ?] = k\n            \n    return L, U\n\nusing LinearAlgebra\n\nfunction LU_decomp(A)\n    # LU_decomp performs the LU decomposition on a general matrix A using \n    #   input:      A= a square matrix\n    #   outputs:    L= a lower-triangular matrix\n    #               U= an upper-triangular matrix\n\n    n = size(A, 2)    # length of a matrix is its number of columns.\n\n    U = copy(A)       # Initialize U as A, though it is not U yet -- must iterate.\n    L = Matrix{Float64}(I, size(A)) # L has 1s along its diagonal, initialize with \"eye\" (requires `using LinearAlgebra`)\n\n    # Big-picture: we go through elements 2->n in the first column to get an\n    # intermediate matrix, and then 3->n in the second column ... we will\n    # use a nested for loop.\n\n    for i = 1:n-1     # row i, multiplied by a scalar, is used to change...\n        for j = ?:?   # ... row j\n            k = ?     # the multiplier\n            U[?, ?] = U[?, ?] - k * U[?, ?] # make sure not to change the rows before i!\n            L[?, ?] = k\n        end\n    end\n\n    return L, U\nend","type":"content","url":"/lu-starter#lu-decomposition","position":3},{"hierarchy":{"lvl1":"LU Decomposition Starter","lvl2":"Forward-Substitution Algorithm"},"type":"lvl2","url":"/lu-starter#forward-substitution-algorithm","position":4},{"hierarchy":{"lvl1":"LU Decomposition Starter","lvl2":"Forward-Substitution Algorithm"},"content":"function [d] = forward_sub(L,b)\n% forward_sub uses the forward-substitution algorithm to solve the equation\n% Ld = b for a lower-triangular matrix L\n% inputs:   L= a lower-triangular matrix\n%           b= a vector \"forcing function\"\n% output:   x= the solution to Ld = b\n\nn=length(b);\nd=zeros(size(b));\n\n% Use a for loop that counts from i=1 to n.\n% Within that loop, you will need to calculate a new sum each time.\n% I recommend re-initializing a variable called S, at zero,\n% and then computing the sum with a second for loop.\n\nend\n\nimport numpy as np\n\ndef forward_sub(L, b):\n    # forward_sub uses the forward-substitution algorithm to solve the equation\n    # Ld = b for a lower-triangular matrix L\n    # inputs:   L= a lower-triangular matrix\n    #           b= a vector \"forcing function\"\n    # output:   x= the solution to Ld = b\n\n    n = len(b)\n    d = np.zeros(b.shape)\n\n    # Use a for loop that counts from i=1 to n.\n    # Within that loop, you will need to calculate a new sum each time.\n    # I recommend re-initializing a variable called S, at zero,\n    # and then computing the sum with a second for loop.\n    \n    return d\n\nfunction forward_sub(L, b)\n    # forward_sub uses the forward-substitution algorithm to solve the equation\n    # Ld = b for a lower-triangular matrix L\n    # inputs:   L= a lower-triangular matrix\n    #           b= a vector \"forcing function\"\n    # output:   x= the solution to Ld = b\n\n    n = length(b)\n    d = zeros(size(b))\n\n    # Use a for loop that counts from i=1 to n.\n    # Within that loop, you will need to calculate a new sum each time.\n    # I recommend re-initializing a variable called S, at zero,\n    # and then computing the sum with a second for loop.\n\n    return d\nend","type":"content","url":"/lu-starter#forward-substitution-algorithm","position":5},{"hierarchy":{"lvl1":"LU Decomposition Starter","lvl2":"Backward-Substitution Algorithm"},"type":"lvl2","url":"/lu-starter#backward-substitution-algorithm","position":6},{"hierarchy":{"lvl1":"LU Decomposition Starter","lvl2":"Backward-Substitution Algorithm"},"content":"function [x] = back_sub(U,d)\n% backsub uses the back-substitution algorithm to solve the equation Ux = d\n% for an upper-triangular matrix U\n% inputs:   U= an upper-triangular matrix\n%           d= modified forcing function, as in Ld=b\n% output:   x= the solution to Ux = d\n\nn=length(d);\nx=zeros(size(d));\n\n% Use a for loop that counts backwards from i=n to 1.\n% Within that loop, you will need to calculate a new sum each time.\n% I recommend re-initializing a variable called S, at zero,\n% and then computing the sum with a second for loop.\n\nend\n\nimport numpy as np\n\ndef back_sub(U, d):\n    # backsub uses the back-substitution algorithm to solve the equation Ux = d\n    # for an upper-triangular matrix U\n    # inputs:   U= an upper-triangular matrix\n    #           d= modified forcing function, as in Ld=b\n    # output:   x= the solution to Ux = d\n\n    n = len(d)\n    x = np.zeros(d.shape)\n\n    # Use a for loop that counts backwards from i=n to 1.\n    # Within that loop, you will need to calculate a new sum each time.\n    # I recommend re-initializing a variable called S, at zero,\n    # and then computing the sum with a second for loop.\n\n    return x\n\nfunction back_sub(U, d)\n    # backsub uses the back-substitution algorithm to solve the equation Ux = d\n    # for an upper-triangular matrix U\n    # inputs:   U= an upper-triangular matrix\n    #           d= modified forcing function, as in Ld=b\n    # output:   x= the solution to Ux = d\n\n    n = length(d)\n    x = zeros(size(d))\n\n    # Use a for loop that counts backwards from i=n to 1.\n    # Within that loop, you will need to calculate a new sum each time.\n    # I recommend re-initializing a variable called S, at zero,\n    # and then computing the sum with a second for loop.\n\n    return x\nend","type":"content","url":"/lu-starter#backward-substitution-algorithm","position":7},{"hierarchy":{"lvl1":"EigenValue Decomposition"},"type":"lvl1","url":"/evd","position":0},{"hierarchy":{"lvl1":"EigenValue Decomposition"},"content":"I want to introduce at least two other matrix decomposition techniques, the EigenValue Decomposition (EVD) and \n\nSingular-Value Decomposition (SVD). These are interesting because they are a gateway to wisdom in engineering problems -- if, for example, you can identify which chemical reaction is associated with the largest positive eigenvalue, then you know a very interesting detail about how ignition is occurring and can potentially delay ignition by working to slow down that chemical reaction. Wisdom!\n\nSee Also\n\nThere are more decompositions out there! E.g., \n\nthe QR Decomposition is relevant to model-fitting, which we will talk about shortly, but diving in to QR is not essential.\n\nFor EVD and SVD, we are not going to program them ourselves, as we are doing with almost everything else in the course. But I thought it would be nice to have a few examples this semester of how to use built-in tools.","type":"content","url":"/evd","position":1},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl2":"How to do the EVD in MATLAB/Python/Julia"},"type":"lvl2","url":"/evd#how-to-do-the-evd-in-matlab-python-julia","position":2},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl2":"How to do the EVD in MATLAB/Python/Julia"},"content":"Let’s talk about how to implement these in your programming language first. I’ll use the matrix associated with the PageRank algorithm, discussed below, as an example.\n\nImportant\n\nThe EVD can only be applied to square matrices.\n\nM=[ [  0,   0,   1, 1/2];\n    [1/3,   0,   0,   0];\n    [1/3, 1/2,   0, 1/2];\n    [1/3, 1/2,   0,   0]\n    ];\n\n% eigenvectors in V, and eigenvalues are the diagonal of L\n[V,L]=eig(M);\n\n% turns the diagonal of L into a column vector\nL_vals=diag(L);\n\n% reconstruct M\nM_reconstructed=V*L*inv(V);\n\nimport numpy as np\n\nM = np.array([\n    [0,   0,   1, 1/2],\n    [1/3, 0,   0,   0],\n    [1/3, 1/2, 0, 1/2],\n    [1/3, 1/2, 0,   0]\n])\n\n# eigenvalues (L_vals) and eigenvectors (V)\nL_vals, V = np.linalg.eig(M)\n\n# to get the diagonal matrix L, if needed\nL = np.diag(L_vals)\n\n# reconstruct M\nM_reconstructed = V @ L @ np.linalg.inv(V)\n\nusing LinearAlgebra\n\nM = [ 0    0    1  1/2;\n     1/3   0    0    0;\n     1/3  1/2   0  1/2;\n     1/3  1/2   0    0 ]\n\nresults = eigen(M)\n\nV = results.vectors\nL = Diagonal(results.values)\n\nM_reconstructed = V * L * inv(V)","type":"content","url":"/evd#how-to-do-the-evd-in-matlab-python-julia","position":3},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl2":"Eigenvectors and Values (this is largely covered in the video)"},"type":"lvl2","url":"/evd#eigenvectors-and-values-this-is-largely-covered-in-the-video","position":4},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl2":"Eigenvectors and Values (this is largely covered in the video)"},"content":"“The eigenvalue problem” involves finding, for a given matrix \\mathbf{A}, the vectors \\mathbf{v}_i and corresponding scalars \\lambda_i such that\\mathbf{A}\\mathbf{v}_i= \\lambda_i\\mathbf{v}_i.\n\nWe say that the \\mathbf{v}_i are eigenvectors, and they have associated eigenvalues \\lambda_i.\n\nIn your linear algebra course you probably spent some time calculating these things for a given matrix by creating a polynomial from the determinant: \\left|\\mathbf{A}-\\lambda \\mathbf{I}\\right| (where \\mathbf{I} is the identity matrix) and figuring out its roots. This is definitely NOT how eigenvalues are calculated for large systems. It is kind of a disservice that the typical linear algebra class had students finding eigenvalues of a 2\\times 2 matrix by hand from the polynomial. That whole exercise carries very little meaning, delivers no intuition, and is not even how eigenvalues are calculated in most practical situations. Instead, the eigenvalues are usually determined via an iterative process based on \n\nQR Decomposition... but that is too much math to talk about here.\n\nA 5\\times 5 matrix is not even “large”, yet solving the fifth-degree polynomial is impossible for a human and not straightforward for a computer either. In many applications, the matrix in question is even larger, maybe much larger, and there is no hope of finding the polynomial’s roots!","type":"content","url":"/evd#eigenvectors-and-values-this-is-largely-covered-in-the-video","position":5},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl2":"The Decomposition"},"type":"lvl2","url":"/evd#the-decomposition","position":6},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl2":"The Decomposition"},"content":"An n \\times n matrix (of full rank) will have n eigenvectors. If we gather them together as columns of a matrix (called \\mathbf{V}) and include the eigenvalues in a diagonal matrix (called \\boldsymbol{\\Lambda}, “lambda”, or \\boldsymbol{L}... not the same as that in LU decomposition), we could write \\mathbf{A}\\mathbf{V}=\\mathbf{V}\\boldsymbol{\\Lambda}. Or, writing in the typical decomposed form:\n\nWe use the order \\mathbf{V}\\boldsymbol{\\Lambda} instead of \\boldsymbol{\\Lambda}\\mathbf{V} to make sure each column of \\mathbf{V} is multiplied by the correct \\lambda.\\mathbf{A}=\\mathbf{V}\\boldsymbol{\\Lambda}\\mathbf{V}^{-1}.\n\nThis is the EVD of matrix \\mathbf{A}. The eigenvectors and eigenvalues are properties of \\mathbf{A}, independent of \\mathbf{x} or \\mathbf{b}.","type":"content","url":"/evd#the-decomposition","position":7},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl2":"Applications"},"type":"lvl2","url":"/evd#applications","position":8},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl2":"Applications"},"content":"Thinking about what the eigenvalues mean for a system is really interesting. In many cases, the eigenvalue/vector pairs can be interpreted as the magnitudes and direction of greatest stretch (when applying a matrix to a vector), but that is not always a useful perspective. I’ll give some examples here where that understanding is and is not meaningful.","type":"content","url":"/evd#applications","position":9},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"Linear Predator-Prey Models","lvl2":"Applications"},"type":"lvl3","url":"/evd#linear-predator-prey-models","position":10},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"Linear Predator-Prey Models","lvl2":"Applications"},"content":"Let’s examine the discrete system\\begin{bmatrix}\n        x_{i+1}\\\\\n        y_{i+1}\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        2 & -1\\\\\n        1 & -1\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        x_i\\\\\n        y_i\n    \\end{bmatrix}.\n\nwhich is sometimes called a “linear predator-prey model” -- the idea is that the population of two species, often said to be foxes and rabbits, in year (or generation) i+1 is going to depend on the population in year/generation i. The matrix is interesting to create in itself, as it includes factors such as reproduction, food scarcity (not enough rabbits for the foxes to eat), etc.\n\nSee Also\n\nIn truth, this isn’t a very meaningful predator-prey model -- those usually have a nonlinear term \\dot{x}\\sim -xy that implies a consumption rate that increases with both the population of predator and prey. A nonlinear system can’t immediately be put into a matrix framework, but can be linearized around critical points and then matrixified to understand those critical points. See the \n\nLotka-Volterra Equations.\n\nThe eigen-decomposition of this matrix is\\begin{bmatrix}\n        2 & -1\\\\\n        1 & -1\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        0.9342 & 0.3568\\\\\n        0.3568 & 0.9342\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        1.618 & 0\\\\\n        0 & -0.618\n    \\end{bmatrix}\n        \\begin{bmatrix}\n        1.2533 & -0.4787\\\\\n        -0.4787 & 1.2533\n    \\end{bmatrix}.\n\nSo, one positive eigenvalue, one negative eigenvalue. Starting with populations of x_0=0.5, y_0=0.5 (this is arbitrary), we can iterate through 1000 generations by repeatedly multiplying [0.5,0.5]^T by the original matrix. The result is... well, a big value for each, but the more interesting thing is the ratio:\\frac{x_{1000}}{y_{1000}}=2.618=\\frac{0.9342}{0.3568}.\n\nThat is, the “vector” [x,y]^T ends up pointing in the same direction as the eigenvector associated with the biggest eigenvalue. This provides some intuition about a meaning of the eigenvectors: when a matrix is applied to a vector, the vector will be stretched in the direction of the eigenvector with the greatest eigenvalue. Here, that has meaning: This ends up being the steady-state population ratio between species x and y.\n\nNote\n\nAgain, a better population model would include some effect of overpopulation that would keep the populations from going to \\infty.","type":"content","url":"/evd#linear-predator-prey-models","position":11},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"A model with complex eigenvalues","lvl2":"Applications"},"type":"lvl3","url":"/evd#a-model-with-complex-eigenvalues","position":12},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"A model with complex eigenvalues","lvl2":"Applications"},"content":"What about the following?\\begin{bmatrix}\n        x_{i+1}\\\\\n        y_{i+1}\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        3 & 9\\\\\n        -4 & -3\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        x\\\\\n        y\n    \\end{bmatrix}\n\nThis matrix decomposes into\\mathbf{V}=\\begin{bmatrix}\n        0.832 & 0.832\\\\\n        -0.277+0.480i & -0.277-0.480i\n    \\end{bmatrix},\n    \\quad\n    \\boldsymbol{\\Lambda}=\\begin{bmatrix}\n        5.196i & 0\\\\\n        0 & -5.196i\n    \\end{bmatrix}.\n\nComplex eigenvectors and eigenvalues?\nStarting again with (x_0,y_0)=(0.5,0.5) and repeatedly applying the matrix via \\mathbf{x}_{i+1}=\\mathbf{A}\\mathbf{x}_i yields\\frac{x_{i+1}}{y_{i+1}}=1\\text{ or }-1.714\\text{, alternating back-and-forth.}\n\nComplex eigenvalues/vectors are associated with rotational motion.\n\nFor nonlinear systems, we analyze stationary/critical/fixed points. It is sometimes significant to the understanding of system dynamics to recognize that a point with purely imaginary eigenvalues will have trajectories that circle that stationary point -- no real components, purely imaginary, and so no movement away from or towards the fixed point.","type":"content","url":"/evd#a-model-with-complex-eigenvalues","position":13},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"Google’s PageRank Algorithm","lvl2":"Applications"},"type":"lvl3","url":"/evd#googles-pagerank-algorithm","position":14},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"Google’s PageRank Algorithm","lvl2":"Applications"},"content":"Let’s imagine the internet has four websites on some topic. If we search for that topic, how is it decided which one is the first search result?\n\n“If I am at website A, with links to websites B, C, and D, what is my likelihood of clicking a link to move to B, C, or D?” We can frame that as a matrix system with a simple assumption that you are 33% likely to click on any of those links.\n\nIn the video, we did the following one:\\begin{bmatrix}\n        0 & 0 & 1 & \\frac{1}{2}\\\\\n        \\frac{1}{3} & 0 & 0 & 0\\\\\n        \\frac{1}{3} & \\frac{1}{2} & 0 & \\frac{1}{2}\\\\\n        \\frac{1}{3} & \\frac{1}{2} & 0 & 0\\\\\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        x_\\text{A}\\\\\n        x_\\text{B}\\\\\n        x_\\text{C}\\\\\n        x_\\text{D}\n    \\end{bmatrix}_1\n    =\n    \\begin{bmatrix}\n        x_\\text{A}\\\\\n        x_\\text{B}\\\\\n        x_\\text{C}\\\\\n        x_\\text{D}\n    \\end{bmatrix}_2\n\nwhere the columns were interpreted as the fraction of links on a given site that led to another site -- thus, the zeros in the diagonal. A quick clarifying example: looking at the last column, if you are on website D and it has two links, one goes to website A and the other to C, so the chance of going to A is 50% and C is 50%.\n\nSee Also\n\nI learned a lot of this from \n\nRaluca Tanase & Remus Radu’s page. They address additional questions such as: What if there are two “subcultures” that reference a search term that don’t reference each other at all? Then, depending on the starting population \\mathbf{x}, a user might never find the second subculture. Page and Brin included the probability of a a random restart point that would then have a chance throw the searcher to the other sites.\n\nWe can imagine an internet user marching their way through the links on various webpages, which would correspond to repeatedly multiplying the probability vector \\mathbf{x} by the matrix. And we might wonder: will this ever settle into a steady-state distribution, independent of the starting point, such that applying the matrix just gets us the same distribution again? I.e., \\mathbf{x}_i=\\mathbf{x}_{i+1}. Sounds like an eigenvalue problem -- the distribution we are describing would be an eigenvector with an associated eigenvalue of 1. For this example, the eigenvector associated with \\lambda=1 is\\mathbf{x}=\n    \\begin{bmatrix}\n        0.721\\\\0.240\\\\0.541\\\\0.361\n    \\end{bmatrix}.\n\nThis is the PageRank: the order that Google would place these pages in their search results. Most to least important: A, C, D, B. This is not exactly how the algorithm works, particularly not in 2024, but this is the kernel of the idea.\n\nThe interesting thing is the amount of logic buried here. In this example, every node references C, so at first glance, C must be the most important, right? Well, C only references one node: A. That probably means A is really important! So we find C indeed has a large PageRank, but A’s is larger.","type":"content","url":"/evd#googles-pagerank-algorithm","position":15},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"Chemical Mechanism Reduction","lvl2":"Applications"},"type":"lvl3","url":"/evd#chemical-mechanism-reduction","position":16},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"Chemical Mechanism Reduction","lvl2":"Applications"},"content":"The logic from Google’s PageRank Algorithm can be applied to an important modern topic: chemical mechanism reduction, which may be of interest to those who want to work with internal combustion engines.\n\nThe motivation: chemistry is vastly more complicated than a stoichiometric balance would have you believe. The “overall reaction” for methane (the simplest hydrocarbon) combustion \\text{CH}_4+2\\text{O}_2\\rightarrow \\text{CO}_2+2\\text{H}_2\\text{O} actually involves many intermediate species. Many combustion chemists deal with a mechanism that is 53 species and 325 reactions (such as H+O_2\\rightarrow O+OH). And that is just methane... gasoline is judged by its octane rating, hinting that eight carbons are in the fuel molecule. (It is actually a complicated mixture of many hydrocarbon molecules.) Diesel is judged on its cetane (hexadecane) rating, 16 carbons. (Even more complicated mixture.) The detailed chemical mechanisms for iso-octane+air and hexadecane+air have about 1000 species each. In order to simulate these in a real engine, we’d need coupled ODEs for the concentration of each species at each time step, at each location, with turbulent flow, droplet vaporization physics, and molecular diffusivity. Good luck.\n\nA partial list of additional species in methane combustion: H, O, OH, HO2, H2O2, CH3, CH2, CH, C, HCO, CH2O, CO, C2H6 (yes, the molecules can get bigger), C2H2, ... . And if we are worried about NOx pollution, we need to include N2, NO, NO2, NO3, NCO, CN, HCNO, ... . See \n\nthe GRI Mechanism.\n\nA strategy adopted by some combustion/engine researchers: Use the PageRank algorithm to identify the most significant species to the reaction for given initial concentrations, given temperature, given pressure, etc., and toss out the insignificant ones. So a mechanism that contains 150 species and 750 reactions could be reduced to, say, 15 species and 75 reactions. That is 135 species that are dropped from the coupled ODE system and 135 species where we don’t need to track their dispersal through flow and diffusion. A huge reduction in computational complexity.\n\nMost turbulent flow simulations would have a hard time with even 15 species!","type":"content","url":"/evd#chemical-mechanism-reduction","position":17},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"One More Idea in Chemistry: Computational Singular Perturbation","lvl2":"Applications"},"type":"lvl3","url":"/evd#one-more-idea-in-chemistry-computational-singular-perturbation","position":18},{"hierarchy":{"lvl1":"EigenValue Decomposition","lvl3":"One More Idea in Chemistry: Computational Singular Perturbation","lvl2":"Applications"},"content":"This is another combustion-related application that can help to reduce computational complexity. If we represent the concentration of a series of species with a vector \\mathbf{y} (i.e., the first entry might be number of moles of H_2, the second might be the number of moles of O_2,...), the change in those concentrations will be given by the set of coupled nonlinear differential equations\n\nRevisited my old advisor’s textbook to write this and the previous section: Chung K. Law Combustion Physics.\\frac{d\\mathbf{y}}{dt} = \\mathbf{g}(\\mathbf{y})\n\nand then the time-derivative of the right-hand-side will be given by\\frac{d\\mathbf{g}}{dt}=\\frac{d\\mathbf{g}}{d\\mathbf{y}}\\cdot\\frac{d\\mathbf{y}}{dt} = \\frac{d\\mathbf{g}}{d\\mathbf{y}}\\cdot\\mathbf{g}=\\mathbf{J}\\cdot\\mathbf{g}\n\nwhere \\mathbf{J} is the Jacobian matrix -- a matrix populated by derivatives of each equation, with respect to each independent variable.\n\nThere are more complications to this application than what I am about to say, particularly because \\mathbf{J} varies with time. But, basically: we can EVD \\mathbf{J} to reveal its eigenvectors, which are particular combinations of the reactions in the mechanism, and eigenvalues, which tell us something about how rapidly those reactions are proceeding. Namely, \\left|1/\\lambda_i\\right| is the characteristic time of the reaction “mode”/eigenvector. The “fast” eigenvectors can be removed from the coupled differential equations system and replaced with algebraic equations -- ostensibly, the associated reactions proceed infinitely quickly and immediately equilibrate -- which is another way to reduce the complexity of the calculation.","type":"content","url":"/evd#one-more-idea-in-chemistry-computational-singular-perturbation","position":19},{"hierarchy":{"lvl1":"Matrix Inverse Note"},"type":"lvl1","url":"/inverse","position":0},{"hierarchy":{"lvl1":"Matrix Inverse Note"},"content":"The LU-decomposition can be used to find a matrix inverse. We know \\mathbf{A}\\mathbf{A}^{-1}  = \\mathbf{I} (where \\mathbf{I} is the identity matrix... the diagonal is all ones). Let’s see what this calculation could look like for a 3\\times 3, where we write the (to-be-determined) entries of the matrix inverse as c_{ij}:\\mathbf{A}\\mathbf{A}^{-1}  = \\mathbf{I} \\rightarrow\n    \\begin{bmatrix}\n        a_{11} & a_{12} & a_{13}\\\\\n        a_{21} & a_{22} & a_{23}\\\\\n        a_{31} & a_{32} & a_{33}\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        c_{11} & c_{12} & c_{13}\\\\\n        c_{21} & c_{22} & c_{23}\\\\\n        c_{31} & c_{32} & c_{33}\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        1 & 0 & 0\\\\\\\n        0 & 1 & 0\\\\\\\n        0 & 0 & 1\n    \\end{bmatrix}.\n\nThis can be reinterpreted as\\begin{bmatrix}\n        a_{11} & a_{12} & a_{13}\\\\\n        a_{21} & a_{22} & a_{23}\\\\\n        a_{31} & a_{32} & a_{33}\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        c_{11}\\\\\n        c_{21}\\\\\n        c_{31}\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        1\\\\\n        0\\\\\n        0\n    \\end{bmatrix}\n\nwhere, reminder, the a_{ij} are known. Further:\\begin{bmatrix}\n        a_{11} & a_{12} & a_{13}\\\\\n        a_{21} & a_{22} & a_{23}\\\\\n        a_{31} & a_{32} & a_{33}\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        c_{12}\\\\\n        c_{22}\\\\\n        c_{32}\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        0\\\\\n        1\\\\\n        0\n    \\end{bmatrix}\n\nand\\begin{bmatrix}\n        a_{11} & a_{12} & a_{13}\\\\\n        a_{21} & a_{22} & a_{23}\\\\\n        a_{31} & a_{32} & a_{33}\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        c_{13}\\\\\n        c_{23}\\\\\n        c_{33}\n    \\end{bmatrix}\n    =\n    \\begin{bmatrix}\n        0\\\\\n        0\\\\\n        1\n    \\end{bmatrix}.\n\nThat is, we can determine the i^\\text{th} column of the inverse matrix using a forcing function that is mostly zeros, except for the i^\\text{th} element, which is 1. This is a great opportunity to use LU-decomposition: we can calculate \\mathbf{L} and \\mathbf{U} once, and then apply them to the different forcing functions: [1,0,0,0,...]^T, [0,1,0,0,...]^T, [0,0,1,0,...]^T, etc., to determine the columns of the inverse.\n\nTo check your work, you can use the built-in commands for inverse:\n\nA=rand(5,5);\ninvA=inv(A)\n\nTo solve a linear algebra problem MATLAB has the “under-divide”, which is slightly faster than inv(A) because it does not explicitly calculate the inverse matrix.A=rand(5,5);\nb=rand(5,1);\nx=A\\b\nx2=inv(A)*b % same\n\nimport numpy as np\nA = np.random.rand(5, 5)\ninvA = np.linalg.inv(A)\n\nTo solve a linear algebra problem, one could use:import numpy as np\nA = np.random.rand(5, 5)\nb = np.random.rand(5, 1)\nx = np.linalg.solve(A, b)\n\nusing LinearAlgebra\nA = rand(5, 5)\ninvA = inv(A)\n\nTo solve a linear algebra problem Julia has the “under-divide”, which is slightly faster than inv(A) because it does not explicitly calculate the inverse matrix.using LinearAlgebra\nA = rand(5, 5)\nb = rand(5, 1)\nx = A \\ b\nx2 = inv(A) * b # same","type":"content","url":"/inverse","position":1},{"hierarchy":{"lvl1":"Singular-Value Decomposition"},"type":"lvl1","url":"/svd","position":0},{"hierarchy":{"lvl1":"Singular-Value Decomposition"},"content":"Another decomposition idea, is the Singular-Value Decomposition (SVD).\\mathbf{A} = \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^T.\n\nThis is the “singular-value decomposition”, SVD. We will do an in-class problem on this on Tuesday, bring a computer and an image. I’ll add the link here.","type":"content","url":"/svd","position":1},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl2":"How to do the SVD in MATLAB/Python/Julia"},"type":"lvl2","url":"/svd#how-to-do-the-svd-in-matlab-python-julia","position":2},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl2":"How to do the SVD in MATLAB/Python/Julia"},"content":"Let’s talk about how to implement these in your programming language first. I just grabbed the same matrix as we used for EVD, but note...\n\nImportant\n\nThe SVD can be applied to non-square matrices.\n\nM=[ [  0,   0,   1, 1/2];\n    [1/3,   0,   0,   0];\n    [1/3, 1/2,   0, 1/2];\n    [1/3, 1/2,   0,   0]\n    ];\n\n[U,S,V] = svd(M);\n\n% if not a square matrix, still picks (1,1)->(n,n), then stops\nS_vals=diag(S); \n\nM_reconstructed=U*S*V';\n\nimport numpy as np\n\nM = np.array([\n    [0,   0,   1, 0.5],\n    [1/3, 0,   0, 0],\n    [1/3, 0.5, 0, 0.5],\n    [1/3, 0.5, 0, 0]\n])\n\n# Python returns V already transposed (Vh = V^H)\nU, S_vals, Vh = np.linalg.svd(M)\n\nM_reconstructed = np.dot(U * S_vals, Vh)\n\nusing LinearAlgebra\n\nM = [ 0    0    1  1/2;\n     1/3   0    0    0;\n     1/3  1/2   0  1/2;\n     1/3  1/2   0    0 ]\n\nF = svd(M)\n\nU = F.U\nS_vals = F.S  # This is the vector of singular values\nVt = F.Vt     # This is V' (adjoint)\n\n# To reconstruct:\nM_reconstructed = U * Diagonal(S_vals) * Vt\n\n# Or using the shorthand property for the whole reconstruction:\n# M_reconstructed = F.U * F.S * F.Vt\n\nNote\n\nThe matrix \\mathbf{U} is an m\\times m orthogonal matrix, \\mathbf{V} is an n\\times n orthogonal matrix, and \\boldsymbol{\\Sigma} is an m\\times n diagonal matrix, with positive values on the diagonal, decreasing in size: s_1\\geq s_2 \\geq s_3 \\geq ... \\geq 0. The number of singular values in this matrix is the lesser of m and n, and for a square matrix, these values are the matrix’s eigenvalues squared.","type":"content","url":"/svd#how-to-do-the-svd-in-matlab-python-julia","position":3},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl2":"Low-Rank Approximation"},"type":"lvl2","url":"/svd#low-rank-approximation","position":4},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl2":"Low-Rank Approximation"},"content":"If I’m being honest, I am not sure the practicalities of how the SVD is calculated numerically. But we can still try to develop some intuition about what is going on, and talking about the matrix rank is one way to do that.\n\nSuppose we think of the rows of a matrix as vectors. (We could equivalently think about columns.) In a matrix of rank one, all the rows will be a scalar multiple of one vector, e.g.:\\mathbf{A}\\equiv\n    \\begin{bmatrix}\n        a_1 & a_2 & a_3\\\\\n        2 a_1 & 2 a_2 & 2 a_3\\\\\n        6a_1 & 6 a_2 & 6 a_3\\\\\n    \\end{bmatrix}=\n    \\begin{bmatrix}\n        1\\\\2\\\\6\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        a_1 & a_2 & a_3\n    \\end{bmatrix}\n\nThat is, the matrix can be written as \\mathbf{A}=\\boldsymbol{\\alpha}\\mathbf{a}^T, where \\boldsymbol{\\alpha} and \\mathbf{a} are column vectors. In a matrix with rank two, all the rows will be scalar multiples of two vectors, i.e., two of the rows are linearly independent, and then the remaining rows are made up of linear combinations of those two rows, e.g.:\\mathbf{A}\\equiv\n    \\begin{bmatrix}\n        ~ ― & \\mathbf{a} & ― ~\\\\\n        ~ ―& \\mathbf{b} & ― ~\\\\\n        ~ ―& 3\\mathbf{a}+4\\mathbf{b} & ― ~\n    \\end{bmatrix}=\n    \\begin{bmatrix}\n        1\\\\0\\\\3\n    \\end{bmatrix}\n    \\mathbf{a}^T+\n        \\begin{bmatrix}\n        0\\\\1\\\\4\n    \\end{bmatrix}\n    \\mathbf{b}^T.\n\nThis system could be written as \\mathbf{A}=\\boldsymbol{\\alpha}\\mathbf{a}^T+\\boldsymbol{\\beta}\\mathbf{b}^T. Another way to put it: a matrix of rank two can be written as the sum of two rank one matrices (and cannot be represented as a rank one matrix). A matrix with rank three would require three rank one matrices, \\mathbf{A}=\\boldsymbol{\\alpha}\\mathbf{a}^T+\\boldsymbol{\\beta}\\mathbf{b}^T+\\boldsymbol{\\gamma}\\mathbf{c}^T, four takes four, five takes five, etc.\n\nWith one last gimmick -- write all the vectors as unit vectors multiplied by a scalar constant -- we can represent a matrix with rank k as:\\mathbf{A}=\\sum\\limits_{i=1}^k s_i \\mathbf{u}_i\\mathbf{v}^T_i\n\nwhere \\mathbf{u}_i and \\mathbf{v}_i are unit vectors and s_i is a scalar. Not coincidentally, this looks like the SVD decomposition, and s_i are the singular values.\n\nNote\n\nRelating to the \\boldsymbol{\\alpha} description from before: \\boldsymbol{\\alpha}\\mathbf{a}^T=s_1 \\mathbf{u}_1\\mathbf{v}_1^T. This is generic and totally legal.","type":"content","url":"/svd#low-rank-approximation","position":5},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl2":"Applications"},"type":"lvl2","url":"/svd#applications","position":6},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl2":"Applications"},"content":"Suppose we were to write a matrix \\mathbf{A} with m rows and n columns as\n\nThe rank of the matrix is the smaller of m and n, here I assumed it would be m.\\mathbf{A}=s_1 \\mathbf{u}_1\\mathbf{v}^T_1 +\n    s_2 \\mathbf{u}_2\\mathbf{v}^T_2 +\n    s_3 \\mathbf{u}_3\\mathbf{v}^T_3 + \\dots\n\nwhere s_1 \\geq s_2 \\geq s_3 \\geq ... \\geq s_{m-1} \\geq s_m \\geq 0. So we can say that the matrix has rank m, but let’s further suppose that a certain number of the singular values are approximately zero, i.e., s_m \\approx 0, s_{m-1} \\approx 0, ... . These terms are not going to appreciably contribute to the summation to get \\mathbf{A}. So the “full” matrix \\mathbf{A}, with rank m, can be well-approximated by another matrix \\mathbf{A}_k, with rank k<m. We say the matrix \\mathbf{A}_k is the “low-rank approximation” of the “full” matrix \\mathbf{A}.","type":"content","url":"/svd#applications","position":7},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl3":"Image Processing/Data Compression","lvl2":"Applications"},"type":"lvl3","url":"/svd#image-processing-data-compression","position":8},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl3":"Image Processing/Data Compression","lvl2":"Applications"},"content":"This rationalization lends itself well to understanding why SVD works in image processing. A black-and-white image can be interpreted as a matrix, with the value in each entry the intensity of that pixel. We can can get a really decent image with the low-rank approximation, wherein we essentially discard a bunch of information, thus reducing the storage size. SVD is the tool that we use to do that (and there is a bit of judgment involved in deciding how many singular values to keep).\n\n\n\n\n\nTwilight picture (and made black-and-white) of my neighbors’ cat, LB, in full detail (top); and in a low-rank approximation (bottom). The low rank approximation ostensibly requires about 5% of the storage space.\n\nThe original image is 3024\\times 4032 pixels, meaning the matrix describing it has 12.2 million entries (the intensity of each pixel) and 3024 singular values. The full SVD has 3024\\times (3024+4032)=21.3 million numbers. However, the singular values are ranked, and many of them are nearly zero. Effectively, we toss out the ones that are nearly zero, and then rewrite a reduced version of \\mathbf{U}, \\mathbf{S}, and \\mathbf{V}. After recombining them, the image is inferior, but not bad, and requires much less space to store.\n\nThe specifics: In the second image, we keep only 100 of the singular values. We still get a lot of of detail of LB, of the grain in the wood, of the trees, the pine needles, etc. That is, the low-rank approximation does a really good job replicating the original image in just 6% of the space. (Full disclosure, the images I saved are 2.8 MB and 2.3 MB, signaling that this isn’t how MATLAB actually saves the images.)\n\nAttention\n\nThe image itself is still 3024\\times 4032, and so saving it in the “naive” way, with individual pixel intensities, does not actually help us: it’s 12192768 doubles. Meanwhile: \\mathbf{U} goes from 3024\\times 3024 to 3024\\times 100, \\mathbf{S} goes from 3024\\times 4032 to 100\\times 100, and \\mathbf{V} goes from 4032\\times 4032 to 4032\\times 100. If we can save these three matrices separately, it is 715600 doubles total.","type":"content","url":"/svd#image-processing-data-compression","position":9},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl3":"Understanding Big Data Sets","lvl2":"Applications"},"type":"lvl3","url":"/svd#understanding-big-data-sets","position":10},{"hierarchy":{"lvl1":"Singular-Value Decomposition","lvl3":"Understanding Big Data Sets","lvl2":"Applications"},"content":"We also may look to the singular-value decomposition for insight into otherwise unwieldy data. One example: Put members of the Congress in rows in a matrix, and each bill’s votes make up the columns. E.g., a congressperson who votes “yea”, “yea”, “nay” would have a row [1,1,0]. The SVD can be used to quantitatively assess each congressperson’s partisanship.\n\nTaken from a textbook: Fundamentals of Numerical Computation by Tobin Driscoll & Richard Braun. Prof. Driscoll explained some of the finer details to me in an email.\n\nThere are 435 members in the US Congress, and in a two-year session they vote on 600 bills or so, so this system would include approximately 435\\times 600=261,000 data points. Definitely a lot of data, and it is not exactly obvious how to assess which of the 435 columns is most partisan. (Maybe something like: How often did you disagree with the median vote of your political party? But we’d need to additionally inject information about political party. And how do we deal with independents? ...We’d just have to ignore them.)\n\nBig-picture, the system will likely be very well-described by a rank-2 matrix because the US is de-facto a two-party system where members of each party are “whipped” (there is literally a position within each party called the “whip”) into voting along party lines. There will be enough alignment between any given republican and the stereotypical republican, and any given democrat and the stereotypical democrat, that the entire voting record can be described nearly perfectly with a linear combination of the array of R votes plus the array of D votes. Indeed, if each party votes as a block only the first two singular values are nonzero. (Assuming no third-party candidates/independents.)\n\nGood write-up on this aspect \n\nhere, by Cleve Moler, quantitatively describing an increase in partisanship over time.\n\nWithout getting too lost in the weeds, we can create a “partisanship score” for each congressperson with \\mathbf{A}\\mathbf{v}_1, i.e.~by multiplying the voting record matrix by the first column in \\mathbf{V}; and a “bipartisanship score” by multiplying it by the second column. The outputs are vectors -- one entry per congressperson. The SVD thus gives us an unbiased score for each member that we can use to criticize them.\n\nA reasonable interpretation is that, similar to the dot product between two vectors telling us “the component of a vector along another vector”, these multiplications tell us “the component of the matrix along the first and second right singular vectors.” There would need to be an additional step wherein we decide how to normalize this information. Note also that \\mathbf{A}\\mathbf{v}_1=\\sigma_1 \\mathbf{u}_1, which is a representation that more explicitly includes the role of the singular values.\n\nSee Also\n\nSVD is used in machine learning. \n\nHere is an implementation in scikit-learn. We won’t need to build our machine learning project from such fundamental details, but hopefully you appreciate hearing that this (long but still hopefully readable) document is relevant to a very modern tool.","type":"content","url":"/svd#understanding-big-data-sets","position":11},{"hierarchy":{"lvl1":"Keys to Success (not just in 3030)"},"type":"lvl1","url":"/success","position":0},{"hierarchy":{"lvl1":"Keys to Success (not just in 3030)"},"content":" **Author:** Jeremy Koch \n\nI speculate that your career success will be correlated with your ability to focus and persevere when stuck.\n\nBeing an engineer means being able to carry out a careful analysis that may take hours or days or weeks to assemble. When we get stuck, we find our way out by learning a new topic, finding connections, reconsidering the assumptions, trying a new approach, etc. It is hard, time-consuming work! Having the wisdom, patience, and organization skills to put that all together is why we are trusted with exciting and meaningful projects (and why we make decent money).\n\nPassivity is easier, but it gets you nowhere.\n\nYou are not an empty vessel that is getting filled when I lecture, and reading solutions/watching others solve problems is not an effective way to learn. The best way to learn is to do! We assign homework so that you have problems in which you have to interpret, plan, make decisions, carry out an analysis, interpret the results, and more. These things are what I really care about, but they are harder to assess than “did you use the right equation here and do the algebra right”, so I am stuck assessing that.\n\nFacing the decision of whether to use approach 1 or approach 2 is uncomfortable. What if you are wrong? Be wrong for a second, you’ll figure it out! Don’t just ask someone else to tell you which is the right way, or if you do, at least ask them why and judge for yourself if it makes sense. Figuring it out yourself will teach you why it is the way it is, and you will be more ready the next time you see a similar problem.\n\nAI is a tool that amplifies your skills.\n\nI worry that there is a misconception about how AI is going to be useful in your careers. Homework problems are well-posed because they have to be. Here is the velocity and some properties, compute the pressure. This type of problem is easy for LLMs to solve... and you will probably never see it again after your fluid mechanics class.\n\nNot to say it is pointless. By doing the problem, you will develop intuition about how pressure and velocity are related, get some experience with the algorithm of problem solving, and maybe will get to think about the design opportunities.\n\nReal problems are not so nice. “The pressure in my turbocharger is 15% too high” is going to get a handful of generic comments from AI that probably won’t help. Turns out the seal was erroneously manifactured 5% too thick delaying the wastegate from opening, or something... I doubt that a large-LANGUAGE model would figure that out. (\n\nMaybe it would!)\n\nA pretty accurate description of LLMs: “This is what a good answer SOUNDS like, but as a large-language model, I don’t know if it is ACTUALLY a good answer!” I imagine a lot of the research happening in this field is about getting the language of problems to be more closely aligned with the physical descriptions of the problems.\n\nMeanwhile, a wise engineer might know how to get access to a bunch of data about the turbocharger’s performance. Pressure, temperature, oxygen level, all as a function of time from start-up, etc., maybe an overwhelming amount of data across 10 different turbochargers put through hours of testing! But the wise engineer knows enough about the details to coach an AI into developing a machine learning model, and then is insightful enough to triangulate a solution from that data.\n\nTHAT is the power of LLMs. If you know what you are doing and know how to assess the validity of ideas, they can streamline some of the busywork, quickly delivering information to help you make a decision. If you don’t have the foundation, you won’t know the questions to ask and won’t be able to discern a good idea from a bad one. Even if AI delivers a reasonable answer, do you believe it? Could you convince your boss? There’s probably a lot of money involved... how confident are you?\n\nGet the easy stuff right.\n\nAttending class and office hours. Submitting your work on time. \n\nCommunicating in a professional way. Staying off social media in class. Not watching soccer in class (yes, this happens). Showing up to exams with a pencil (yes, this too). These things are not hard. Get the easy stuff right and the hard stuff won’t be as hard and/or you will actually reap the full rewards from your hard work.\n\nDon’t forget you and your instructors have the same goal: to see you succeed.\n\n“Success” is not just “good grades”, think long-term: a happy life, satisfying work, continued opportunities for growth. You may have a slightly different definition of success, but I still want to see you succeed.\n\nI unfortunately have to give grades in this class, and a few people might not pass -- a temporary setback, but that is with their long-term success in mind. Rounding a student’s final grade of 64% to a C- does not serve their long-term success. Allowing a student to rush through and submit multiple late assignments during finals week does not serve their long-term success.\n\nSuccess is built on: being earnest (as in: don’t just rush through the work... care about your education!), being responsible (get the easy stuff right), and taking care of your health.","type":"content","url":"/success","position":1}]}