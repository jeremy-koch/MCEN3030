# AI in Computational Methods

**Author:** Jeremy Koch<sup>1,2</sup> \

For better or worse, AI seems like it is here to stay. I could write many thousands of words on why this is not necessarily a good thing for students. Most notably: Why would an engineer who has outsourced all their thinking to AI be hired? 

An engineer who is solid at the fundamentals can use AI to supercharge their abilities, but overuse of AI is preventing many students from becoming solid at the fundamentals.

A class like MCEN 3030: Computational Methods is particularly vulnerable to AI misuse. As an example, the Newton-Raphson Method for determining the roots of a function has been known since the 1600's. I don't know .

This means that LLMs (large-language models) have for sure seen countless versions of the code on the internet, and so a simple prompt like "Write me python code that implements 1D Newton-Raphson" is going to give you a perfect implementation of the method. 


known to engineersIt was probably one of the first things to appear on the internet. 

As I thought about designing the course, a few things were on my mind.
- We could officially prohibit AI. This would involve a lot of police-work on my end, which I have no appetite for, and it would likely lead to an adversarial relationship between me and you. I for sure don't want that. 
- I am uncomfortable with the fact that a student who has misused AI 





## Practically...

You have the green-light to use AI on homework and projects in this course. Pencil-and-paper work, including the in-class problems and exams, are technology-free -- no AI. I therefore encourage you to judiciously AI to debug your work, explain error messages, generate example applications, etc. Additionally, it may be essential to use AI on the machine learning project in this class.

I strongly discourage using AI to write your code from scratch, or even to give you a "skeleton"/outline of the code. It is possible, and many of your colleagues did it in recent semesters. By devaluing this course, they missed out on an opportunity to grow as engineers.
:::{aside}
I am hearing stories about students in tech electives/senior design who are running code, writing down the output on a piece of paper, changing the code and rerunning, writing that result down, changing the code and rerunning, writing that result down, ... . Didn't know how to add the three or fours lines to automate this entirely. I am kinda embarrassed: some of them probably passed my MCEN 3030 course.
:::

## If I am not going to police AI use...

... the responsibility shifts to the students to understand what amount is too much. A good starting point: If you would be hesitant to show me your prompts, you probably went too far.

:::{warning}
Someone will use AI to complete every homework problem in this class and will pass the exams. Presumably, this person will have a good computer science foundation and/or they responsibly used AI.

Someone will use AI to complete every homework problem in this class and will fail the exams.

Another someone will claim that they "only" used AI to debug, or to "get started", or that they used AI but really tried to understand the output, yet they too will fail the exams. I will be a bit sympathetic, but won't change the grades. Understanding a solution is a VERY different mental process than being able to produce a solution -- you do not want to be the one to learn this the hard way. 

There will be no test re-dos, no extra credit, and probably won't be much of a curve. Don't ask.
:::

<!-- :::{aside}
https://en.wikipedia.org/wiki/Magnetic-core_memory
::: -->


<!-- ::::{tab-set}
:::{tab-item} MATLAB
```MATLAB
f=@(x) x^2
```
:::
:::{tab-item} python
```python
f=lambda x: x**2
```
:::
:::{tab-item} julia
```julia
f=lambda x: x**2
```
:::

:::: -->