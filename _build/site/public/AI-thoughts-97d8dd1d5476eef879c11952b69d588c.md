# Some thoughts on AI

**Author:** Jeremy Koch

## Motivation

Optional reading, if you care to hear my opinions. On the technical aspects of how LLMs work, I am far from an expert. But when it comes to AI use in engineering education, including how that manifests in your early career, I have done a lot of thinking on this issue.

## What are LLMs doing?

First, a bit of vocabulary.
- AI = artificial intelligence. This is a very broad idea that we, as a society, [have been thinking about for a long time](https://thejetsons.fandom.com/wiki/Rosey).
- LLM = large language model. This was the recent breakthrough. Trained on massive amounts of text, they are "predictive" in the sense that, given a bit of text, they can guess what bit of text comes next based on their training. 
:::{aside}
There is debate about whether LLMs represent a form of artificial intelligence, or are they simply statistics calculators. I lean more towards the latter.
:::
- Token == the calculation unit of LLMs. It is not quite a word.

So, a dismissive view of LLMs is that they are plagiarism machines, but maybe the blandest kind: they don't steal from one author, they have a knowledge base that includes 50 authors who have written a similar bit of text. If 13 of them followed up that bit of text with with a similar idea, and the other 37 had unique ideas, it is ostensibly going to follow-up with some average of the 13 ideas. After all, that is the one that is statistically most likely, and therefore "correct"?!

Let me emphasize again that I am not an expert on the technical side. I think a lot of the current research towards new models is about systematically examining the 37 other opinions, maybe in slightly different contexts, in order to judge if they should influence the output. When an LLM claims "PhD-level knowledge", it is likely trying to cut through the large amounts of less-expert knowledge to find the one or two pieces of genuine-expert knowledge, and that is a tougher problem.

## Some readings

The Atlantic has produced a steady stream of thought-provoking articles on AI use. Here are a few -- I don't endorse the views in any of them, but they might help you to shape your opinions.

- [The Entry-Level Hiring Process Is Breaking Down](https://www.theatlantic.com/ideas/2025/12/grade-inflation-ai-hiring/685157/).
> "In the past, companies looking for fresh entry-level talent could rely on a college graduate’s GPA as a mark of their intelligence and work ethic. Hiring managers could assess a candidate’s cover letter and interview performance to get a sense of their writing and communication skills. Now those signals have lost much of their value. Rampant grade inflation has rendered GPAs almost meaningless. The widespread use of AI to write cover letters—and even to assist with job-interview performance—has robbed those assessments of their predictive power."

- [The Age of De-Skilling](https://www.theatlantic.com/ideas/archive/2025/10/ai-deskilling-automation-technology/684669/).
> "

- [My Students Use AI. So What?](https://www.theatlantic.com/ideas/archive/2025/10/ai-college-crisis-overblown/684642/)

<!-- :::{aside}
https://en.wikipedia.org/wiki/Magnetic-core_memory
::: -->


<!-- ::::{tab-set}
:::{tab-item} MATLAB
```MATLAB
f=@(x) x^2
```
:::
:::{tab-item} python
```python
f=lambda x: x**2
```
:::
:::{tab-item} julia
```julia
f=lambda x: x**2
```
:::

:::: -->