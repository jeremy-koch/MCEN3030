# Using AI in school

**Author:** Jeremy Koch<sup>1,2</sup> \

## AI Misuse

Your instructors are not na√Øve. We are aware that AI use is widespread among students. That alone is not necessarily an issue, it is MISuse . I honestly would really love it if we spend the whole 


For engineering courses, the most audacious behavior I have seen is students taking screenshots of problems, pasting into ChatGPT, and then copying the results. These students possibly did not even read the problem! I have given the following (perhaps controversial) advice in the past, and I guess will give it here: If you care that little about mechanical engineering, you should consider switching majors. Find something you are actually passionate about. You are in the first stages of your careers and might spend the next 40 years as a mechanical engineer... it sounds like a [curse](https://en.wikipedia.org/wiki/The_Monkey%27s_Paw) to be given what you want, today (very little effort on your homework), just for you to hate your job for the next four decades.

:::{tip}
If you would be ashamed to show your instructor your prompts, you are probably misusing AI.
:::

:::{warning}
The thing that students need to realize is that understanding an answer is very very very different from being able to produce an answer. I suspect many students ask LLMs to produce an answer, then they "study" it, and then think they "understand" the problem. That is basically never the case.

If you are interested, you can read about [Bloom's Taxonomy](https://en.wikipedia.org/wiki/Bloom%27s_taxonomy), which is a framework for understanding mastery of a topic. Reading LLM solutions may help you with "knowledge" and "comprehension", the lower levels of the taxonomy ("Ah that is how to format the inputs"). It will not help you get better at the "application", "analysis", "synthesis", or "evaluation" levels. This far into your engineering education, those are the things that matter.
:::

## AI Reasonable Use

It is my assessment that, overall, LLMs are plagiarism machines -- it's just that they go word-by-word, statistically, and so it is difficult to point to a single source from which their text was plagiarized. However, when it comes to coding, I have a comforting hypothesis that the LLMs are looking at code documentation (e.g. for [numpy piecewise](https://numpy.org/devdocs/reference/generated/numpy.piecewise.html)) and logicking together the inputs and outputs to achieve a goal. I feel a bit better about that, at least from an ethical standpoint.

This does not mean that LLMs are there to help you learn: if you want to learn, you must be more thoughtful about how you interact with them. 

So here are my recommendations on how to responsibly use AI, if your goal is to actually learn:
- Do not go to AI at the beginning. Do not go to AI immediately when you get stuck. Getting stuck and thinking about how to get unstuck is very much an authentic engineering experience. Reread the problem, think about what information is given, what information is missing that is needed, what assumptions could be made etc.
- If, after a while of being stuck, you have not made much progress, then talk to an AI. But write it in your own words, and try to be specific about the issue. "I am trying to write a root-solving algorithm using Newton-Raphson Method. I am stuck trying to figure out when to end the iterations.". Honestly, I don't think the AI will need all that detail, but this is not about what the AI needs, it is about what you need... you need to get practice with the language, with defining problems, with troubleshooting your logic!
- Once you 

## Prompting